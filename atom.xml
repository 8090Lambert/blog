<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>8090Lambert | Blog</title>
  
  <subtitle>A Programmer With Coding.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://8090lambert.cn/"/>
  <updated>2021-11-04T09:58:13.279Z</updated>
  <id>http://8090lambert.cn/</id>
  
  <author>
    <name>8090Lambert</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LSMTree结构理解</title>
    <link href="http://8090lambert.cn/2021/08/03/LSMTree%E7%BB%93%E6%9E%84%E7%90%86%E8%A7%A3/"/>
    <id>http://8090lambert.cn/2021/08/03/LSMTree结构理解/</id>
    <published>2021-08-03T09:35:42.000Z</published>
    <updated>2021-11-04T09:58:13.279Z</updated>
    
    <content type="html"><![CDATA[<p>LSM-Tree 结构的存储系统，将离散的随机写请求，通过WAL + Compaction机制变为批量的顺序写请求，<br>提升写入性能。但是，多个level、每层多个SST文件的架构也存在一些问题：</p><ul><li>读放大：当查询一个key时，需要遵循从新到旧的查找过程，直到找到想要的数据。虽然有全局manifest文件索引、<br>每个SSTable还有Bloom filter，但是逐层的步骤不可避免，这个过程可能需要不止一次的磁盘IO，尤其是做query range时，影响更明显；</li><li>空间放大：所有写入都是顺序写，修改和删除操作也是通过写入新的 SN 来实现，所以无效数据不会随着delete一起立即删除，<br>而是在compaction时实现物理删除；</li><li>写放大：每层level，在SSTable数量到达一定阈值时，会发生compation操作（本层和下一层中的相同key如果有重叠，<br>会进行排序后的重写）</li></ul><h3 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h3><p>每一个 Record 由 &lt;Key, SN(Sequence Number), ValueType, Value&gt; 四部分组成。SN 是在写入数据时生成的一个全局递增的整数，<br>ValueType 表明这个 Record 是否为有效的 Record。 Record 被分为多层保存，从 Level 0 开始到 Level N。除 Level 0 外，<br>每一个 Level 内的 Record 都是有序的，且被分别保存在多个文件中，每个文件被称作一个 SStable。</p><h3 id="写入流程："><a href="#写入流程：" class="headerlink" title="写入流程："></a>写入流程：</h3><ul><li>生成一个新的SN.</li><li>将 Record 写入WAL（write ahead log），保证Crash Safe(Consistency Safe).</li><li>将 Record 写入内存中的 Memtable.  </li></ul><p>当 MemTable(可读可写) 中的数据量超过某个值(一般4MB)时，会变为 Immutable memtable(可读)。通过双buffer的机制，<br>有效减少了 MemTable 在写满时，由于flush到磁盘可能产生的阻塞问题。</p><h3 id="查询流程"><a href="#查询流程" class="headerlink" title="查询流程"></a>查询流程</h3><p>一般读取有两种方式：</p><ol><li>通过<code>get</code>接口读取数据.</li><li>创建一个<code>snapshot</code>，基于该<code>snapshot</code>调用get接口读取数据. </li></ol><p>这两种方式本质一样，都是快照读，第一种方式会先隐式的创建一个数据库当前状态的快照，然后基于这个快照再去调用<code>get</code>方法读.  </p><p>具体的步骤如下：</p><ul><li>在Memtable（skipList）中查找指定的key，若搜索到符合条件的key就结束查找；</li><li>在Immutable memtable（skipList）中查找指定的key，若搜索到符合条件的key就结束查找；</li><li>按照level0 -&gt; levelN的顺序在每层中的sstable文件中查找指定的key，若搜索到符合条件的数据项就结束查找  <blockquote><p>注意在每一层sstable中查找数据时，都是按序依次查找sstable的。<br>0层的文件比较特殊。由于0层的文件中可能存在key重合的情况，因此在0层中，文件编号大的sstable优先查找。理由是文件编号较大的sstable中存储的总是最新的数据。<br>非0层文件，一层中所有文件之间的key不重合，因此可以借助sstable的元数据（一个文件中最小与最大的key值）进行快速定位，每一层只需要查找一个sstable文件的内容。  </p></blockquote></li></ul><p>在memory db或者sstable的查找过程中，需要根据指定的序列号拼接一个internalKey，<strong>查找用户key一致，且seq号不大于指定seq</strong> 的数据.</p><h3 id="Compaction-压缩"><a href="#Compaction-压缩" class="headerlink" title="Compaction(压缩)"></a>Compaction(压缩)</h3><h4 id="Minor-Compaction"><a href="#Minor-Compaction" class="headerlink" title="Minor Compaction"></a>Minor Compaction</h4><p>是指将内存中 Immutable memtable 的数据持久化为 0 层的 sstable 文件的过程，若干个0层文件中key是可能存在 overlap 的。<br>是一个时效性非常高的操作，要求在尽可能短的时间内完成，否则会阻塞正常的写入操作。minor compaction 的优先级高于 major compaction，<br>当同时发生时，会暂停 major compaction。 minor compaction 操作重写文件会带来很大的带宽压力以及短时间IO压力。 因此可以认为，<br>它就是使用短时间的IO消耗以及带宽消耗换取后续查询的低延迟。</p><h4 id="Major-Compaction"><a href="#Major-Compaction" class="headerlink" title="Major Compaction"></a>Major Compaction</h4><p>对相邻两个层的 sstable 进行多路归并排序，对文件中的 key 重新排序，过滤掉冗余版本后（视情况决定是否删除原文件），重新生成新的 sstable 的过程。</p><p>一次读取需要在内存中进行效率为O（log n）的查询。 若没有在内存中命中，则需要从 sstable 文件中查找。因为0层可能存在overlap，最差情况需要遍历0层所有文件。<br>随着运行时间的增长，minor compaction 导致 0 层文件的个数会越来越多，查询效率也会越来越低，这显然是不能接受的。 因此，需要 major compaction 机制通过将0层中的文件，<br>合并为若干个没有数据重叠的1层文件，一次的查找过程就可以进行优化。 compaction 归并的一个原因就是为了提高读取的效率，优化读放大问题。</p><p>一般 major compaction 的触发机制需要满足这几个条件：</p><ul><li>当0层文件数超过预定的上限（默认为4个）</li><li>当 i 层文件的总大小超过(10 ^ i) MB</li><li>当某个文件无效读取的次数过多</li></ul><p>因为 major compaction 是为了解决 0层文件过多导致读取效率低，但是如果仅关注 i 层的文件个数，在多次major compaction后，i+1 层会发生同样的问题，<br>因此需要对每层的文件总数设定阈值。在某层文件个数达到阈值时，启动major compaction，提升读取效率，并且降低后续 compaction 的IO开销。</p><p>上述的机制可以保证合并的进行，但仍存在一种极端问题：当i层合并完成之后，i+1层的文件同时达到数据上限，更糟糕的是，最差情况下0-&gt;n层都会发生连锁更新。<br>因此在合并时增加了这样两种机制：</p><h5 id="错峰合并"><a href="#错峰合并" class="headerlink" title="错峰合并"></a>错峰合并</h5><ol><li>一个文件一个查询的开销为10ms，若某个文件的查询次数过多，且查询在该文件中不命中，那么这种行为就可以视为无效查询开销</li><li>一个1MB的文件，其合并的开销为25ms。因此当一个1MB文件的文件无效查询超过25次时，对其合并</li></ol><h5 id="采样探测"><a href="#采样探测" class="headerlink" title="采样探测"></a>采样探测</h5><p>在sstable文件的metadata中，有一个额外的字段seekLeft，默认为文件的大小除以16kb。采样的过程：<br>记录本次访问的第一个sstable文件，如果在该文件中访问命中，则不做任何处理；若未命中，对该文件的seekLeft标志做减一操作。<br>seekLeft标志减少到0时，触发对该文件的错峰合并。</p><h5 id="最终目标"><a href="#最终目标" class="headerlink" title="最终目标"></a>最终目标</h5><p>Compaction 的设计一方面需要保证Compaction的基本效果，另一方面又不会带来严重的IO压力。<br>然而，并没有一种设计策略能够适用于所有应用场景或所有数据集。Compaction选择什么样的策略需要根据不同的业务场景、不同数据集特征进行确定。<br>设计Compaction策略需要根据业务数据特点，目标就是降低读、写、空间三者的放大，不断权衡如下几点：</p><ul><li>合理控制读放大：避免因Minor Freeze增多导致读取时延出现明显增大，避免请求读取过多SSTable；</li><li>合理控制写放大：避免一次又一次地Compact相同的数据；</li><li>合理控制空间放大：避免让不需要的多版本数据，已经删除的数据和过期的数据长时间占据存储空间，避免在Compaction过程中占用过多临时存储空间，<br>及时释放已经Compact完成的无用SSTable的存储空间；</li></ul><h4 id="Compaction流程"><a href="#Compaction流程" class="headerlink" title="Compaction流程"></a>Compaction流程</h4><p>压缩整体过程分为这几步：</p><ol><li>寻找合适的输入文件</li><li>扩大输入文件集合</li><li>多路合并</li></ol><h5 id="寻找输入文件"><a href="#寻找输入文件" class="headerlink" title="寻找输入文件"></a>寻找输入文件</h5><ul><li>对于 0 层文件数过多引发的合并场景或由于 i 层文件总量过大的合并场景，采用轮转的方法选择起始输入文件，记录了上一次该层合并的文件的最大key，<br>下一次则选择在此key之后的首个文件。</li><li>对于错峰合并，起始输入文件则为该查询次数过多的文件。</li></ul><h5 id="扩大输入文件集合"><a href="#扩大输入文件集合" class="headerlink" title="扩大输入文件集合"></a>扩大输入文件集合</h5><ol><li>在 i 层确定起始输入文件。</li><li>在 i 层中，查找与起始输入文件有key重叠的文件（这种情况一般发生在0层），构成 i 层的输入文件，结果为红线标注的文件。</li><li>利用 i 层的输入文件，在 i+1 层寻找有 key 重叠的文件，构成 i、i+1层的输入文件，结果为绿线标注的文件。</li><li>利用两层的输入文件，在不扩大 i+1 层输入文件的前提下，查找 i 层有key重叠的文件，构成最终全部的输入文件，结果为蓝线标注的文件。<br><img src="http://8090lambert.cn/images/blog/lsmtree/expand_collect.jpg" alt="expand_collect"></li></ol><h5 id="多路合并"><a href="#多路合并" class="headerlink" title="多路合并"></a>多路合并</h5><p>将输入文件内所有的数据项，按序排列之后，输出到 i+1 层的若干个新文件中。在合并的过程中，相同key的冗余数据，仅保留最新版本的那一份。<br>如果文件中存在某些仍在使用的旧版本数据，此时不能立即删除，需要等到使用结束，释放文件句柄后，根据引用计数来清除。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;LSM-Tree 结构的存储系统，将离散的随机写请求，通过WAL + Compaction机制变为批量的顺序写请求，&lt;br&gt;提升写入性能。但是，多个level、每层多个SST文件的架构也存在一些问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读放大：当查询一个key时，需要遵循从新到旧的
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>sync.Pool原理解析</title>
    <link href="http://8090lambert.cn/2021/05/23/sync-Pool%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"/>
    <id>http://8090lambert.cn/2021/05/23/sync-Pool原理解析/</id>
    <published>2021-05-23T10:34:06.000Z</published>
    <updated>2021-11-03T04:04:31.554Z</updated>
    
    <content type="html"><![CDATA[<h2 id="sync-Pool"><a href="#sync-Pool" class="headerlink" title="sync.Pool"></a>sync.Pool</h2><p><img src="http://8090lambert.cn/images/blog/sync.pool/head.jpg" alt="Pool"></p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>拥有垃圾回收特性的语言里，gc发生时都会带来性能损耗，为了减少gc影响，通常的做法是减少小块对象内存频繁申请，让每次发生垃圾回收时scan和clean活跃对象尽可能的少。<code>sync.Pool</code>可以帮助在程序构建了对象池，提供对象可复用能力，本身是可伸缩且并发安全的。</p><p>主要结构体<code>Pool</code>对外导出两个方法： <code>Get</code> 和 <code>Put</code>，<strong>Get是用来从Pool中获取可用对象</strong>，如果可用对象为空，则会通过<code>New</code>预定义的func创建新对象。<strong>Put是将对象放入Pool中，提供下次获取</strong>。<br><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cf89ea28650543e08402ab0f8c8b6ed6~tplv-k3u1fbpfcp-zoom-1.image" alt=""></p><h3 id="Get"><a href="#Get" class="headerlink" title="Get"></a>Get</h3><pre><code>func (p *Pool) Get() interface{} {    if race.Enabled {        race.Disable()    }    l, pid := p.pin()    x := l.private    l.private = nil    if x == nil {        // Try to pop the head of the local shard. We prefer        // the head over the tail for temporal locality of        // reuse.        x, _ = l.shared.popHead()        if x == nil {            x = p.getSlow(pid)        }    }    runtime_procUnpin()    if race.Enabled {        race.Enable()        if x != nil {            race.Acquire(poolRaceAddr(x))        }    }    if x == nil &amp;&amp; p.New != nil {        x = p.New()    }    return x}</code></pre><p>首先看下<code>GET</code>方法的逻辑（在看前需要对<code>gmp</code>调度模型有大致了解）</p><ul><li>通过<code>pin</code>拿到<code>poolLocal</code>和当前 goroutine 绑定运行的<code>P</code>的 id。每个goroutine创建后会挂在<code>P</code>结构体上；运行时，需要绑定<code>P</code>才能在<code>M</code>上执行。因此，对private指向的poolLocal操作无需加锁，都是线程安全的</li><li>设置<code>x</code>，并且清空<code>private</code></li><li><code>x</code>为空说明本地对象未设置，由于<code>P</code>上存在多个<code>G</code>，如果一个时间片内协程1把私有对象获取后置空，下一时间片g2再去获取就是nil。此时需要去<code>share</code>中获取头部元素，<code>share</code>是在多个<code>P</code>间共享的，读写都需要<code>加锁</code>，但是这里并未加锁，具体原因等下讲</li><li>如果<code>share</code>中也返回空，调用<code>getSlow()</code>函数获取，等下具体看内部实现</li><li>runtime_procUnpin()方法，稍后我们详细看</li><li>最后如果还是未找到可复用的对象, 并且设置了<code>New</code>的func，初始化一个新对象</li></ul><p><code>Pool</code>的<code>local</code>字段表示<code>poolLocal</code>指针。获取时，优先检查<code>private</code>域是否为空，为空时再从<code>share</code>中读取，还是空的话从其他<code>P</code>中窃取一个，类似<code>goroutine</code>的调度机制。</p><h3 id="pin"><a href="#pin" class="headerlink" title="pin"></a>pin</h3><p>刚才的几个问题，我们具体看下。首先，<code>pin</code>方法获取当前<code>P</code>的<code>poolLocal</code>,方法逻辑比较简单</p><pre><code>func (p *Pool) pin() *poolLocal {    pid := runtime_procPin()    s := atomic.LoadUintptr(&amp;p.localSize) // load-acquire    l := p.local                          // load-consume    if uintptr(pid) &lt; s {        return indexLocal(l, pid)    }    return p.pinSlow()}</code></pre><p><code>runtime_procPin</code>返回了当前的pid，实现细节看看<code>runtime</code>内部</p><pre><code>//go:linkname sync_runtime_procPin sync.runtime_procPin//go:nosplitfunc sync_runtime_procPin() int {    return procPin()}//go:linkname sync_runtime_procUnpin sync.runtime_procUnpin//go:nosplitfunc sync_runtime_procUnpin() {    procUnpin()}//go:nosplitfunc procPin() int {    _g_ := getg()    mp := _g_.m    mp.locks++    return int(mp.p.ptr().id)}//go:nosplitfunc procUnpin() {    _g_ := getg()    _g_.m.locks--}</code></pre><ul><li><code>pin</code>获取当前goroutine的地址，让g对应的<code>m</code>结构体中<code>locks</code>字段++，返回<code>p</code>的id。<code>unPin</code>则是对<code>m</code>的<code>locks</code>字段–，为什么要这么做？</li></ul><p>协程发生调度的时机之一：如果某个g长时间占用cpu资源，便会发生抢占式调度，可以抢占的依据就是locks == 0。<strong>其实本质是为了禁止发生抢占。</strong></p><pre><code>// One round of scheduler: find a runnable goroutine and execute it.// Never returns.func schedule() {    _g_ := getg()    //调度时，会判断`locks`是否为0。    if _g_.m.locks != 0 {        throw(&quot;schedule: holding locks&quot;)    }    ...}</code></pre><p>为什么要禁止调度呢?因为调度是把<code>m</code>和<code>p</code>的绑定关系解除，让<code>p</code>去绑定其他线程，执行其他线程的代码段。在<code>get</code>时，首先是获取当前goroutine绑定的p的private，不禁止调度的话，后面的获取都不是当前协程的运行时的<code>p</code>，会污染其他<code>p</code>上的数据，引起未知错误。</p><h4 id="poolChain"><a href="#poolChain" class="headerlink" title="poolChain"></a>poolChain</h4><p><code>poolChain</code>是一个双端链表，结构体如下：</p><pre><code>type poolChain struct {    head *poolChainElt    tail *poolChainElt}</code></pre><h4 id="poolChain-popHead"><a href="#poolChain-popHead" class="headerlink" title="poolChain.popHead"></a>poolChain.popHead</h4><p><code>poolChain.popHead</code>获取时，首先从<code>poolDequeue</code>的<code>popHead</code>方法获取，未获取到时，找到<code>prev</code>节点，继续重复查找，直到返回nil。</p><pre><code>func (c *poolChain) popHead() (interface{}, bool) {    d := c.head    for d != nil {        if val, ok := d.popHead(); ok {            return val, ok        }        // There may still be unconsumed elements in the        // previous dequeue, so try backing up.        d = loadPoolChainElt(&amp;d.prev)    }    return nil, false}</code></pre><p><strong><em>这里注意区分<code>poolChain</code>和<code>poolDequeue</code>，两个结构存在同名的方法，但是结构和逻辑完全不同</em></strong></p><pre><code>type poolChain struct {    // head is the poolDequeue to push to. This is only accessed    // by the producer, so doesn&#39;t need to be synchronized.    head *poolChainElt    // tail is the poolDequeue to popTail from. This is accessed    // by consumers, so reads and writes must be atomic.    tail *poolChainElt}type poolChainElt struct {    poolDequeue    next, prev *poolChainElt}type poolDequeue struct {    headTail uint64    vals []eface}</code></pre><p>需要说明下：<code>poolChainElt</code>组成的链表结构和我们常见的链表方向相反，从<code>head</code> -&gt; <code>tail</code>的方向是<code>prev</code>，反之是<code>next</code>;<code>poolDequeue</code> 是一个环形链表，<code>headTail</code>字段保存首尾地址，其中高32位表示head，低32位表示tail.<br><img src="http://8090lambert.cn/images/blog/sync.pool/poolChain.png" alt="poolChain"></p><h4 id="poolDequeue-popHead"><a href="#poolDequeue-popHead" class="headerlink" title="poolDequeue.popHead"></a>poolDequeue.popHead</h4><pre><code>func (d *poolDequeue) popHead() (interface{}, bool) {    var slot *eface    for {        ptrs := atomic.LoadUint64(&amp;d.headTail)        head, tail := d.unpack(ptrs)        if tail == head {            return nil, false        }        head--        ptrs2 := d.pack(head, tail)        if atomic.CompareAndSwapUint64(&amp;d.headTail, ptrs, ptrs2) {            slot = &amp;d.vals[head&amp;uint32(len(d.vals)-1)]            break        }    }    val := *(*interface{})(unsafe.Pointer(slot))    if val == dequeueNil(nil) {        val = nil    }    *slot = eface{}    return val, true}</code></pre><ul><li>看到<code>if tail == head</code>，如果首位地址相同说明链表整体为空，证明<code>poolDequeue</code>确实是环形链表；</li><li><code>head--</code>后<code>pack(head, tail)</code>得到新的地址ptrs2，如果ptrs == ptrs2，修改<code>headTail</code>地址；</li><li>把slot转成interface{}类型的value；</li></ul><h3 id="getSlow"><a href="#getSlow" class="headerlink" title="getSlow"></a>getSlow</h3><p>如果从<code>shared</code>的<code>popHead</code>中没拿到可服用的对象，需要通过<code>getSlow</code>来获取</p><pre><code>func (p *Pool) getSlow(pid int) interface{} {    size := atomic.LoadUintptr(&amp;p.localSize) // load-acquire    locals := p.local                        // load-consume    // 遍历locals，从其他P上的尾部窃取    for i := 0; i &lt; int(size); i++ {        l := indexLocal(locals, (pid+i+1)%int(size))        if x, _ := l.shared.popTail(); x != nil {            return x        }    }    size = atomic.LoadUintptr(&amp;p.victimSize)    if uintptr(pid) &gt;= size {        return nil    }    // 尝试从victim指向的poolLocal中，按照先private -&gt; shared的顺序获取    locals = p.victim    l := indexLocal(locals, pid)    if x := l.private; x != nil {        l.private = nil        return x    }    for i := 0; i &lt; int(size); i++ {        l := indexLocal(locals, (pid+i)%int(size))        if x, _ := l.shared.popTail(); x != nil {            return x        }    }    atomic.StoreUintptr(&amp;p.victimSize, 0)    return nil}</code></pre><p>通过遍历locals获取对象，使用到<code>victim</code>字段指向的<code>[]poolLocal</code>。这里其实引用了一种叫做<code>Victim Cache</code>的机制，具体解释详见<a href="https://en.wikipedia.org/wiki/Victim_cache" target="_blank" rel="noopener">这里</a>。</p><h4 id="poolChain-popTail"><a href="#poolChain-popTail" class="headerlink" title="poolChain.popTail"></a>poolChain.popTail</h4><pre><code>func (c *poolChain) popTail() (interface{}, bool) {    d := loadPoolChainElt(&amp;c.tail)    if d == nil {        return nil, false    }    for {        d2 := loadPoolChainElt(&amp;d.next)        if val, ok := d.popTail(); ok {            return val, ok        }        if d2 == nil {            return nil, false        }        if atomic.CompareAndSwapPointer((*unsafe.Pointer)(unsafe.Pointer(&amp;c.tail)), unsafe.Pointer(d), unsafe.Pointer(d2)) {            storePoolChainElt(&amp;d2.prev, nil)        }        d = d2    }}</code></pre><ul><li><code>d2</code>是<code>d</code>的<code>next</code>节点，<code>d</code>已经为链表尾部了，这里也应证了我们刚才说到的<code>poolChain</code>链表的首尾方向和正常的链表是相反的（至于为啥要这么设计，我也是比较懵逼）。如果<code>d2</code>为空证明已经到了链表的头部，所以直接返回；</li><li>从尾部节点get成功时直接返回，已经返回的这个位置，等待着下次get遍历时再删除。由于是从其他的P上窃取，可能发生同时多个协程获取对象，需要保证并发安全；</li><li>为什么<code>popHead</code>不去删除链表节点，两个原因吧。第一个，popHead只有当前协程在自己的P上操作，popTail是窃取，如果在<code>popHead</code>中操作，也需要原子操作，作者应该是希望把get阶段的开销降到最低；第二个，因为<code>poolChain</code>结构本身是链表，无论在哪一步做结果都是一样，不如统一放在尾部获取时删除。</li></ul><h4 id="poolDequeue-popTail"><a href="#poolDequeue-popTail" class="headerlink" title="poolDequeue.popTail"></a>poolDequeue.popTail</h4><pre><code>func (d *poolDequeue) popTail() (interface{}, bool) {    var slot *eface    for {        ptrs := atomic.LoadUint64(&amp;d.headTail)        head, tail := d.unpack(ptrs)        if tail == head {            return nil, false        }        ptrs2 := d.pack(head, tail+1)        if atomic.CompareAndSwapUint64(&amp;d.headTail, ptrs, ptrs2) {            slot = &amp;d.vals[tail&amp;uint32(len(d.vals)-1)]            break        }    }    val := *(*interface{})(unsafe.Pointer(slot))    if val == dequeueNil(nil) {        val = nil    }    slot.val = nil    atomic.StorePointer(&amp;slot.typ, nil)    return val, true}</code></pre><p>和<code>poolDequeue.popHead</code>方法逻辑基本差不多，由于<code>popTail</code>存在多个协程同时遍历，需要通过CAS获取，最后设置<code>slot</code>为空。</p><h3 id="Put"><a href="#Put" class="headerlink" title="Put"></a>Put</h3><pre><code>func (p *Pool) Put(x interface{}) {    if x == nil {        return    }    if race.Enabled {        if fastrand()%4 == 0 {            // Randomly drop x on floor.            return        }        race.ReleaseMerge(poolRaceAddr(x))        race.Disable()    }    l, _ := p.pin()    if l.private == nil {        l.private = x        x = nil    }    if x != nil {        l.shared.pushHead(x)    }    runtime_procUnpin()    if race.Enabled {        race.Enable()    }}</code></pre><p><code>put</code>方法相关逻辑和<code>get</code>很像，先设置<code>poolLocal</code>的<code>private</code>，如果<code>private</code>已有，通过<code>shared.pushHead</code>写入。</p><h4 id="poolChain-pushHead"><a href="#poolChain-pushHead" class="headerlink" title="poolChain.pushHead"></a>poolChain.pushHead</h4><pre><code>func (c *poolChain) pushHead(val interface{}) {    d := c.head    if d == nil {        // 初始化环，数量为2的幂        const initSize = 8        d = new(poolChainElt)        d.vals = make([]eface, initSize)        c.head = d        storePoolChainElt(&amp;c.tail, d)    }    if d.pushHead(val) {        return    }    // 如果环已满，按照2倍大小创建新的ring。注意这里有最大数量限制    newSize := len(d.vals) * 2    if newSize &gt;= dequeueLimit {        // Can&#39;t make it any bigger.        newSize = dequeueLimit    }    d2 := &amp;poolChainElt{prev: d}    d2.vals = make([]eface, newSize)    c.head = d2    storePoolChainElt(&amp;d.next, d2)    d2.pushHead(val)}</code></pre><p>如果节点是空，则创建一个新的poolChainElt对象作为头节点,然后调用pushHead放入到环状队列中.如果放置失败，那么创建一个2倍大小且不超过dequeueLimit（2的30次方）的poolChainElt节点。所有的vals长度必须为2的整数幂。</p><pre><code>func (d *poolDequeue) pushHead(val interface{}) bool {    ptrs := atomic.LoadUint64(&amp;d.headTail)    head, tail := d.unpack(ptrs)    if (tail+uint32(len(d.vals)))&amp;(1&lt;&lt;dequeueBits-1) == head {        return false    }    slot := &amp;d.vals[head&amp;uint32(len(d.vals)-1)]    typ := atomic.LoadPointer(&amp;slot.typ)    if typ != nil {        return false    }    if val == nil {        val = dequeueNil(nil)    }    *(*interface{})(unsafe.Pointer(slot)) = val    atomic.AddUint64(&amp;d.headTail, 1&lt;&lt;dequeueBits)    return true}</code></pre><p>首先判断ring是否大小已满，然后找到head位置对应的slot判断typ是否为空，因为<code>popTail</code>是先设置 val，再将 typ 设置为 nil，有冲突会直接返回。</p><h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p>整个对象池通过几个主要的结构体构成，它们之间关系如下：<br><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c9b9fc326d584593a9ed18d8da06f158~tplv-k3u1fbpfcp-zoom-1.image" alt=""></p><h4 id="poolCleanup"><a href="#poolCleanup" class="headerlink" title="poolCleanup"></a>poolCleanup</h4><p>注册了全局清理的func，在每次gc开始时运行。既然每次gc都会清理pool内对象，那么对象复用的优势在哪里呢？<br><code>poolCleanup</code>在每次gc时，会将<code>allPools</code>里的对象写入<code>oldPools</code>对象后再清除自身对象。那么就是说，如果申请的对象，会经过两次<code>gc</code>后，才会被彻底回收。<code>p.local</code>会先设置为<code>p.victim</code>，是不是有点类似新生代、老生代的感觉。</p><pre><code>func init() {    runtime_registerPoolCleanup(poolCleanup)}func poolCleanup() {    for _, p := range oldPools {        p.victim = nil        p.victimSize = 0    }    // Move primary cache to victim cache.    for _, p := range allPools {        p.victim = p.local        p.victimSize = p.localSize        p.local = nil        p.localSize = 0    }    oldPools, allPools = allPools, nil}</code></pre><p>可以看出，在gc发生不频繁的场景，<code>sync.Pool</code>对象复用就可以减少内存的频繁申请和回收。</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzA4ODg0NDkzOA==&amp;mid=2247487149&amp;idx=1&amp;sn=f38f2d72fd7112e19e97d5a2cd304430&amp;source=41#wechat_redirect" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzA4ODg0NDkzOA==&amp;mid=2247487149&amp;idx=1&amp;sn=f38f2d72fd7112e19e97d5a2cd304430&amp;source=41#wechat_redirect</a></li><li><a href="https://medium.com/@genchilu/whats-false-sharing-and-how-to-solve-it-using-golang-as-example-ef978a305e10" target="_blank" rel="noopener">https://medium.com/@genchilu/whats-false-sharing-and-how-to-solve-it-using-golang-as-example-ef978a305e10</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;sync-Pool&quot;&gt;&lt;a href=&quot;#sync-Pool&quot; class=&quot;headerlink&quot; title=&quot;sync.Pool&quot;&gt;&lt;/a&gt;sync.Pool&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://8090lambert.cn/images/blo
      
    
    </summary>
    
    
      <category term="go" scheme="http://8090lambert.cn/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>一致性协议raft、zab的区别</title>
    <link href="http://8090lambert.cn/2020/11/03/%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEraft%E3%80%81zab%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://8090lambert.cn/2020/11/03/一致性协议raft、zab的区别/</id>
    <published>2020-11-03T13:46:43.000Z</published>
    <updated>2021-11-03T09:20:47.406Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>为解决大型分布式系统中多个副本日志及状态机一致性问题。</p><h2 id="Raft介绍"><a href="#Raft介绍" class="headerlink" title="Raft介绍"></a>Raft介绍</h2><p>协议由三部分组成：Leader election、Log Replication、Safety。分别对应着三种状态的身份：<br>leader(工作时的首要进程)、candidate(选举时可能会成为leader)、follower(副本).</p><h2 id="Raft选举"><a href="#Raft选举" class="headerlink" title="Raft选举"></a>Raft选举</h2><p>选举的时机一般有两种： </p><ul><li>初始化时，系统中不存在 Leader 角色。所有节点均为 candidate 角色</li><li>follower 在 election timeout 后没有收到 leader心跳，follower 变为 candidate 角色</li></ul><p>candidate向其他节点发起 leader election 请求，得到超过半数其他 candidate 的回复后成为leader. 同时选举的过程存在极端情况：</p><ul><li>所有选票被多个节点瓜分，没有选出leader。</li></ul><p>为避免发生多个 candidate 同时发生选举，而导致的多次选举。raft采用 <strong>random election timeout</strong> 机制，使每个节点的超时时间不同。<br>一般来说需要保证 election timeout &gt; broadcast 的间隔时间，否则，election timeout 无法说明与leader断开连接.</p><h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><h3 id="两个限制条件保证日志复制的安全"><a href="#两个限制条件保证日志复制的安全" class="headerlink" title="两个限制条件保证日志复制的安全"></a>两个限制条件保证日志复制的安全</h3><p>限制一：选举阶段节点 m 向节点 n 发送了 RequestVote RPC，如果节点 n 发现节点 m 的数据没有自己新，则节点 n 拒绝节点 m 的投票请求。<br>这里的“新”包含两个方面，term 更大的数据更新，term 相同，index更大的数据更新。    </p><p>选举时，只有日志最新的candidate才有机会得到超过半数的投票。其中有这两个条件:</p><ul><li>term越大的节点越容易成为leader</li><li>term相同的情况下，index越大的节点越容易成为leader  </li></ul><p>限制二：不直接提交之前 term 的log，必须通过提交本 term 的 log，间接的提交之前 term 的 log。<br>选举时，在条件1的情况下，term不同，可能选举出来的leader不包含所有过半提交的日志。要解决这个问题，需要在 那么就需要对过半提交通过限制二来约束。<br>一旦加上了这个限制意味着含有所有过半提交的日志的几个节点必然拥有目前最大的term，这样的话再次进行leader选举时，就避免了条件1的误判。</p><h2 id="Raft-对比-Zab"><a href="#Raft-对比-Zab" class="headerlink" title="Raft 对比 Zab"></a>Raft 对比 Zab</h2><h3 id="Leader-election-阶段"><a href="#Leader-election-阶段" class="headerlink" title="Leader election 阶段"></a>Leader election 阶段</h3><table><thead><tr><th style="text-align:left">Issue</th><th style="text-align:left">Raft</th><th style="text-align:left">Zab</th></tr></thead><tbody><tr><td style="text-align:left">Leader检测</td><td style="text-align:left">通过Follower心跳</td><td style="text-align:left">leader: 维护Quorum集合；<br> follower: 通过长链接</td></tr><tr><td style="text-align:left">过期leader判断</td><td style="text-align:left">term_id</td><td style="text-align:left">epoch</td></tr><tr><td style="text-align:left">leader投票过程</td><td style="text-align:left">每个节点每轮只投一次票</td><td style="text-align:left">每次选举节点可能产生多次投票，选出最新的</td></tr></tbody></table><ul><li>leader 可用性检查：Raft 协议 leader 宕机仅仅由 folower 进行检测，当 folower 收不到 leader 心跳时，则认为 leader 宕机，<br>变为 candidate。Zk 的 leader down 机分别由 leader 和 folower 检测，leader 维护了一个 Quorum 集合，当该 Quorum 集合不再超过半数，<br>leader 自动变为 LOOKING 状态。folower 与 leader 之间维护了一个超链接，连接断开则 folower 变为 LOOKING 状态。</li><li>过期 leader 的屏蔽：Raft 通过 term 识别过期的 leader。Zk 通过 Epoch识别过期的 leader。这点两者是相似的。</li><li>leader 选举的投票过程：Raft 每个选举周期每个节点只能投一次票，选举失败进入下次周期才能重新投票。<br>Zk 每次选举节点需要不断的变换选票以便选出数据最新的节点为 leader。</li><li>保证 commited 的数据出现在未来 leader 中：Raft选取 leader 时拒绝数据比自己旧的节点的投票。<br>Zk 通过在选取 leader 时不断更新选票使得拥有最新数据的节点当选 leader。</li></ul><p>Zab在leader选举出来后会立即进行数据同步过程，同步下最新的epoch（相当于term），数据同步之后就不会存在Raft（经过几个term变更后）日志错乱的现象。<br>Zab是正式对外提交服务之前先清理好数据的不一致问题，Raft是延迟清理的，在后续的复制过程中不断的进行纠正更新。</p><h3 id="Log-Replication-阶段"><a href="#Log-Replication-阶段" class="headerlink" title="Log Replication 阶段"></a>Log Replication 阶段</h3><table><thead><tr><th style="text-align:left">Issue</th><th style="text-align:left">Raft</th><th style="text-align:left">Zab</th></tr></thead><tbody><tr><td style="text-align:left">新leader数据同步</td><td style="text-align:left">通过AppendEntry Rpc每次同步</td><td style="text-align:left">通过 Recovery Phase 同步</td></tr><tr><td style="text-align:left">新leader数据同步量</td><td style="text-align:left">增量同步</td><td style="text-align:left">增量或全量同步</td></tr><tr><td style="text-align:left">之前未commit数据处理</td><td style="text-align:left">commit 当前term时，会将未提交数据一起commit</td><td style="text-align:left">Recovery Phase阶段commit</td></tr><tr><td style="text-align:left">新加入集群节点数据同步</td><td style="text-align:left">不阻塞写请求</td><td style="text-align:left">Recovery Phase 会阻塞写请求</td></tr></tbody></table><ul><li>选取新 leader 后数据同步：Raft 没有固定在某个特定的阶段做这件事情，通过每个节点的 AppendEntry RPC 分别做数据同步。<br>Zk 则在新leader 选举之后，有一个 Recovery Phase 做这个件事情。</li><li>选取新 leader 后同步的数据量：Raft 只需要传输和新 leader 差异的部分。Zab 的原始协议需要传输 leader 的全部数据，Zk 优化后，<br>视情况而定，最坏情况下需要传输 leader 全部数据。</li><li>新 leader 对之前 leader 未 commit 数据的处理：Raft 不会直接 commit 之前 leader 的数据，通过 commit 本 term 的数据间接的 commit 之前 leader 的数据。<br>Zk 在 Recovery Phase直接 commit 之前 leader 的数据。</li><li>新加入集群节点的数据同步：Raft 对于新加入集群的节点数据同步不会影响客户端的写请求。Zk 对于新加入集群的节点，需要单独走一下 Recovery Phase，<br>目前是通过读写锁同步的，因此会阻塞客户端的写请求。（Zk 可以在这里使用 copy-on-write 机制避免阻塞问题？？）</li></ul><h3 id="脑裂问题"><a href="#脑裂问题" class="headerlink" title="脑裂问题"></a>脑裂问题</h3><table><thead><tr><th style="text-align:left">Raft</th><th style="text-align:left">Zab</th></tr></thead><tbody><tr><td style="text-align:left">通过增加region leader角色 + lease机制，每个请求通过region leader转发至raft leader</td><td style="text-align:left">通过Quorum过半机制避免</td></tr></tbody></table><p>Tips： Etcd 不存在脑裂</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote><p><a href="https://niceaz.com/2018/11/03/raft-and-zab/" target="_blank" rel="noopener">https://niceaz.com/2018/11/03/raft-and-zab/</a><br><a href="https://www.jianshu.com/p/072380e12657" target="_blank" rel="noopener">https://www.jianshu.com/p/072380e12657</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;为解决大型分布式系统中多个副本日志及状态机一致性问题。&lt;/p&gt;
&lt;h2 id=&quot;Raft介绍&quot;&gt;&lt;a href=&quot;#Raft介绍&quot; clas
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>IO Optimize</title>
    <link href="http://8090lambert.cn/2020/07/25/IO%20Optimize/"/>
    <id>http://8090lambert.cn/2020/07/25/IO Optimize/</id>
    <published>2020-07-25T03:15:05.000Z</published>
    <updated>2021-11-03T06:41:14.370Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、传统IO传输"><a href="#一、传统IO传输" class="headerlink" title="一、传统IO传输"></a>一、传统IO传输</h2><p>传统的数据传输，不论是文件，还是写文件，都是会经过从 磁盘-》内核缓冲区 -》用户应用缓冲区 -》Socket 缓冲区 -》 网卡，这些步骤。这其中，会涉及到 4次用户态到内核态的上下文切换、4次用户态和内核态之间的数据拷贝。<br><img src="http://8090lambert.cn/images/blog/iooptimize/origin_io.jpg" alt="origin"></p><p>以读文件为例：<br>线程在用户空间发起read()读文件，线程从用户态切换为内核态<br>DMA将磁盘数据拷贝到内核缓存后，CPU又将数据从内核缓存拷贝至用户缓存，这时线程又从内核态切换为用户态<br>CPU将数据从用户缓存拷贝至socket缓存，线程又从用户态切换到内核态<br>DMA将数据从内核缓存拷贝到网卡，read()调用结束返回，线程又从内核态切换到用户态</p><h3 id="方式一：mmap-write实现零拷贝"><a href="#方式一：mmap-write实现零拷贝" class="headerlink" title="方式一：mmap + write实现零拷贝"></a>方式一：mmap + write实现零拷贝</h3><p><img src="http://8090lambert.cn/images/blog/iooptimize/mmap_io.jpg" alt="mmap"><br>mmap，Memory Mapped Files：简称 mmap，也有叫 MMFile 的，使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射。从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程。它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。<br>使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销，在用户态对映射区域的写操作数据会同时在内核态缓存中存在<br>用户空间发起mmap系统调用<br>DMA将数据从文件系统拷贝到内核缓存中，并和用户空间堆外缓存建立映射关系<br>CPU从用户缓存读取到数据后，将数据拷贝到socket缓存中，线程从用户态切换到内核态<br>DMA将数据从socket缓存拷贝到网卡，调用write()结束后返回，线程从内核态切换到用户态<br>整个过程发生了3次拷贝，2次DMA，1次CPU；4次线程切换</p><h3 id="方式二：sendfile"><a href="#方式二：sendfile" class="headerlink" title="方式二：sendfile"></a>方式二：sendfile</h3><p><img src="http://8090lambert.cn/images/blog/iooptimize/sendfile_io.jpg" alt="sendfile"><br>sendfile，在Linux内核2.1版本之后，提供了sendfile()函数<br>sendfile(int out_fd, int in_fd, off_t *offset, size_t count);</p><p>// out_fd 参数代表待写入的文件描述符<br>// in_fd 参数代表待读取的文件描述符<br>// *offset 参数代表指定从读取文件流的哪个位置开始读，为空时则使用读入文件流默认的起始位置<br>// count 参数代表传输的字节数<br>sendfile函数实现了内核态和用户态之间的“零拷贝”：就是将数据的拷贝全部控制在内核态中，省去传统读取文件方式中 2次上下文切换 和 2次数据拷贝（伴随着上下文切换时，发生在内核态到用户态之间的拷贝），具体步骤如下：<br>用户空间发起sendfile()函数调用，设置读取数据和写入输入的文件描述符、读取字节的偏移量、读取的字节长度，进程从用户态切换到内核态<br>DMA 把磁盘的数据拷贝到内核缓存(Page Cache)中<br>CPU 从内核缓存中，将数据拷贝至socket缓存中<br>DMA 将socket缓存中的数据拷贝至网卡，sendfile调用完成，进程由内核态切换至用户态</p><p>整个过程发生了 2次上下文切换 和 3次数据拷贝，和上文说的貌似不一致。没错，在 sendfile()的 man page 中有这样的定义：In Linux kernels before 2.6.33, out_fd must refer to a socket. Since Linux 2.6.33 it can be any file. 因此，在Linux 2.6.33 之前的内核版本，写入的 fd 必须为 socket，因此数据在内核缓冲区后，需要再次拷贝到socket缓冲区，而在 2.6.33 版本之后的实现略有不同<br><img src="http://8090lambert.cn/images/blog/iooptimize/sendfile_optimize.jpg" alt="sendfile_optimize"></p><p>如图，当数据被拷贝至内核缓冲区时，通过DMA Gather控制器，直接拷贝至网卡。因为全程没有cpu参与数据的搬运，所有的数据都是通过 DMA 来进行传输的，实现了真正意义上的“零拷贝”。</p><p>Reference<br><a href="https://www.cnblogs.com/xiaolincoding/p/13719610.html" target="_blank" rel="noopener">https://www.cnblogs.com/xiaolincoding/p/13719610.html</a><br><a href="https://www.cnblogs.com/ericli-ericli/articles/12923420.html" target="_blank" rel="noopener">https://www.cnblogs.com/ericli-ericli/articles/12923420.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、传统IO传输&quot;&gt;&lt;a href=&quot;#一、传统IO传输&quot; class=&quot;headerlink&quot; title=&quot;一、传统IO传输&quot;&gt;&lt;/a&gt;一、传统IO传输&lt;/h2&gt;&lt;p&gt;传统的数据传输，不论是文件，还是写文件，都是会经过从 磁盘-》内核缓冲区 -》用户应用缓冲区
      
    
    </summary>
    
    
      <category term="linux" scheme="http://8090lambert.cn/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Kafka四问</title>
    <link href="http://8090lambert.cn/2020/01/27/Kafka%E5%9B%9B%E9%97%AE/"/>
    <id>http://8090lambert.cn/2020/01/27/Kafka四问/</id>
    <published>2020-01-27T14:35:09.000Z</published>
    <updated>2021-11-03T06:41:03.385Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="HW（HighWater）"><a href="#HW（HighWater）" class="headerlink" title="HW（HighWater）"></a>HW（HighWater）</h3><p>高水位，表示已经提交（commit）的最大日志偏移量（offset）,已提交是指 ISRs 中所有节点都已同步到这条日志</p><h3 id="LEO（Log-endOffset）"><a href="#LEO（Log-endOffset）" class="headerlink" title="LEO（Log endOffset）"></a>LEO（Log endOffset）</h3><p>日志最后偏移量，表示日志中下一条待写入消息的Offset</p><h3 id="ISRs"><a href="#ISRs" class="headerlink" title="ISRs"></a>ISRs</h3><p>每个 partition 有一个 leader 和多个 follower（副本因子&gt;1）,其中日志状态保持和 leader 同步的 follower 集合被称为 ISRs，于其对应的有落后于 leader 日志状态的副本集合称为 OSRs，ISRs + OSRs = AR（All Replication）</p><hr><h2 id="一、为什么不使用Quorum策略？"><a href="#一、为什么不使用Quorum策略？" class="headerlink" title="一、为什么不使用Quorum策略？"></a>一、为什么不使用Quorum策略？</h2><h3 id="Quorum-机制"><a href="#Quorum-机制" class="headerlink" title="Quorum 机制"></a>Quorum 机制</h3><p>Quorum 机制对集群节点数量有要求，如果需要容忍N个节点故障，集群整体需要2N+1个节点；Quorum 主要能应对集群出现 脑裂问题</p><h3 id="ISRs-机制"><a href="#ISRs-机制" class="headerlink" title="ISRs 机制"></a>ISRs 机制</h3><p>ISR 机制，如果要容忍N个节点故障，只需保证 ISR 中存在N+1个节点；ISR通过zookeeper来避免来保证leader的唯一</p><h2 id="二、数据一致性如何保证？"><a href="#二、数据一致性如何保证？" class="headerlink" title="二、数据一致性如何保证？"></a>二、数据一致性如何保证？</h2><ol><li>关闭unclean，保证新的Leader副本，是从ISRs集合中进行选举  </li><li>设置ISRs的最小副本数 &gt;= 2（ISR中包括Leader副本）</li></ol><p>以下两类特殊的数据一致性问题，通过引入Leader Epoch机制解决（类似Raft的Terms）</p><h3 id="日志丢失问题"><a href="#日志丢失问题" class="headerlink" title="日志丢失问题"></a>日志丢失问题</h3><p><img src="http://8090lambert.cn/images/blog/kafka/log_miss.jpg" alt="log_miss"></p><ol><li>某一个时刻，Leader A收到 producer 的消息m2，并成功写入本地Page Cache中。Follower B拉取到m2，写入Page Cache但未刷盘。同步给Leader A HW=2，Leader A更新自身HW=2。此时，A、B同时崩溃  </li><li>B先恢复，并成为leader 节点，A 恢复后成为follower，HW=2所以不需要截断自身的日志。  </li><li>Leader B 收到了 producer 的m3消息，此时offset=1的日志，两个节点出现了不一致现象。（A=m2, B=m3）</li></ol><h3 id="引入Leader-Epoch解决"><a href="#引入Leader-Epoch解决" class="headerlink" title="引入Leader Epoch解决"></a>引入Leader Epoch解决</h3><p>两个问题产生的原因，都是follower节点在异常情况恢复后，通过自身的HW来决定日志的状态。其实，上面分析的场景和raft中的日志恢复类似，raft中的follower是和leader的日志不一致时，会以leader的日志为准进行日志恢复。而raft中的日志恢复很重要的一点是follower根据leader任期号进行日志比对，快速进行日志恢复，follower需要判断新旧leader的日志（可能由于分区等问题，短暂出现2个leader的情况），以最新leader的数据为准。<br>这里的leader epoch和raft中的 term 类似，用一个严格单调递增的id来标志。follower每次奔溃重启后，都需要去leader那边确认下当前leader的日志是从哪个offset开始的。  </p><p>介绍这几个概念各自的用处：</p><ul><li>Leader Epoch：Leader纪元，单调递增的int值。</li><li>Leader Epoch Start Offset：Leader的第一个日志偏移，也标志了旧Leader最后一条日志的偏移</li><li>Leader Epoch Request：Follower向Leader发送请求时，Leader会判断当前纪元是否是自身的epoch，如果是则返回自己的LEO，否则返回下一个纪元的Leader Epoch Start Offset，follower通过这个值做日志的截断处理<blockquote><p>日志截断仅会发生在 follower 节点上</p></blockquote></li></ul><h2 id="三、如何保证高性能？"><a href="#三、如何保证高性能？" class="headerlink" title="三、如何保证高性能？"></a>三、如何保证高性能？</h2><ul><li>多副本：多副本机制，带来多节点的并发能力。由于内部的优先副本分配策略，可以尽可能的保证做到Leader副本的负载均衡（Leader副本被均匀的分配在不同的broker节点）。</li><li>磁盘的顺序读写：由于topic的每个partition的消息是不可变的，新消息写入时，不断追加到partition日志的末尾。因此，可以利用磁盘顺序写的特点。数据的删除，因为每个log 被划分为多个segment，每个segment对应一个物理文件，通过删除文件的方式清理partition内的数据。</li><li>利用Page Cache：引入Page Cache，由OS来决定刷盘的时机。Page Cache的使用，可以将多个非连续、小块写操作合并，提高磁盘的写入效率，同时减少对文件系统的频繁调用。Kafka本身是Java语言栈，如果使用堆内存做Cache，在kafka进程重启时，数据会丢失，而且堆内内存的占用比数据本身占用的内存大（因为有结构、辅助字段等必要信息存储）。</li><li>零拷贝技术：生产者写入数据时，通过mmap提升写数据消息日志落盘的性能；消费者读取消息时。</li><li>批量处理：在很多情况下，系统的瓶颈不是CPU或磁盘，而是网络IO传输。kafka的producer在收到消息时，在积累足够多的消息或等待足够长的时间后，再发送到broker，批处理分摊了网络传输开销，提升带宽利用率，类似 TCP 的 Nagle 算法。</li><li>数据压缩：合并消息，减少数据体积</li></ul><h2 id="四、如何保证消息的幂等性和顺序性？"><a href="#四、如何保证消息的幂等性和顺序性？" class="headerlink" title="四、如何保证消息的幂等性和顺序性？"></a>四、如何保证消息的幂等性和顺序性？</h2><h3 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h3><p>一般消息系统需要具备三种常见的语义，at most once(至多一次)，at least once(至少一次)，exactly once(恰好一次)，大多数系统都可以做到at most once 和 at least once。  </p><ol><li>PID (producer ID)，用来表示每个 producer 的唯一性（在开启幂等时，每次发送给 broker 时消息中都携带）  </li><li>sequence numbers，producer 发送给 broker 的每条消息都会带响应的 sequence number，逐次递增<br><strong>在配置 enable.idempotence = true 时(开启幂等配置)，通过 pid + sequence number，保证了同一个 producer 在 topic-partition 维度的幂等性</strong></li></ol><h3 id="顺序性"><a href="#顺序性" class="headerlink" title="顺序性"></a>顺序性</h3><p>kafka producer 采用异步发送机制。KafkaProducer.send(ProducerRecord) 方法仅仅是把这条消息放入一个缓存中(即RecordAccumulator，本质上使用了队列来缓存记录)，同时后台的IO线程会不断扫描该缓存区，将满足条件的消息封装到某个 batch 中然后发送出去。在这个过程中有一个数据丢失的窗口：若IO线程发送之前 producer 挂掉了，累积在 Accumulator 中的数据的确有可能会丢失。而且当设置 max.in.flight.requests.per.connection &gt; 1 并且 retries &gt;= 1 时，发送到同一个 topic-partition 中的消息中，可能由于网络等其他问题，导致实际顺序与写入顺序不一致，max.in.flight.requests.per.connection = 1 保证有序。<br><strong>在开启了幂等的情况下，可以保证写入的顺序性</strong></p><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><h4 id="未设置幂等时"><a href="#未设置幂等时" class="headerlink" title="未设置幂等时"></a>未设置幂等时</h4><p><img src="http://8090lambert.cn/images/blog/kafka/unidempotence.jpg" alt="unidempotence"></p><h4 id="设置幂等时"><a href="#设置幂等时" class="headerlink" title="设置幂等时"></a>设置幂等时</h4><p><img src="http://8090lambert.cn/images/blog/kafka/idempotence.jpg" alt="idempotence"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h2&gt;&lt;h3 id=&quot;HW（HighWater）&quot;&gt;&lt;a href=&quot;#HW（HighWater）&quot; class=&quot;headerlink
      
    
    </summary>
    
    
      <category term="kafka" scheme="http://8090lambert.cn/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Golang的interface探究</title>
    <link href="http://8090lambert.cn/2019/10/11/Golang%E7%9A%84interface%E6%8E%A2%E7%A9%B6/"/>
    <id>http://8090lambert.cn/2019/10/11/Golang的interface探究/</id>
    <published>2019-10-11T10:15:49.000Z</published>
    <updated>2021-05-09T14:50:16.593Z</updated>
    
    <content type="html"><![CDATA[<p>golang被诟病最多的，没有泛型应该算一个。作为强类型语言来说，没有泛型很多时候在业务开发上会有些不适应，但是它有个<code>interface</code><br>类型，被很多人拿来当泛型玩，如果你了解它的原理也是没问题的。<br>但是你真的了解吗？</p><h3 id="Interface"><a href="#Interface" class="headerlink" title="Interface"></a>Interface</h3><p><code>golang</code> 中的<code>interface</code>，可以将任意类型的变量赋予它。常见的我们区分两种，一种就是<code>struct</code>类型的，因为<code>struct</code><br>可能会有<code>func</code>；另外一种，就是非结构体的普通类型（下面提到的普通类型，都是指代除<code>struct</code>外的类型）</p><h4 id="eface"><a href="#eface" class="headerlink" title="eface"></a>eface</h4><pre><code>  1 package main  2  3 import &quot;fmt&quot;  4  5 func main() {  6     var x int  7     var y interface{}  8     x = 1  9     y = x 10     fmt.Println(y) 11 }</code></pre><p>当我们把<code>int</code>类型的变量赋值给<code>interface</code>类型时，会发生什么：</p><pre><code>TEXT main.main(SB) /home/xiaoju/gomodule/runtime/main.go    main.go:5    0x4a23a0    64488b0c25f8ffffff    mov rcx, qword ptr fs:[0xfffffff8]    main.go:5    0x4a23a9    488d4424f8        lea rax, ptr [rsp-0x8]    main.go:5    0x4a23ae    483b4110        cmp rax, qword ptr [rcx+0x10]    main.go:5    0x4a23b2    0f86c7000000        jbe 0x4a247f=&gt;    main.go:5    0x4a23b8*    4881ec88000000        sub rsp, 0x88    main.go:5    0x4a23bf    4889ac2480000000    mov qword ptr [rsp+0x80], rbp    main.go:5    0x4a23c7    488dac2480000000    lea rbp, ptr [rsp+0x80]    main.go:6    0x4a23cf    48c744243000000000    mov qword ptr [rsp+0x30], 0x0    main.go:7    0x4a23d8    0f57c0            xorps xmm0, xmm0    main.go:7    0x4a23db    0f11442448        movups xmmword ptr [rsp+0x48], xmm0    main.go:8    0x4a23e0    48c744243001000000    mov qword ptr [rsp+0x30], 0x1    main.go:9    0x4a23e9    48c7042401000000    mov qword ptr [rsp], 0x1    main.go:9    0x4a23f1    e89a70f6ff        call $runtime.convT64</code></pre><p>追到<code>runtime</code>的<code>convT64</code>方法，一探究竟。</p><pre><code>// type uint64InterfacePtr uint64// var uint64Eface interface{} = uint64InterfacePtr(0)// var uint64Type *_type = (*eface)(unsafe.Pointer(&amp;uint64Eface))._typefunc convT64(val uint64) (x unsafe.Pointer) {    if val == 0 {        x = unsafe.Pointer(&amp;zeroVal[0])    } else {        x = mallocgc(8, uint64Type, false)        *(*uint64)(x) = val    }    return}</code></pre><p>这个方法返回了 <code>val</code> 的指针，其中<code>uint64Type</code>就是一个 0 值的<code>uint64</code>指针。有个疑问，这里<code>uint64Type</code>定义时，<code>eface</code> 是什么：</p><pre><code>type eface struct {    _type *_type    data  unsafe.Pointer}</code></pre><p>这个结构体，恰好满足了，对于普通类型转换<code>interface</code>，或者说是将普通类型赋值给<code>interface</code>所必须的两个字段，当前类型的<code>type</code><br>和<code>值</code>（这里貌似有点绕口）。真实的是，<code>eface</code>确实就是表示这类<code>interface</code>的结构体，在<code>runtime</code>中，还能看到其他普通类型的转换，<br><code>convTslice</code>、<code>convTstring</code>、<code>convT64</code>、<code>convT32</code>等其他几个方法。</p><h4 id="iface"><a href="#iface" class="headerlink" title="iface"></a>iface</h4><p>如果是一个拥有<code>func</code>的<code>struct</code>类型的变量，赋值给另一个<code>interface</code>，这类的<code>interface</code>在底层是怎么存的呢。如下所示：</p><pre><code>  1 package main                                                                                                                                                                                                                  2   3 import &quot;fmt&quot;  4   5 type Human interface{ Introduce() string }  6   7 type Bob struct{ Human }  8   9 func (b Bob) Introduce() string { return &quot;Name: Bob&quot; } 10  11 func main() { 12     var y Human 13     x := Bob{} 14     y = x 15     fmt.Println(y) 16 }</code></pre><pre><code>TEXT main.main(SB) /Users/such/gomodule/runtime/main.go        main.go:11      0x10b71a0       65488b0c2530000000              mov rcx, qword ptr gs:[0x30]        main.go:11      0x10b71a9       488d4424d0                      lea rax, ptr [rsp-0x30]        main.go:11      0x10b71ae       483b4110                        cmp rax, qword ptr [rcx+0x10]        main.go:11      0x10b71b2       0f860f010000                    jbe 0x10b72c7        ...省略部分指令        main.go:14      0x10b7202       e84921f5ff                      call $runtime.convT2I</code></pre><p>看汇编代码，在 <code>16</code> 行时，调用了<code>runtime.convT2I</code>，这个方法返回的类型是<code>iface</code></p><pre><code>func convT2I(tab *itab, elem unsafe.Pointer) (i iface) {    t := tab._type    if raceenabled {        raceReadObjectPC(t, elem, getcallerpc(), funcPC(convT2I))    }    if msanenabled {        msanread(elem, t.size)    }    x := mallocgc(t.size, t, true)    typedmemmove(t, x, elem)    i.tab = tab    i.data = x    return}</code></pre><p><code>itab</code>包括具体值的<code>type</code>和 interface 的<code>type</code>，还有其他字段</p><pre><code>type itab struct {    inter *interfacetype    // 接口定义的类型    _type *_type            // 接口指向具体值的 type    hash  uint32            // 类型的hash值    _     [4]byte    fun   [1]uintptr        // 判断接口是否实现所有方法（下面会讲到）}</code></pre><p>在<code>itab</code>结构体的<code>init</code>方法中，是所有字段的初始化，重点看这个方法：</p><pre><code>func (m *itab) init() string {    inter := m.inter    typ := m._type    x := typ.uncommon()    // 在 interfacetype 的结构体中，mhdr 存着所有需要实现的方法的    // 结构体切片 []imethod，都是按照方法名的字典序排列的，其中：    // ni 是全量的方法（所有要实现的方法）的个数    // nt 是已实现的方法的个数    ni := len(inter.mhdr)    nt := int(x.mcount)    xmhdr := (*[1 &lt;&lt; 16]method)(add(unsafe.Pointer(x), uintptr(x.moff)))[:nt:nt]    j := 0    methods := (*[1 &lt;&lt; 16]unsafe.Pointer)(unsafe.Pointer(&amp;m.fun[0]))[:ni:ni]    var fun0 unsafe.Pointerimethods:    for k := 0; k &lt; ni; k++ {   // 从第一个开始，逐个对比        i := &amp;inter.mhdr[k]        itype := inter.typ.typeOff(i.ityp)        name := inter.typ.nameOff(i.name)        iname := name.name()        ipkg := name.pkgPath()        if ipkg == &quot;&quot; {            ipkg = inter.pkgpath.name()        }        for ; j &lt; nt; j++ {            t := &amp;xmhdr[j]            tname := typ.nameOff(t.name)            // 比较已实现方法的 type 和 name 是否一致            if typ.typeOff(t.mtyp) == itype &amp;&amp; tname.name() == iname {                pkgPath := tname.pkgPath()                if pkgPath == &quot;&quot; {                    pkgPath = typ.nameOff(x.pkgpath).name()                }                if tname.isExported() || pkgPath == ipkg {                    if m != nil {                        // 计算每个 method 对应代码块的内存地址                        ifn := typ.textOff(t.ifn)                        if k == 0 {                            fun0 = ifn // we&#39;ll set m.fun[0] at the end                        } else {                            methods[k] = ifn                        }                    }                    continue imethods                }            }        }        // 如果没有找到，将 func[0] 设置为0，返回该实现的 method 的 name        m.fun[0] = 0        return iname    }    // 第一个方法的 ptr 和 type 的 hash    m.fun[0] = uintptr(fun0)    m.hash = typ.hash    return &quot;&quot;}</code></pre><h4 id="itabTable"><a href="#itabTable" class="headerlink" title="itabTable"></a>itabTable</h4><p>还有一种将<code>interface</code>类型的实现，赋值给另外一个<code>interface</code>：</p><pre><code>TEXT main.main(SB) /Users/such/gomodule/runtime/main.go    ...省略部分指令    main.go:18    0x10b71f5    488d842480000000        lea rax, ptr [rsp+0x80]    main.go:18    0x10b71fd    4889442408            mov qword ptr [rsp+0x8], rax    main.go:18    0x10b7202    e84921f5ff            call $runtime.convT2I</code></pre><pre><code>func convI2I(inter *interfacetype, i iface) (r iface) {    tab := i.tab    if tab == nil {        return    }    if tab.inter == inter {        r.tab = tab        r.data = i.data        return    }    r.tab = getitab(inter, tab._type, false)    r.data = i.data    return}</code></pre><p>通过前面的分析，我们又知道， <code>iface</code> 是由 <code>tab</code> 和 <code>data</code> 两个字段组成。所以，实际上 <code>convI2I</code> 函数真正要做的事，<br>找到新 <code>interface</code> 的 <code>tab</code> 和 <code>data</code>，就大功告成了。在<code>iface.go</code> 文件头部定义了<code>itabTable</code>全局哈希表存所有<code>itab</code>，<br>其实就是<code>空间换时间</code>的思想。<br><code>itabTable</code>是<code>itabTableType</code>结构体（我的golang版本是1.12.7）</p><pre><code>type itabTableType struct {    size    uintptr             // 大小，2的幂    count   uintptr             // 已有的 itab entry 个数    entries [itabInitSize]*itab // 保存 itab entry}</code></pre><h5 id="getitab"><a href="#getitab" class="headerlink" title="getitab"></a>getitab</h5><p><code>getitab</code>是查找<code>itab</code>的方法</p><pre><code>func getitab(inter *interfacetype, typ *_type, canfail bool) *itab {    if len(inter.mhdr) == 0 {        throw(&quot;internal error - misuse of itab&quot;)    }    if typ.tflag&amp;tflagUncommon == 0 {        if canfail {            return nil        }        name := inter.typ.nameOff(inter.mhdr[0].name)        panic(&amp;TypeAssertionError{nil, typ, &amp;inter.typ, name.name()})    }    var m *itab    t := (*itabTableType)(atomic.Loadp(unsafe.Pointer(&amp;itabTable)))    if m = t.find(inter, typ); m != nil {        goto finish    }    // Not found.  Grab the lock and try again.    lock(&amp;itabLock)    if m = itabTable.find(inter, typ); m != nil {        unlock(&amp;itabLock)        goto finish    }    // Entry doesn&#39;t exist yet. Make a new entry &amp; add it.    m = (*itab)(persistentalloc(unsafe.Sizeof(itab{})+uintptr(len(inter.mhdr)-1)*sys.PtrSize, 0, &amp;memstats.other_sys))    m.inter = inter    m._type = typ    m.init()    itabAdd(m)    unlock(&amp;itabLock)finish:    if m.fun[0] != 0 {        return m    }    if canfail {        return nil    }    // 如果不是 &quot;_, ok := &quot; 类型的断言，会有panic    panic(&amp;TypeAssertionError{concrete: typ, asserted: &amp;inter.typ, missingMethod: m.init()})}</code></pre><p>会调用<code>find</code>方法，根据<code>interfacetype</code>和<code>_type</code>的 hash 值，在<code>itabTable</code>中查找，找到的话直接返回；<br>否则，生成新的<code>itab</code>，加入 <code>itabTable</code> 中。有个问题，就是为什么第一次不加锁找，而第二次加锁？<br>我个人的理解是：<code>首先：应该还是想避免锁的开销（之前在滴滴有幸听过曹大分享【内存重排】，对常用package在concurrently时，锁引起的问题做了一些分析。），而第二次加锁，我觉得更多的是在未找到 itab 后，会新生成一个 itab 写入全局哈希表中，如果有其他协程在查询时，也未找到，可以并发安全写入。</code></p><h5 id="itabAdd"><a href="#itabAdd" class="headerlink" title="itabAdd"></a>itabAdd</h5><pre><code>func itabAdd(m *itab) {    if getg().m.mallocing != 0 {        throw(&quot;malloc deadlock&quot;)    }    t := itabTable    if t.count &gt;= 3*(t.size/4) { // 75% load factor        t2 := (*itabTableType)(mallocgc((2+2*t.size)*sys.PtrSize, nil, true))        t2.size = t.size * 2        iterate_itabs(t2.add)        if t2.count != t.count {            throw(&quot;mismatched count during itab table copy&quot;)        }        atomicstorep(unsafe.Pointer(&amp;itabTable), unsafe.Pointer(t2))        t = itabTable    }    t.add(m)}</code></pre><p><code>itabAdd</code> 是添加<code>itab</code>加入<code>itabTable</code>的方法。既然是<code>hash</code>表，就一定会发生<code>扩容</code>。每次都<br>是<code>2</code>的倍数的增长，创建新的 <code>itabTable</code> 再<code>原子</code>的替换。在 <code>iterate_itabs</code>（复制）时，并<br>未加锁，这里不是协程安全的，而是在添加前，在<code>getitab</code>方法中有锁的操作，会等待复制完成。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;golang被诟病最多的，没有泛型应该算一个。作为强类型语言来说，没有泛型很多时候在业务开发上会有些不适应，但是它有个&lt;code&gt;interface&lt;/code&gt;&lt;br&gt;类型，被很多人拿来当泛型玩，如果你了解它的原理也是没问题的。&lt;br&gt;但是你真的了解吗？&lt;/p&gt;
&lt;h3 
      
    
    </summary>
    
    
      <category term="go" scheme="http://8090lambert.cn/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>Redis5.0 RDB文件超详细解析</title>
    <link href="http://8090lambert.cn/2019/05/26/Redis5.0%20RDB%E6%96%87%E4%BB%B6%E8%B6%85%E8%AF%A6%E7%BB%86%E8%A7%A3%E6%9E%90/"/>
    <id>http://8090lambert.cn/2019/05/26/Redis5.0 RDB文件超详细解析/</id>
    <published>2019-05-26T12:14:26.000Z</published>
    <updated>2021-05-09T14:50:16.596Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis-RDB介绍"><a href="#Redis-RDB介绍" class="headerlink" title="Redis RDB介绍"></a>Redis RDB介绍</h2><p><code>RDB</code> 是 Redis 将 server 端的内存中的 k/v 对以二进制的方式，持久化存储的一种文件形式。<br><em>文件中，一般会以 对象的长度+对象 的格式来存储</em>，只要根据这个格式，就能渐进的遍历整个文件。<br><code>Redis</code> 还支持开启 <code>LZF</code> 的压缩算法，可以牺牲CPU时间，来减少 <code>RDB</code> 文件的大小；如果开启<code>LZF</code>并且超过<code>20</code>个bytes时，<br>会将压缩后的字符写入文件。</p><h3 id="RDB文件格式"><a href="#RDB文件格式" class="headerlink" title="RDB文件格式"></a>RDB文件格式</h3><pre><code>➜  go-redis-parser od -A x -t x1c -v ./teststub/dumpV9.rdb000000  52  45  44  49  53  30  30  30  39  fa  09  72  65  64  69  73         R   E   D   I   S   0   0   0   9 372  \t   r   e   d   i   s000010  2d  76  65  72  05  35  2e  30  2e  35  fa  0a  72  65  64  69         -   v   e   r 005   5   .   0   .   5 372  \n   r   e   d   i000020  73  2d  62  69  74  73  c0  40  fa  05  63  74  69  6d  65  c2         s   -   b   i   t   s 300   @ 372 005   c   t   i   m   e 302000030  71  8a  8d  5d  fa  08  75  73  65  64  2d  6d  65  6d  c2  30         q 212 215   ] 372  \b   u   s   e   d   -   m   e   m 302   0000040  e0  0f  00  fa  0c  61  6f  66  2d  70  72  65  61  6d  62  6c       340 017  \0 372  \f   a   o   f   -   p   r   e   a   m   b   l000050  65  c0  00  fe  00  fb  06  00  f9  00  00  01  73  01  61  f9         e 300  \0 376  \0 373 006  \0 371  \0  \0 001   s 001   a 371000060  03  0e  02  6c  69  01  11  11  00  00  00  0d  00  00  00  02       003 016 002   l   i 001 021 021  \0  \0  \0  \r  \0  \0  \0 002000070  00  00  01  61  03  01  62  ff  f9  00  02  03  73  65  74  02        \0  \0 001   a 003 001   b 377 371  \0 002 003   s   e   t 002000080  01  62  01  61  f9  00  0f  06  73  74  72  65  61  6d  01  10       001   b 001   a 371  \0 017 006   s   t   r   e   a   m 001 020000090  00  00  01  6d  70  b5  4a  7e  00  00  00  00  00  00  00  00        \0  \0 001   m   p 265   J   ~  \0  \0  \0  \0  \0  \0  \0  \00000a0  40  52  52  00  00  00  18  00  03  01  00  01  02  01  84  6e         @   R   R  \0  \0  \0 030  \0 003 001  \0 001 002 001 204   n0000b0  61  6d  65  05  83  61  67  65  04  00  01  02  01  00  01  00         a   m   e 005 203   a   g   e 004  \0 001 002 001  \0 001  \00000c0  01  87  4c  61  6d  62  65  72  74  08  1d  01  05  01  02  01       001 207   L   a   m   b   e   r   t  \b 035 001 005 001 002 0010000d0  f2  33  8c  00  04  00  01  84  4a  61  63  6b  05  1a  01  05       362   3 214  \0 004  \0 001 204   J   a   c   k 005 032 001 0050000e0  01  02  01  f2  9c  ad  00  04  00  01  83  54  6f  6d  04  1e       001 002 001 362 234 255  \0 004  \0 001 203   T   o   m 004 0360000f0  01  05  01  ff  03  81  00  00  01  6d  70  b5  f8  1a  00  01       001 005 001 377 003 201  \0  \0 001   m   p 265 370 032  \0 001000100  05  67  72  6f  75  70  00  00  00  00  f9  00  0c  04  7a  73       005   g   r   o   u   p  \0  \0  \0  \0 371  \0  \f 004   z   s000110  65  74  15  15  00  00  00  12  00  00  00  04  00  00  01  61         e   t 025 025  \0  \0  \0 022  \0  \0  \0 004  \0  \0 001   a000120  03  f2  02  01  62  03  f3  ff  f9  03  0d  01  68  11  11  00       003 362 002 001   b 003 363 377 371 003  \r 001   h 021 021  \0000130  00  00  0d  00  00  00  02  00  00  01  61  03  01  61  ff  ff        \0  \0  \r  \0  \0  \0 002  \0  \0 001   a 003 001   a 377 377000140  0e  e0  f7  31  2f  37  16  df       016 340 367   1   /   7 026 337000148</code></pre><p>这是一个 <code>version 9</code> 的 RDB 文件</p><h3 id="魔数-Magic-Number"><a href="#魔数-Magic-Number" class="headerlink" title="魔数 Magic Number"></a>魔数 Magic Number</h3><p>文件前 9 个字节是一个 <code>魔数</code>，5 个字节<code>REDIS</code> 和 4 个字节的版本号 <code>009</code>。</p><h3 id="辅助字段-Aux-Fields"><a href="#辅助字段-Aux-Fields" class="headerlink" title="辅助字段 Aux Fields"></a>辅助字段 Aux Fields</h3><p>通用字符串字段，用于向RDB添加状态，<code>Version 7</code> 加入的，向后兼容。AUX字段由两个字符串组成：<code>键和值</code>。<br>整理了下，除了 <code>lua</code>，有这些字段：</p><ul><li>redis-ver：版本号</li><li>redis-bits：OS Arch</li><li>ctime：RDB文件创建时间</li><li>used-mem：使用内存大小</li><li>repl-stream-db：在server.master客户端中选择的数据库</li><li>repl-id：当前实例 replication ID</li><li>repl-offset：当前实例复制的偏移量</li></ul><h3 id="数据库索引"><a href="#数据库索引" class="headerlink" title="数据库索引"></a>数据库索引</h3><p><img src="https://raw.githubusercontent.com/8090Lambert/material/master/rdb-select.jpg" alt=""><br>fe(0xfe)，fb(0xfb)是 10 进制的 254 和 251，在 RDB 分别对应着，<code>SELECT_DB</code>和<code>RESIZE_DB</code>。 每一个<br><code>SELECTDB</code>后都会紧跟着<code>RESIZEDB</code>，后者表示的是当前数据库<code>hashtable</code>键大小的提示，每次切换数据库时提前读到，避免不必要的<code>rehash</code>。</p><h3 id="数据库键值对"><a href="#数据库键值对" class="headerlink" title="数据库键值对"></a>数据库键值对</h3><p>接下来，读到的就是<code>Redis</code>中所有存储着的<code>K/V</code>对：<br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/rdb-datatype.jpg" alt="类型对照表"></p><h4 id="LFU-LRU-Idle"><a href="#LFU-LRU-Idle" class="headerlink" title="LFU/LRU Idle"></a>LFU/LRU Idle</h4><p>后面f9(0xf9)是 10 进制的 249，是表示 key 对象的<code>lfu_idle</code>，这个字段是只有开启<code>maxmemory-policy</code>并且设置为<code>volatile-lfu</code>或<code>allkeys-lfu</code>才会写入文件。<br><code>LRU</code>的同理，不过前缀是 f8(0xf8)，<code>maxmemory-policy</code>要设置为：<code>allkeys-lru</code>和<code>volatile-lru</code>。</p><h4 id="String结构"><a href="#String结构" class="headerlink" title="String结构"></a>String结构</h4><p>00(0x00)是 10 进制的 0，表示<code>string</code>类型的对象，01 指<code>key</code>是一个字节长度：“s”, <code>value</code> 也是一个字节长度：“a”,</p><h4 id="List结构"><a href="#List结构" class="headerlink" title="List结构"></a>List结构</h4><p>0e(0x0e)是 10 进制的 14，表示<code>list</code>类型的对象（在3.2版本之前，是由<code>ziplist</code>和<code>linkedlist</code>结构保存，之后存储是<code>quicklist</code>）；2个字节长度的<code>key</code>：”li”,<br>下来分别是一个长度的<code>items</code>：”a” 和 “b”</p><h4 id="Set结构"><a href="#Set结构" class="headerlink" title="Set结构"></a>Set结构</h4><p>2，表示<code>Set</code>类型对象，3个长度 “set”，两个<code>members</code>：”a” 和 “b”</p><h4 id="Stream结构"><a href="#Stream结构" class="headerlink" title="Stream结构"></a>Stream结构</h4><p>继 <code>module</code> 之后，redis 在 5.0 增加了新的数据类型 <code>Stream</code>，不了解的同学可以Google下，很多介绍的文章。根据作者自己说，它也是充分借鉴了 <code>kafka</code> 的设计思想，在已有 <code>list</code> 的基础上增加了另一种流式类型。<br>基本。<br>0f(0x0f)是 10 进制的 15，是<code>Stream</code>类型的对象，5个长度的<code>key</code>:”stream”。然后是 <code>StreamId</code>结构体，<br><code>6d  70  b5  4a  7e</code>分别是 10 进制的（109 112 181 74 126），二进制 <code>01101101 01110000 10110101 01001010 01111110</code>，因为毫秒是<code>uint</code>，加上符号位即：<code>1 01101101 01110000 10110101 01001010 01111110</code> 对应如图所示:<br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20190927132103.png" alt=""><br><code>first-entry</code> 恰好是创建<code>stream</code>的毫秒数，后面跟着8位的随机数<code>0</code>；然后是<code>entry</code>结构，每个<code>entry</code>结构前面，也会有和<code>streamId</code>相同的<code>messageId</code>，这里就不具体逐位分析了。长度是 3，第一个字段：”name”;<br>第二个字段：”age”，3个<code>entry</code>分别是<code>name:Lambert,age:29</code>、<code>name:Jack,age:26</code>、<code>name:Tom,age:30</code>；下来是消费组<code>Group</code>，名为：<code>group</code> 的消费组，因为没有任何消费，所以偏移量<code>pending entry list</code>都是<code>0</code>。</p><h4 id="ZSet结构"><a href="#ZSet结构" class="headerlink" title="ZSet结构"></a>ZSet结构</h4><p>0c 是 10 进制的 12，以<code>ziplist</code>结构存储的<code>Sortedset</code>类型，4个长度的<code>key</code>：”zset”，接下来的 4 表示：4个元素，<code>zset</code>会将<code>member</code>和<code>score</code>一起保存，所以，就是2组<code>members</code>；分别是：<code>{memeber:&quot;a&quot;,score:1}</code>、<code>{member:&quot;b&quot;,score:2}</code>。</p><h4 id="Hash结构"><a href="#Hash结构" class="headerlink" title="Hash结构"></a>Hash结构</h4><p>0d(13) 是<code>RDB_TYPE_HASH_ZIPLIST</code>，表示是<code>ziplist</code>存储的<code>hash</code>类型数据，1 个长度的key：”h”。<br><code>key</code>后面的2，存着<code>hash</code>结构的<code>field</code>和<code>value</code>；在 field 和 value 前面的 1，分别是指各自的长度，都是 “a”</p><h3 id="文件EOF"><a href="#文件EOF" class="headerlink" title="文件EOF"></a>文件EOF</h3><p>ff(255) EOF，在所有数据写完结束后，会以一个EOF结尾</p><h3 id="CheckSum"><a href="#CheckSum" class="headerlink" title="CheckSum"></a>CheckSum</h3><p>从<code>Version 5</code> 开始，如果在配置文件中开启<code>rdbchecksum yes</code>，会在<code>RDB</code>文件的结尾处，用 8 个字节保存通过<code>CRC64</code>计算整个文件内容的检验和。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis-RDB介绍&quot;&gt;&lt;a href=&quot;#Redis-RDB介绍&quot; class=&quot;headerlink&quot; title=&quot;Redis RDB介绍&quot;&gt;&lt;/a&gt;Redis RDB介绍&lt;/h2&gt;&lt;p&gt;&lt;code&gt;RDB&lt;/code&gt; 是 Redis 将 server 
      
    
    </summary>
    
    
      <category term="redis" scheme="http://8090lambert.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>从底层理解 Golang 的 map 实现</title>
    <link href="http://8090lambert.cn/2019/04/30/%E4%BB%8E%E5%BA%95%E5%B1%82%E7%90%86%E8%A7%A3%20Golang%20%E7%9A%84%20map%20%E5%AE%9E%E7%8E%B0/"/>
    <id>http://8090lambert.cn/2019/04/30/从底层理解 Golang 的 map 实现/</id>
    <published>2019-04-30T09:34:15.000Z</published>
    <updated>2021-05-09T14:50:16.598Z</updated>
    
    <content type="html"><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>golang 中的 <code>map</code> 就是常用的 <a href="https://en.wikipedia.org/wiki/Hash_table" target="_blank" rel="noopener">hashtable</a>，底层实现由 <code>hmap</code>，维护着若干个 <code>bucket</code> 数组，通常每个 <code>bucket</code> 保存着8组kv对，如果<br>超过8个(发生hash冲突时)，会在 <code>extra</code> 字段结构体中的 <code>overflow</code> ，使用链地址法一直扩展下去。<br>先看下 <code>hmap</code> 结构体：</p><pre><code>type hmap struct {    count     int // 元素的个数    flags     uint8 // 标记读写状态，主要是做竞态检测，避免并发读写    B         uint8  // 可以容纳 2 ^ N 个bucket    noverflow uint16 // 溢出的bucket个数    hash0     uint32 // hash 因子    buckets    unsafe.Pointer // 指向数组buckets的指针    oldbuckets unsafe.Pointer // growing 时保存原buckets的指针    nevacuate  uintptr        // growing 时已迁移的个数    extra *mapextra}type mapextra struct {    overflow    *[]*bmap    oldoverflow *[]*bmap    nextOverflow *bmap}</code></pre><p><code>bucket</code> 的结构体：</p><pre><code>// A bucket for a Go map.type bmap struct {    // tophash generally contains the top byte of the hash value    // for each key in this bucket. If tophash[0] &lt; minTopHash,    // tophash[0] is a bucket evacuation state instead.    tophash [bucketCnt]uint8    // 记录着每个key的高8个bits    // Followed by bucketCnt keys and then bucketCnt elems.    // NOTE: packing all the keys together and then all the elems together makes the    // code a bit more complicated than alternating key/elem/key/elem/... but it allows    // us to eliminate padding which would be needed for, e.g., map[int64]int8.    // Followed by an overflow pointer.}</code></pre><p>其中 <code>kv</code> 对是按照 key0/key1/key2/…val0/val1/val2/… 的格式排列，虽然在保存上面会比key/value对更复杂一些，但是避免了因为cpu要求固定长度读取，字节对齐，造成的空间浪费。  </p><h2 id="初始化-amp-amp-插入"><a href="#初始化-amp-amp-插入" class="headerlink" title="初始化 &amp;&amp; 插入"></a>初始化 &amp;&amp; 插入</h2><pre><code>package mainfunc main() {    a := map[string]int{&quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 3}    _ = a[&quot;one&quot;]}</code></pre><p>初始化3个key/value的map</p><pre><code>TEXT main.main(SB) /Users/such/gomodule/runtime/main.go=&gt;      main.go:3       0x10565fb*      4881ec70010000          sub rsp, 0x170        main.go:3       0x1056602       4889ac2468010000        mov qword ptr [rsp+0x168], rbp        main.go:3       0x105660a       488dac2468010000        lea rbp, ptr [rsp+0x168]        main.go:4       0x105664b       488b6d00                mov rbp, qword ptr [rbp]        main.go:4       0x105666d       e8de9cfeff              call $runtime.fastrand        main.go:4       0x1056672       488b442450              mov rax, qword ptr [rsp+0x50]        main.go:4       0x1056677       8400                    test byte ptr [rax], al        main.go:4       0x10566c6       48894c2410              mov qword ptr [rsp+0x10], rcx        main.go:4       0x10566cb       4889442418              mov qword ptr [rsp+0x18], rax        main.go:4       0x10566d0       e80b8efbff              call $runtime.mapassign_faststr        main.go:4       0x1056726       48894c2410              mov qword ptr [rsp+0x10], rcx        main.go:4       0x105672b       4889442418              mov qword ptr [rsp+0x18], rax        main.go:4       0x1056730       e8ab8dfbff              call $runtime.mapassign_faststr        main.go:4       0x1056786       4889442410              mov qword ptr [rsp+0x10], rax        main.go:4       0x105678b       48894c2418              mov qword ptr [rsp+0x18], rcx        main.go:4       0x1056790       e84b8dfbff              call $runtime.mapassign_faststr</code></pre><p>(省略了部分) 可以看出来，声明时连续调用三次 <code>call $runtime.mapassign_faststr</code> 添加键值对</p><pre><code>func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {    if h == nil {        panic(plainError(&quot;assignment to entry in nil map&quot;))    }    if raceenabled {        callerpc := getcallerpc()        pc := funcPC(mapassign)        racewritepc(unsafe.Pointer(h), callerpc, pc)        raceReadObjectPC(t.key, key, callerpc, pc)    }    // 看到这里，发现和之前 slice 声明时一样，都会做竞态检测    if msanenabled {        msanread(key, t.key.size)    }    // 这里就是并发读写map时，panic的地方    if h.flags&amp;hashWriting != 0 {        throw(&quot;concurrent map writes&quot;)    }    // t 是 map 的类型，因此在编译时，可以确定key的类型，继而确定hash算法。    alg := t.key.alg    hash := alg.hash(key, uintptr(h.hash0))    // 设置flag为writing    h.flags ^= hashWriting    if h.buckets == nil {        h.buckets = newobject(t.bucket) // newarray(t.bucket, 1)    }again:  // 重新计算bucket的hash    bucket := hash &amp; bucketMask(h.B)    if h.growing() {        growWork(t, h, bucket)    }    b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize)))    top := tophash(hash)    var inserti *uint8    var insertk unsafe.Pointer    var elem unsafe.Pointerbucketloop:    // 遍历找到bucket    for {        for i := uintptr(0); i &lt; bucketCnt; i++ {            if b.tophash[i] != top {                if isEmpty(b.tophash[i]) &amp;&amp; inserti == nil {                    inserti = &amp;b.tophash[i]                    insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))                    elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))                }                if b.tophash[i] == emptyRest {                    break bucketloop                }                continue            }            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))            if t.indirectkey() {                k = *((*unsafe.Pointer)(k))            }            // equal 方法也是根据不同的数据类型，在编译时确定            if !alg.equal(key, k) {                continue            }            // map 中已经存在 key，修改 key 对应的 value            if t.needkeyupdate() {                typedmemmove(t.key, k, key)            }            elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))            goto done        }        ovf := b.overflow(t)        if ovf == nil {            break        }        b = ovf    }    // Did not find mapping for key. Allocate new cell &amp; add entry.    // If we hit the max load factor or we have too many overflow buckets,    // and we&#39;re not already in the middle of growing, start growing.    if !h.growing() &amp;&amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {        hashGrow(t, h)        goto again // Growing the table invalidates everything, so try again    }    if inserti == nil         // 如果没有找到插入的node，即当前所有桶都已放满        newb := h.newoverflow(t, b)        inserti = &amp;newb.tophash[0]        insertk = add(unsafe.Pointer(newb), dataOffset)        elem = add(insertk, bucketCnt*uintptr(t.keysize))    }    // store new key/elem at insert position    if t.indirectkey() {        kmem := newobject(t.key)        *(*unsafe.Pointer)(insertk) = kmem        insertk = kmem    }    if t.indirectelem() {        vmem := newobject(t.elem)        *(*unsafe.Pointer)(elem) = vmem    }    typedmemmove(t.key, insertk, key)    *inserti = top    h.count++done:    // 再次检查（双重校验锁的思路）是否并发写    if h.flags&amp;hashWriting == 0 {        throw(&quot;concurrent map writes&quot;)    }    h.flags &amp;^= hashWriting    if t.indirectelem() {        elem = *((*unsafe.Pointer)(elem))    }    return elem}</code></pre><h2 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h2><pre><code>TEXT main.main(SB) /Users/such/gomodule/runtime/main.go=&gt;      main.go:6       0x10567a9*      488d0550e10000          lea rax, ptr [rip+0xe150]        main.go:6       0x10567c5       4889442410              mov qword ptr [rsp+0x10], rax        main.go:6       0x10567ca       48c744241803000000      mov qword ptr [rsp+0x18], 0x3        main.go:6       0x10567d3       e89885fbff              call $runtime.mapaccess1_faststr</code></pre><p>在 map 中找一个 key 的时候，runtime 调用了 <code>mapaccess1</code> 方法，和添加时很类似</p><pre><code>func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {    if raceenabled &amp;&amp; h != nil {        callerpc := getcallerpc()        pc := funcPC(mapaccess1)        racereadpc(unsafe.Pointer(h), callerpc, pc)        raceReadObjectPC(t.key, key, callerpc, pc)    }    if msanenabled &amp;&amp; h != nil {        msanread(key, t.key.size)    }    if h == nil || h.count == 0 {        if t.hashMightPanic() {            t.key.alg.hash(key, 0) // see issue 23734        }        return unsafe.Pointer(&amp;zeroVal[0])    }    if h.flags&amp;hashWriting != 0 {        throw(&quot;concurrent map read and map write&quot;)    }    alg := t.key.alg    hash := alg.hash(key, uintptr(h.hash0))    m := bucketMask(h.B)    b := (*bmap)(add(h.buckets, (hash&amp;m)*uintptr(t.bucketsize)))    if c := h.oldbuckets; c != nil {        if !h.sameSizeGrow() {            // There used to be half as many buckets; mask down one more power of two.            m &gt;&gt;= 1        }        oldb := (*bmap)(add(c, (hash&amp;m)*uintptr(t.bucketsize)))        if !evacuated(oldb) {            b = oldb        }    }    top := tophash(hash)bucketloop:    for ; b != nil; b = b.overflow(t) {        for i := uintptr(0); i &lt; bucketCnt; i++ {            if b.tophash[i] != top {                if b.tophash[i] == emptyRest {                    break bucketloop                }                continue            }            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))            if t.indirectkey() {                k = *((*unsafe.Pointer)(k))            }            // 如果找到 key，就返回 key 指向的 value 指针的值，            // 在计算 ptr 的时候，初始位置当前bmap, 偏移量 offset，是一个 bmap 结构体的大小，但对于amd64架构，            // 还需要考虑字节对齐，即 8 字节对齐（dataOffset）+ 8个key的大小 + i (当前索引) 个value的大小            if alg.equal(key, k) {                e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))                if t.indirectelem() {                    e = *((*unsafe.Pointer)(e))                }                return e            }        }    }    // 如果未找到的话，返回零对象的引用的指针    return unsafe.Pointer(&amp;zeroVal[0])}</code></pre><p>在 map 包里，还有个类似的方法， <code>mapaccess2</code> 在经过验证，在 <code>_, ok := a[&quot;one&quot;]</code><br>一般用于判断key是否存在的写法时，是会用到。其实根据函数的返回值也可以看出。</p><h3 id="Growing"><a href="#Growing" class="headerlink" title="Growing"></a>Growing</h3><p>和 slice 一样，在 map 的元素持续增长时，每个bucket极端情况下会有很多overflow，退化成链表，需要 rehash。一般扩容是在 <code>h.count &gt; loadFactor(2^B)</code>。<br>负载因子一般是：容量 / bucket数量，golang 的负载因子 loadFactorNum / loadFactorDen = 6.5，为什么不选择1呢，像 Redis 的 dictentry，只能保存一组键值对，golang的话，一个bucket正常情况下可以保存8组键值对；<br>那为什么选择6.5这个值呢，作者给出了一组数据。</p><table><thead><tr><th style="text-align:left">loadFactor</th><th style="text-align:left">%overflow</th><th style="text-align:left">bytes/entry</th><th style="text-align:left">hitprobe</th><th style="text-align:left">missprobe</th></tr></thead><tbody><tr><td style="text-align:left">4.00</td><td style="text-align:left">2.13</td><td style="text-align:left">20.77</td><td style="text-align:left">3.00</td><td style="text-align:left">4.00</td></tr><tr><td style="text-align:left">4.50</td><td style="text-align:left">4.05</td><td style="text-align:left">17.30</td><td style="text-align:left">3.25</td><td style="text-align:left">4.50</td></tr><tr><td style="text-align:left">5.00</td><td style="text-align:left">6.85</td><td style="text-align:left">14.77</td><td style="text-align:left">3.50</td><td style="text-align:left">5.00</td></tr><tr><td style="text-align:left">5.50</td><td style="text-align:left">10.55</td><td style="text-align:left">12.94</td><td style="text-align:left">3.75</td><td style="text-align:left">5.50</td></tr><tr><td style="text-align:left">6.00</td><td style="text-align:left">15.27</td><td style="text-align:left">11.67</td><td style="text-align:left">4.00</td><td style="text-align:left">6.00</td></tr><tr><td style="text-align:left">6.50</td><td style="text-align:left">20.90</td><td style="text-align:left">10.79</td><td style="text-align:left">4.25</td><td style="text-align:left">6.50</td></tr><tr><td style="text-align:left">7.00</td><td style="text-align:left">27.14</td><td style="text-align:left">10.15</td><td style="text-align:left">4.50</td><td style="text-align:left">7.00</td></tr><tr><td style="text-align:left">7.50</td><td style="text-align:left">34.03</td><td style="text-align:left">9.73</td><td style="text-align:left">4.75</td><td style="text-align:left">7.50</td></tr><tr><td style="text-align:left">8.00</td><td style="text-align:left">41.10</td><td style="text-align:left">9.40</td><td style="text-align:left">5.00</td><td style="text-align:left">8.00</td></tr></tbody></table><p>loadFactor：负载因子；<br>%overflow：溢出率，有溢出 bucket 的占比；<br>bytes/entry：每个 key/value 对占用字节比；<br>hitprobe：找到一个存在的key平均查找个数；<br>missprobe：找到一个不存在的key平均查找个数；</p><p>通常在负载因子 &gt; 6.5时，就是平均每个bucket存储的键值对<br>超过6.5个或者是overflow的数量 &gt; 2 ^ 15时会发生扩容（迁移）。它分为两种情况：<br>第一种：由于map在不断的insert 和 delete 中，bucket中的键值存储不够均匀，内存利用率很低，需要进行迁移。（注：bucket数量不做增加）<br>第二种：真正的，因为负载因子过大引起的扩容，bucket 增加为原 bucket 的两倍<br>不论上述哪一种 rehash，都是调用 <code>hashGrow</code> 方法：</p><ol><li>定义原 hmap 中指向 buckets 数组的指针</li><li>创建 bucket 数组并设置为 hmap 的 bucket 字段</li><li>将 extra 中的 oldoverflow 指向 overflow，overflow 指向 nil</li><li>如果正在 growing 的话，开始渐进式的迁移，在 <code>growWork</code> 方法里是 bucket 中 key/value 的迁移</li><li>在全部迁移完成后，释放内存</li></ol><blockquote><p>注意： <strong>golang在rehash时，和Redis一样采用渐进式的rehash，没有一次性迁移所有的buckets，而是把key的迁移分摊到每次插入或删除时，<br>在 bucket 中的 key/value 全部迁移完成释放oldbucket和extra.oldoverflow（尽可能不去使用map存储大量数据；最好在初始化一次性声明cap，避免频繁扩容）</strong></p></blockquote><h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><pre><code>func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) {...省略search:    for ; b != nil; b = b.overflow(t) {        for i := uintptr(0); i &lt; bucketCnt; i++ {            if t.indirectkey() {                *(*unsafe.Pointer)(k) = nil            } else if t.key.ptrdata != 0 {                memclrHasPointers(k, t.key.size)            }            e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))            if t.indirectelem() {                *(*unsafe.Pointer)(e) = nil            } else if t.elem.ptrdata != 0 {                memclrHasPointers(e, t.elem.size)            } else {                memclrNoHeapPointers(e, t.elem.size)            }            b.tophash[i] = emptyOne            if i == bucketCnt-1 {                if b.overflow(t) != nil &amp;&amp; b.overflow(t).tophash[0] != emptyRest {                    goto notLast                }            } else {                if b.tophash[i+1] != emptyRest {                    goto notLast                }            }            for {                b.tophash[i] = emptyRest                if i == 0 {                    if b == bOrig {                        break // beginning of initial bucket, we&#39;re done.                    }                    // Find previous bucket, continue at its last entry.                    c := b                    for b = bOrig; b.overflow(t) != c; b = b.overflow(t) {                    }                    i = bucketCnt - 1                } else {                    i--                }                if b.tophash[i] != emptyOne {                    break                }            }        notLast:            h.count--            break search        }    }    ...}</code></pre><p>key 和value，如果是值类型的话，直接设置为nil, 如果是指针的话，就从 ptr 位置开始清除 n 个bytes;<br>接着在删除时，只是在tophash对应的位置上，设置为 empty 的标记（<code>b.tophash[i] = emptyOne</code>），没有真正的释放内存空间，因为频繁的申请、释放内存空间开销很大，如果真正想释放的话，只有依赖GC；<br>如果bucket是以一些 emptyOne 的标记结束，最终，就设置为 emptyRest 标记，emptyOne 和 emptyRest 都是空的标记，emptyRest的区别就是：标记在 高索引位 和 overflow bucket 都是空的，<br>应该是考虑在之后重用时，插入和删除操作需要查找位置时，减少查找次数。</p><h3 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h3><p>做两组试验，第一组是：提前分配好 map 的总容量后追加k/v；另一组是：初始化 0 容量的 map 后做追加</p><pre><code>package mainimport &quot;testing&quot;var count int = 100000func addition(m map[int]int) map[int]int {    for i := 0; i &lt; count; i++ {        m[i] = i    }    return m}func BenchmarkGrows(b *testing.B) {    b.ResetTimer()    for i := 0; i &lt; b.N; i++ {        m := make(map[int]int)        addition(m)    }}func BenchmarkNoGrows(b *testing.B) {    b.ResetTimer()    for i := 0; i &lt; b.N; i++ {        m := make(map[int]int, count)        addition(m)    }}</code></pre><pre><code>$ go test -bench=. ./goos: darwingoarch: amd64# benchmark名字 -CPU数       执行次数      平均执行时间nsBenchmarkGrows-4             200           8298505 ns/opBenchmarkNoGrows-4           300           4627118 ns/opPASSok      _/Users/such/gomodule/runtime   4.401s</code></pre><p>提前定义容量的case平均执行时间比未定义容量的快了80% — <strong>扩容时的数据拷贝和重新哈希成本很高！</strong><br>再看看内存的分配次数：</p><pre><code>$ go test -bench=. -benchmem ./goos: darwingoarch: amd64# benchmark名字 -CPU数       执行次数      平均执行时间ns         每次分配内存大小        每次内存分配次数BenchmarkGrows-4             200           9265553 ns/op         5768155 B/op       4010 allocs/opBenchmarkNoGrows-4           300           4855000 ns/op         2829115 B/op       1678 allocs/opPASSok      _/Users/such/gomodule/runtime   4.704s</code></pre><p>两个方法执行相同的次数，GC的次数也会多出一倍</p><pre><code>func main() {    for i := 0; i &lt; 5; i++ {        n := make(map[int]int, count)        addition(n)        //m := make(map[int]int)        //addition(m)    }}// 第一组，预分配$ go build -o growth &amp;&amp; GODEBUG=gctrace=1 ./growthgc 1 @0.006s 0%: 0.002+0.091+0.015 ms clock, 0.011+0.033/0.011/0.088+0.060 ms cpu, 5-&gt;5-&gt;2 MB, 6 MB goal, 4 Pgc 2 @0.012s 0%: 0.001+0.041+0.002 ms clock, 0.007+0.032/0.007/0.033+0.009 ms cpu, 5-&gt;5-&gt;2 MB, 6 MB goal, 4 Pgc 3 @0.017s 0%: 0.002+0.090+0.010 ms clock, 0.008+0.035/0.006/0.084+0.041 ms cpu, 5-&gt;5-&gt;2 MB, 6 MB goal, 4 Pgc 4 @0.022s 0%: 0.001+0.056+0.008 ms clock, 0.007+0.026/0.003/0.041+0.034 ms cpu, 5-&gt;5-&gt;2 MB, 6 MB goal, 4 P// 第二组，未分配$ go build -o growth &amp;&amp; GODEBUG=gctrace=1 ./growthgc 1 @0.005s 0%: 0.001+0.10+0.001 ms clock, 0.007+0.076/0.004/0.13+0.007 ms cpu, 5-&gt;5-&gt;3 MB, 6 MB goal, 4 Pgc 2 @0.012s 0%: 0.002+0.071+0.010 ms clock, 0.008+0.016/0.010/0.075+0.040 ms cpu, 5-&gt;5-&gt;0 MB, 7 MB goal, 4 Pgc 3 @0.015s 0%: 0.001+0.13+0.009 ms clock, 0.007+0.006/0.037/0.082+0.036 ms cpu, 4-&gt;5-&gt;3 MB, 5 MB goal, 4 Pgc 4 @0.021s 0%: 0.001+0.13+0.009 ms clock, 0.007+0.040/0.007/0.058+0.038 ms cpu, 6-&gt;6-&gt;1 MB, 7 MB goal, 4 Pgc 5 @0.024s 0%: 0.001+0.084+0.001 ms clock, 0.005+0.036/0.006/0.052+0.006 ms cpu, 4-&gt;4-&gt;3 MB, 5 MB goal, 4 Pgc 6 @0.030s 0%: 0.002+0.075+0.001 ms clock, 0.008+0.056/0.004/0.072+0.007 ms cpu, 6-&gt;6-&gt;1 MB, 7 MB goal, 4 Pgc 7 @0.033s 0%: 0.013+0.11+0.003 ms clock, 0.053+0.047/0.013/0.075+0.012 ms cpu, 4-&gt;4-&gt;3 MB, 5 MB goal, 4 Pgc 8 @0.041s 0%: 0.002+0.073+0.024 ms clock, 0.008+0.033/0.010/0.067+0.097 ms cpu, 6-&gt;6-&gt;1 MB, 7 MB goal, 4 Pgc 9 @0.043s 0%: 0.001+0.067+0.001 ms clock, 0.006+0.046/0.003/0.070+0.006 ms cpu, 4-&gt;4-&gt;3 MB, 5 MB goal, 4 P</code></pre><p>有个1千万kv的 map，测试在什么情况下会回收内存</p><pre><code>package mainvar count = 10000000var dict = make(map[int]int, count)func addition() {    for i := 0; i &lt; count; i++ {        dict[i] = i    }}func clear() {    for k := range dict {        delete(dict, k)    }    //dict = nil}func main() {    addition()    clear()    debug.FreeOSMemory()}$ go build -o clear &amp;&amp; GODEBUG=gctrace=1 ./cleargc 1 @0.007s 0%: 0.006+0.12+0.015 ms clock, 0.025+0.037/0.038/0.12+0.061 ms cpu, 306-&gt;306-&gt;306 MB, 307 MB goal, 4 Pgc 2 @0.963s 0%: 0.004+1.0+0.025 ms clock, 0.017+0/0.96/0.48+0.10 ms cpu, 307-&gt;307-&gt;306 MB, 612 MB goal, 4 Pgc 3 @1.381s 0%: 0.004+0.081+0.003 ms clock, 0.018+0/0.051/0.086+0.013 ms cpu, 309-&gt;309-&gt;306 MB, 612 MB goal, 4 P (forced)scvg-1: 14 MB releasedscvg-1: inuse: 306, idle: 77, sys: 383, released: 77, consumed: 306 (MB)</code></pre><p>删除了所有kv，堆大小（goal）并无变化</p><pre><code>func clear() {    for k := range dict {        delete(dict, k)    }    dict = nil}$ go build -o clear &amp;&amp; GODEBUG=gctrace=1 ./cleargc 1 @0.006s 0%: 0.004+0.12+0.010 ms clock, 0.019+0.035/0.016/0.17+0.043 ms cpu, 306-&gt;306-&gt;306 MB, 307 MB goal, 4 Pgc 2 @0.942s 0%: 0.003+1.0+0.010 ms clock, 0.012+0/0.85/0.54+0.043 ms cpu, 307-&gt;307-&gt;306 MB, 612 MB goal, 4 Pgc 3 @1.321s 0%: 0.003+0.072+0.002 ms clock, 0.013+0/0.050/0.090+0.010 ms cpu, 309-&gt;309-&gt;0 MB, 612 MB goal, 4 P (forced)scvg-1: 319 MB releasedscvg-1: inuse: 0, idle: 383, sys: 383, released: 383, consumed: 0 (MB)</code></pre><p>清除过后，设置为nil，才会真正释放内存。（本身每2分钟强制 runtime.GC()，每5分钟 scavenge 释放内存，其实不必太过纠结是否真正释放，未真正释放也是为了后面有可能的重用，<br><strong>但有时需要真实释放时，清楚怎么做才能解决问题</strong>）</p><blockquote><p>Reference<br>Map：<a href="https://golang.org/src/runtime/map.go?h=hmap#L115" target="_blank" rel="noopener">https://golang.org/src/runtime/map.go?h=hmap#L115</a><br>Benchmark：<a href="https://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go" target="_blank" rel="noopener">https://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go</a><br>Gctrace：<a href="https://dave.cheney.net/tag/godebug" target="_blank" rel="noopener">https://dave.cheney.net/tag/godebug</a><br>FreeOsMemory：<a href="https://golang.org/pkg/runtime/debug/#FreeOSMemory" target="_blank" rel="noopener">https://golang.org/pkg/runtime/debug/#FreeOSMemory</a>  </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;定义&quot;&gt;&lt;a href=&quot;#定义&quot; class=&quot;headerlink&quot; title=&quot;定义&quot;&gt;&lt;/a&gt;定义&lt;/h2&gt;&lt;p&gt;golang 中的 &lt;code&gt;map&lt;/code&gt; 就是常用的 &lt;a href=&quot;https://en.wikipedia.org/wik
      
    
    </summary>
    
    
      <category term="go" scheme="http://8090lambert.cn/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>详解 Golang 的 slice 设计与实现</title>
    <link href="http://8090lambert.cn/2019/04/21/%E8%AF%A6%E8%A7%A3%20Golang%20%E7%9A%84%20slice%20%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>http://8090lambert.cn/2019/04/21/详解 Golang 的 slice 设计与实现/</id>
    <published>2019-04-21T06:50:13.000Z</published>
    <updated>2021-05-09T14:50:16.599Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Slice-结构体"><a href="#Slice-结构体" class="headerlink" title="Slice 结构体"></a>Slice 结构体</h3><p>slice 是 golang 中利用指针指向某个连续片段的数组，所以本质上它算是引用类型。<br>一个 <code>slice</code> 在 golang 中占用24个 bytes</p><pre><code>a = make([]int, 0)unsafe.Sizeof(a)    // 24var c intunsafe.Sizeof(c)    // 8, 一个 int 在 golang 中占用 8 个bytes(本机是64位操作系统)</code></pre><p>在 runtime 的 slice.go 中，定义了 slice 的 struct</p><pre><code>type slice struct {    array unsafe.Pointer    // 8 bytes    len   int                // 8 bytes    cap   int                // 8 bytes    // 确认了，slice 的大小 24}</code></pre><ul><li>array 是指向真实的数组的 ptr</li><li>len 是指切片已有元素个数</li><li>cap 是指当前分配的空间</li></ul><h3 id="准备调试"><a href="#准备调试" class="headerlink" title="准备调试"></a>准备调试</h3><p>简单准备一段程序，看看 golang 是如何初始化一个切片的</p><pre><code>package mainimport &quot;fmt&quot;func main() {    a := make([]int, 0)    a = append(a, 2, 3, 4)    fmt.Println(a)}</code></pre><h3 id="Slice-初始化"><a href="#Slice-初始化" class="headerlink" title="Slice 初始化"></a>Slice 初始化</h3><p>使用 <code>dlv</code> 调试，反汇编后：</p><pre><code>(dlv) disassembleTEXT main.main(SB) /Users/such/gomodule/runtime/main.gomain.go:5       0x10b70f0       65488b0c2530000000              mov rcx, qword ptr gs:[0x30]main.go:5       0x10b70f9       488d4424e8                      lea rax, ptr [rsp-0x18]main.go:5       0x10b70fe       483b4110                        cmp rax, qword ptr [rcx+0x10]main.go:5       0x10b7102       0f8637010000                    jbe 0x10b723f      main.go:5       0x10b7108*      4881ec98000000                  sub rsp, 0x98main.go:5       0x10b710f       4889ac2490000000                mov qword ptr [rsp+0x90], rbpmain.go:5       0x10b7117       488dac2490000000                lea rbp, ptr [rsp+0x90]main.go:6       0x10b711f       488d051a0e0100                  lea rax, ptr [rip+0x10e1a]main.go:6       0x10b7126       48890424                        mov qword ptr [rsp], raxmain.go:6       0x10b712a       0f57c0                          xorps xmm0, xmm0main.go:6       0x10b712d       0f11442408                      movups xmmword ptr [rsp+0x8], xmm0main.go:6       0x10b7132       e8b99af8ff                      ** call $runtime.makeslice **main.go:6       0x10b7137       488b442418                      mov rax, qword ptr [rsp+0x18]main.go:6       0x10b713c       4889442460                      mov qword ptr [rsp+0x60], raxmain.go:6       0x10b7141       0f57c0                          xorps xmm0, xmm0main.go:6       0x10b7144       0f11442468                      movups xmmword ptr [rsp+0x68], xmm0...</code></pre><p>在一堆指令中，看到 <code>call $runtime.makeslice</code> 的调用应该是初始化 slice</p><pre><code>func makeslice(et *_type, len, cap int) unsafe.Pointer {    mem, overflow := math.MulUintptr(et.size, uintptr(cap))    if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap {        // NOTE: Produce a &#39;len out of range&#39; error instead of a        // &#39;cap out of range&#39; error when someone does make([]T, bignumber).        // &#39;cap out of range&#39; is true too, but since the cap is only being        // supplied implicitly, saying len is clearer.        // See golang.org/issue/4085.        mem, overflow := math.MulUintptr(et.size, uintptr(len))        if overflow || mem &gt; maxAlloc || len &lt; 0 {            panicmakeslicelen()        }        panicmakeslicecap()    }    return mallocgc(mem, et, true)}</code></pre><p>makeslice 最后返回真正值存储的数组域的内存地址，函数中 <code>uintptr()</code> 是什么呢？</p><pre><code>println(uintptr(0), ^uintptr(0))// 0    18446744073709551615    为什么按位异或后是这个数?var c int = 1println(^c, ^uint64(0))// -2    18446744073709551615</code></pre><p>从这几行代码验证，有符号的1，二进制为：0001，异或后：1110，最高位1是负数，表示-2；<br>uint64二进制：0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000<br>异或后：1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111<br>因为无符号的，转换成10进制，就是 2 ^ 64 - 1 = 18446744073709551615<br>。所以，其实^uintptr(0) 就是指当前机器（32位，uint32；64位，uint64）的最大值。<br>我们可以打印下现在的 <code>a</code> </p><pre><code>(dlv) p a[]int len: 1, cap: 0, [0]</code></pre><h3 id="Slice-扩容"><a href="#Slice-扩容" class="headerlink" title="Slice 扩容"></a>Slice 扩容</h3><pre><code>=&gt;      main.go:7       0x10b7149       eb00                            jmp 0x10b714b        main.go:7       0x10b714b       488d0dee0d0100                  lea rcx, ptr [rip+0x10dee]        main.go:7       0x10b7152       48890c24                        mov qword ptr [rsp], rcx        main.go:7       0x10b7156       4889442408                      mov qword ptr [rsp+0x8], rax        main.go:7       0x10b715b       0f57c0                          xorps xmm0, xmm0        main.go:7       0x10b715e       0f11442410                      movups xmmword ptr [rsp+0x10], xmm0        main.go:7       0x10b7163       48c744242003000000              mov qword ptr [rsp+0x20], 0x3        main.go:7       0x10b716c       e84f9bf8ff                      call $runtime.growslice        main.go:7       0x10b7171       488b442428                      mov rax, qword ptr [rsp+0x28]        main.go:7       0x10b7176       488b4c2430                      mov rcx, qword ptr [rsp+0x30]        main.go:7       0x10b717b       488b542438                      mov rdx, qword ptr [rsp+0x38]        main.go:7       0x10b7180       4883c103                        add rcx, 0x3        main.go:7       0x10b7184       eb00                            jmp 0x10b7186        main.go:7       0x10b7186       48c70002000000                  mov qword ptr [rax], 0x2        main.go:7       0x10b718d       48c7400803000000                mov qword ptr [rax+0x8], 0x3        main.go:7       0x10b7195       48c7401004000000                mov qword ptr [rax+0x10], 0x4        main.go:7       0x10b719d       4889442460                      mov qword ptr [rsp+0x60], rax        main.go:7       0x10b71a2       48894c2468                      mov qword ptr [rsp+0x68], rcx        main.go:7       0x10b71a7       4889542470                      mov qword         ...</code></pre><p>在对 slice 做 append 的时候，其实是调用了 <code>call runtime.growslice</code>，看看做了什么：</p><pre><code>func growslice(et *_type, old slice, cap int) slice {    if cap &lt; old.cap {        panic(errorString(&quot;growslice: cap out of range&quot;))    }    if et.size == 0 {        // append should not create a slice with nil pointer but non-zero len.        // We assume that append doesn&#39;t need to preserve old.array in this case.        return slice{unsafe.Pointer(&amp;zerobase), old.len, cap}    }    newcap := old.cap    doublecap := newcap + newcap    if cap &gt; doublecap {        newcap = cap    } else {        if old.len &lt; 1024 {            newcap = doublecap        } else {            for 0 &lt; newcap &amp;&amp; newcap &lt; cap {                newcap += newcap / 4            }            if newcap &lt;= 0 {                newcap = cap            }        }    }    var overflow bool    var lenmem, newlenmem, capmem uintptr    // Specialize for common values of et.size.    // For 1 we don&#39;t need any division/multiplication.    // For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant.    // For powers of 2, use a variable shift.    switch {    case et.size == 1:        lenmem = uintptr(old.len)        newlenmem = uintptr(cap)        capmem = roundupsize(uintptr(newcap))        overflow = uintptr(newcap) &gt; maxAlloc        newcap = int(capmem)    case et.size == sys.PtrSize:        lenmem = uintptr(old.len) * sys.PtrSize        newlenmem = uintptr(cap) * sys.PtrSize        capmem = roundupsize(uintptr(newcap) * sys.PtrSize)        overflow = uintptr(newcap) &gt; maxAlloc/sys.PtrSize        newcap = int(capmem / sys.PtrSize)    case isPowerOfTwo(et.size):        var shift uintptr        if sys.PtrSize == 8 {            // Mask shift for better code generation.            shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63        } else {            shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31        }        lenmem = uintptr(old.len) &lt;&lt; shift        newlenmem = uintptr(cap) &lt;&lt; shift        capmem = roundupsize(uintptr(newcap) &lt;&lt; shift)        overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift)        newcap = int(capmem &gt;&gt; shift)    default:        lenmem = uintptr(old.len) * et.size        newlenmem = uintptr(cap) * et.size        capmem, overflow = math.MulUintptr(et.size, uintptr(newcap))        capmem = roundupsize(capmem)        newcap = int(capmem / et.size)    }    if overflow || capmem &gt; maxAlloc {        panic(errorString(&quot;growslice: cap out of range&quot;))    }    var p unsafe.Pointer    if et.ptrdata == 0 {        // 申请内存        p = mallocgc(capmem, nil, false)        // 清除未使用的地址        memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem)    } else {        p = mallocgc(capmem, et, true)        if lenmem &gt; 0 &amp;&amp; writeBarrier.enabled {            bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem)        }    }    // 拷贝大小为 lenmem 个btyes，从old.array到p    memmove(p, old.array, lenmem)    return slice{p, old.len, newcap}</code></pre><p>具体扩容的策略：</p><ul><li>如果要申请的容量（cap）大于 2 倍的原容量（old.cap）或者 原容量 &lt; 1024 ，那么newcap = old.cap + old.cap</li><li>否则，计算 <code>newcap += newcap / 4</code>，知道 newcap 不小于要申请的容量，如果溢出，newcap = cap（要申请的容量）  </li></ul><p>扩容完成后就开始根据 t.size 的大小，重新计算地址，其中新 slice 的 <code>len</code> 为原 slice 的 <code>cap</code> (只有 slice 的 len 超过 cap，才需要扩容)。<br>接着申请 <code>capmem</code> 大小的内存，从 old.array 拷贝 <code>lenmem</code> 个 bytes (就是原 slice 整个拷贝，lenmem 就是计算的原切片的大小)到 <code>p</code>。</p><pre><code>a := make([]int, 0)a = append(a, 1)println(&quot;1 times:&quot;, len(a), cap(a))    // 1 times: 1 1a = append(a, 2, 3)println(&quot;2 times:&quot;, len(a), cap(a))    // 2 times: 3 4a = append(a, 4)println(&quot;3 times:&quot;, len(a), cap(a))    // 3 times: 4 4</code></pre><p>可以看出:</p><ol><li>如果 <code>append</code> 后的 <code>len</code> 大于 <code>cap</code> 的2倍，即扩大至大于 <code>len</code> 的第一个2的倍数</li><li>如果 <code>append</code> 后的 <code>len</code> 大于 <code>cap</code> 且小于 <code>cap</code> 的两倍，<code>cap</code>扩大至2倍</li><li>如果 <code>append</code> 后的 <code>len</code> 小于 <code>cap</code>，直接追加</li></ol><h3 id="Slice污染"><a href="#Slice污染" class="headerlink" title="Slice污染"></a>Slice污染</h3><p>使用 <code>slice</code>，也许不知不觉中就会造成一些问题。</p><pre><code>a := []int{1, 2, 3, 4, 5}shadow := a[1:3]shadow = append(shadow, 100)fmt.Println(shadow, a)// [2 3 100] [1 2 3 100 5]</code></pre><p>结果很意外，但也是符合逻辑。a 的结构体中 <code>array</code> 是指向数组 <code>[1,2,3,4,5]</code>的内存地址，<code>shadow</code> 是指向其中 <code>[2，3]</code> 的内存地址。在向 <code>shadow</code> 增加后，会直接修改真实的数组，间接影响到指向数组的所有切片。所以可以修改上述代码为：</p><pre><code>a := []int{1, 2, 3, 4, 5}shadow := append([]int{}, a[1:3]...)shadow = append(shadow, 100)fmt.Println(shadow, a)// [2 3 100] [1 2 3 4 5]</code></pre><p>如果某个函数的返回值，是上述的这种情况 <code>return a[1:3]</code>，还会造成 <code>[1,2,3,4,5]</code> 锁占用的内存无法释放。</p><h3 id="黑魔法"><a href="#黑魔法" class="headerlink" title="黑魔法"></a>黑魔法</h3><p>知道了 <code>slice</code> 本身是指向真实的数组的指针，在 <code>Golang</code> 中提供了 <code>unsafe</code> 来做指针操作。</p><pre><code>a := []int{1, 2, 3, 4, 5}shadow := a[1:3]shadowPtr := uintptr(unsafe.Pointer(&amp;shadow[0]))offset := unsafe.Sizeof(int(0))fmt.Println(*(*int)(unsafe.Pointer(shadowPtr - offset)))    // 1fmt.Println(*(*int)(unsafe.Pointer(shadowPtr + 2*offset)))    // 4</code></pre><p><code>shadowPtr</code> 是 a 的第1个下标的位置，一个 <code>int</code> 在64位机器上是8 bytes，向前偏移1个 <code>offset</code>，是 a 的第0个下标 1；向后偏移2个 <code>offset</code>，是 a 的第3个下标 4。</p><h3 id="并发安全"><a href="#并发安全" class="headerlink" title="并发安全"></a>并发安全</h3><p><code>slice</code> 是非协程安全的数据类型，如果创建多个 <code>goroutine</code> 对 <code>slice</code> 进行并发读写，会造成丢失。看一段代码</p><pre><code>package mainimport (    &quot;fmt&quot;    &quot;sync&quot;)func main () {    a := make([]int, 0)    var wg sync.WaitGroup    for i := 0; i &lt; 10000; i++ {        wg.Add(1)        go func(i int) {            a = append(a, i)            wg.Done()        }(i)    }    wg.Wait()    fmt.Println(len(a))}// 9403 9876 9985 9491 ...</code></pre><p>多次执行，每次得到的结果都不一样，总之一定不会是想要的 10000 个。想要解决这个问题，按照协程安全的编程思想来考虑问题，<br>可以考虑使用 <code>channel</code> 本身的特性(阻塞)来实现安全的并发读写。</p><pre><code>func main() {    a := make([]int, 0)    buffer := make(chan int)    go func() {        for v := range buffer {            a = append(a, v)        }    }()    var wg sync.WaitGroup    for i := 0; i &lt; 10000; i++ {        wg.Add(1)        go func(i int) {            buffer &lt;- i            wg.Done()        }(i)    }    wg.Wait()    fmt.Println(len(a))}// 10000</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Slice-结构体&quot;&gt;&lt;a href=&quot;#Slice-结构体&quot; class=&quot;headerlink&quot; title=&quot;Slice 结构体&quot;&gt;&lt;/a&gt;Slice 结构体&lt;/h3&gt;&lt;p&gt;slice 是 golang 中利用指针指向某个连续片段的数组，所以本质上它算是引用
      
    
    </summary>
    
    
      <category term="go" scheme="http://8090lambert.cn/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务原理</title>
    <link href="http://8090lambert.cn/2019/04/15/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86/"/>
    <id>http://8090lambert.cn/2019/04/15/分布式事务原理/</id>
    <published>2019-04-15T14:36:45.000Z</published>
    <updated>2021-05-09T14:50:16.598Z</updated>
    
    <content type="html"><![CDATA[<h4 id="事务的必要性"><a href="#事务的必要性" class="headerlink" title="事务的必要性"></a>事务的必要性</h4><p>一般提到事务，首先想到的就是 MySQL 的 transaction，但是很多场景，仅仅依靠 MySQL, 还是无法<br>保证业务场景需要的 <code>ACID</code>。<br>以购物场景为例，张三购买物品，账户扣款 100 元的同时，需要保证在下游的会员服务中给该账户增加 100 积分。<br>而扣款的业务和增加积分的业务是在两个不同的应用，正常处理逻辑一般是先扣除100元，然后网络通知积分服务增加100积分。<br>类似这种业务需求，就必须要用分布式事务来保证。<br>如下图：<br><img src="http://8090lambert.cn/images/blog/http/http_06.png" alt=""></p><p>以上过程会存在3个问题：</p><ol><li><p>账号服务在扣款的时候宕机了，这时候可能扣款成功，也可能扣款失败；</p></li><li><p>由于网络稳定性无法保证，通知扣积分服务可能失败，但是扣款成功了；</p></li><li><p>扣款成功，并且通知成功，但是增加积分的时候失败了。</p></li></ol><p>实际上，rocketmq 的事务消息解决的是问题1和问题2这种场景，也就是<em>解决本地事务执行与消息发送的原子性问题</em>。即解决 Producer 执行业务逻辑成功之后投递消息可能失败的场景。  </p><p>而对于问题3这种场景，rocketmq提供了消费失败重试的机制。但是如果消费重试依然失败怎么办？rocketmq本身并没有提供解决这种问题的办法，例如如果加积分失败了，则需要回滚事务，实际上增加了业务复杂度，而官方给予的建议是：人工解决。RocketMQ目前暂时没有解决这个问题的原因是：在设计实现消息系统时，我们需要衡量是否值得花这么大的代价来解决这样一个出现概率非常小的问题。</p><h4 id="事务消息的实现思路和过程"><a href="#事务消息的实现思路和过程" class="headerlink" title="事务消息的实现思路和过程"></a>事务消息的实现思路和过程</h4><p>RocketMQ 事务消息的设计流程同样借鉴了两阶段提交理论，通过在执行本地事务前后发送两条消息来保证本地事务与发送消息的原子性，过程如下图：<br><img src="http://8090lambert.cn/images/blog/http/http_07.png" alt=""></p><h4 id="事务消息详细过程说明"><a href="#事务消息详细过程说明" class="headerlink" title="事务消息详细过程说明"></a>事务消息详细过程说明</h4><ol><li>Producer发送Half(prepare)消息到broker；</li><li>half消息发送成功之后执行本地事务；</li><li>（由用户实现）本地事务执行如果成功则返回commit，如果执行失败则返回roll_back。</li><li>Producer发送确认消息到broker（也就是将步骤3执行的结果发送给broker），这里可能broker未收到确认消息，下面分两种情况分析：</li></ol><p><em>如果 broker 收到了确认消息：</em></p><blockquote><ul><li>如果收到的结果是 commit，则 broker 视为整个事务过程执行成功，将消息下发给Conusmer端消费；<br><br><br></li><li>如果收到的结果是 rollback，则 broker 视为本地事务执行失败，broker删除Half消息，不下发给consumer。  </li></ul></blockquote><p><em>如果 broker 未收到了确认消息：</em></p><blockquote><p>broker定时回查本地事务的执行结果；<br><br><br>（由用户实现）如果本地事务已经执行则返回commit；如果未执行，则返回rollback；<br><br><br>Producer端回查的结果发送给broker；<br><br><br>broker接收到的如果是commit，则broker视为整个事务过程执行成功，将消息下发给Conusmer端消费；如果是rollback，则broker视为本地事务执行失败，broker删除Half消息，不下发给consumer。如果broker未接收到回查的结果（或者查到的是unknow），则broker会定时进行重复回查，以确保查到最终的事务结果。</p></blockquote><p>补充：对于过程3，如果执行本地事务突然宕机了（相当本地事务执行结果返回unknow），则和broker未收到确认消息的情况一样处理。</p><h4 id="事务消息的使用"><a href="#事务消息的使用" class="headerlink" title="事务消息的使用"></a>事务消息的使用</h4><p>关于rocketmq事务消息如何使用，最好的学习思路是从github上下载下源码，参考demo示例。这里也以官方的demo讲解如何使用（在demo基础上做了一点修改）。</p><h4 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h4><p>为了模拟事务执行的异常场景，这里会模拟发送5条事务消息，前三条（msg-1、msg-2、msg-3）对应的本地事务执行结果为unknow（模拟本地事务执行未知的情况）;  </p><p>第4条消息（msg-4）返回COMMIT_MESSAGE（模拟本地事务执行成功的情况），第5条消息（msg-5）返回ROLLBACK_MESSAGE（模拟本地事务执行失败的情况）;  </p><p>对于前三条消息，模拟回查到的本地事务处理结果分别为UNKNOW，COMMIT_MESSAGE，ROLLBACK_MESSAGE。</p><ul><li><p>发送事务的逻辑：</p><pre><code class="angular2html">public class TransactionProducer {  public static void main(String[] args) throws MQClientException, InterruptedException {      //事务执行的listener，由用户实现及接口，提供本地事务执行的代码，以及回查本地事务处理结果的逻辑。      TransactionListener transactionListener = new TransactionListenerImpl();      TransactionMQProducer producer = new TransactionMQProducer(&quot;TransactionProducer&quot;);      producer.setNamesrvAddr(&quot;localhost:9876&quot;);      producer.setTransactionListener(transactionListener);      producer.start();      //模拟发送5条消息      for (int i = 1; i &lt; 6; i++) {          try {              Message msg = new Message(&quot;TransactionTopicTest&quot;, null, &quot;msg-&quot; + i, (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));              producer.sendMessageInTransaction(msg, null);              Thread.sleep(10);          } catch (MQClientException | UnsupportedEncodingException e) {              e.printStackTrace();          }      }      Thread.sleep(Integer.MAX_VALUE);      producer.shutdown();  }}</code></pre></li><li><p>提供本地事务执行以及回查本地事务的逻辑：</p><pre><code class="angular2html">public class TransactionListenerImpl implements TransactionListener {  private AtomicInteger transactionIndex = new AtomicInteger(0);  private AtomicInteger checkTimes = new AtomicInteger(0);  private ConcurrentHashMap&lt;String, Integer&gt; localTrans = new ConcurrentHashMap&lt;&gt;();  /**   * 本地事务的执行逻辑实现   * 模拟5条消息本地事务的处理结果   * @param msg Half(prepare) message   * @param arg Custom business parameter   * @return   */  @Override  public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {      LocalTransactionState state = null;      //msg-4返回COMMIT_MESSAGE      if(msg.getKeys().equals(&quot;msg-4&quot;)){          state = LocalTransactionState.COMMIT_MESSAGE;      }      //msg-5返回ROLLBACK_MESSAGE      else if(msg.getKeys().equals(&quot;msg-5&quot;)){          state = LocalTransactionState.ROLLBACK_MESSAGE;      }else{          //这里返回unknown的目的是模拟执行本地事务突然宕机的情况（或者本地执行成功发送确认消息失败的场景）          state = LocalTransactionState.UNKNOW;          //假设3条消息的本地事务结果分别为1，2，3          localTrans.put(msg.getKeys(), transactionIndex.incrementAndGet());      }      System.out.println(&quot;executeLocalTransaction:&quot; + msg.getKeys() + &quot;,excute state:&quot; + state +&quot;,current time：&quot; + new Date());      return state;  }  /**   * 回查本地事务的代码实现   * 第1条消息模拟unknow（例如回查的时候网络依然有问题的情况）。   * 第2条消息模拟本地事务处理成功结果COMMIT_MESSAGE。   * 第3条消息模拟本地事务处理失败结果需要回滚ROLLBACK_MESSAGE。   *   * @param msg Check message   * @return   */  @Override  public LocalTransactionState checkLocalTransaction(MessageExt msg) {      System.out.print(&quot;checkLocalTransaction message key：&quot;+msg.getKeys()+&quot;,current time：&quot; + new Date());      //根据key获取到3条消息本地事务的处理结果(实际业务场景一般是通过获取msg中的消息体数据来确定某条消息的本地事务是否执行成功)      Integer status = localTrans.get(msg.getKeys());      if (null != status) {          switch (status) {              case 1:                  System.out.println(&quot; check result：unknow ，回查次数：&quot;+checkTimes.incrementAndGet());                  //依然无法确定本地事务的执行结果，返回unknow，下次会继续回查结果                  return LocalTransactionState.UNKNOW;              case 2:                  //查到本地事务执行成功，返回COMMIT_MESSAGE，producer继续发送确认消息（此逻辑无需自己写，mq本身提供）                  //或者查到本地事务执行成功了，但是想回滚掉，则这里需要返回ROLLBACK_MESSAGE，同时写回滚的逻辑，实际如何处理根据业务场景而定                  System.out.println(&quot; check result：commit message&quot;);                  return LocalTransactionState.COMMIT_MESSAGE;              case 3:                  //查询到本地事务执行失败，需要回滚消息。                  System.out.println(&quot; check result：rollback message&quot;);                  return LocalTransactionState.ROLLBACK_MESSAGE;          }      }      return LocalTransactionState.COMMIT_MESSAGE;  }}</code></pre></li></ul><h4 id="运行结果分析"><a href="#运行结果分析" class="headerlink" title="运行结果分析"></a>运行结果分析</h4><p><img src="http://8090lambert.cn/images/blog/http/http_09.png" alt=""></p><p><em>仔细观察日志输出和romcketmq的控制台，我们可以得出如下结论：</em></p><ul><li><p>msg-4、msg-5消息没有执行回查事务消息的逻辑，是因为msg-4、msg-5在本地执行事务的时候已经返回了确定的事务执行结果，因此msg-4、msg-5不会回查；</p></li><li><p>msg-1、msg-2、msg-3在执行完本地事务10s后，都回查了本地事务的结果；</p></li><li><p>msg-2、msg-3只回查了一次，因为这两条消息在回查的时候已经返回了确切的事务执行结果；</p></li><li><p>msg-1回查了5次，并且间隔为1分钟，因为msg-1在回查的事务状态依然为unknow，因此会反复回查，直到超过了回查的默认次数不再回查;</p></li><li><p>对比msg-2和msg-4的消息存储时间，msg-4的存储时间恰好是执行本地事务返回的时间，而msg-2的存储时间则恰好是第一次回查事务结果返回的时间;</p></li></ul><p>关键代码如下：</p><pre><code class="angular2html">public TransactionSendResult sendMessageInTransaction(final Message msg,final TransactionListener tranExecuter, final Object arg){       //1.发送prepare消息       SendResult sendResult = this.send(msg);       LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW;       Throwable localException = null;       switch (sendResult.getSendStatus()) {           case SEND_OK: {               try {                   //2.如果prepare消息发送成功，执行TransactionListener的executeLocalTransaction实现，也就是本地事务方法                   localTransactionState = tranExecuter.executeLocalTransaction(msg, arg);               } catch (Throwable e) {                   localException = e;               }           }           break;           case FLUSH_DISK_TIMEOUT:           case FLUSH_SLAVE_TIMEOUT:           case SLAVE_NOT_AVAILABLE:               localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE;               break;           default:               break;       }       //3.结束事务，其实就是针对前面发送的prepare消息再发送一条确认消息（这条确认消息包含了本地事务执行的结果，这里可以猜测broker接收到该确认消息和之前的prepare消息必然有比较大的关联）       this.endTransaction(sendResult, localTransactionState, localException);   }</code></pre><p>大致思路是：</p><ol><li>发送prepare消息；</li><li>执行实现了TransactionListener的executeLocalTransaction方法，也就是执行本地事务的逻辑；</li><li>结束事务，将过程2得到的本地事务结果通过发送另外一条确认消息告诉broker；</li></ol><p>因此我们这里可以推测：broker必然会根据前后两条消息来确定如何处理该事务消息。</p><h4 id="broker端的处理事务消息回查逻辑"><a href="#broker端的处理事务消息回查逻辑" class="headerlink" title="broker端的处理事务消息回查逻辑"></a>broker端的处理事务消息回查逻辑</h4><pre><code class="angular2html">public class TransactionalMessageCheckService extends ServiceThread {    @Override    public void run() {        //检查间隔，默认一分钟，可配置        long checkInterval = brokerController.getBrokerConfig().getTransactionCheckInterval();        while (!this.isStopped()) {            try {                //等待一分钟，以实现每一分钟回查需要的事务消息结果                waitPoint.await(interval, TimeUnit.MILLISECONDS);            } catch (InterruptedException e) {                log.error(&quot;Interrupted&quot;, e);            } finally {                //处理事务消息回查的核心逻辑方法                brokerController.getTransactionalMessageService().check(timeout, checkMax,this.brokerController.getTransactionalMessageCheckListener());            }        }    }}public class TransactionalMessageServiceImpl implements TransactionalMessageService {    public void check(long transactionTimeout, int transactionCheckMax,AbstractTransactionalMessageCheckListener listener) {            //获取到所有的RMQ_SYS_TRANS_HALF_TOPIC消息队列（prepare消息）            Set&lt;MessageQueue&gt; msgQueues = transactionalMessageBridge.fetchMessageQueues(&quot;RMQ_SYS_TRANS_HALF_TOPIC&quot;);            for (MessageQueue messageQueue : msgQueues) {                //从RMQ_SYS_TRANS_OP_HALF_TOPIC消息队列中获取到prepare消息对应的op消息（确认消息）                MessageQueue opQueue = getOpQueue(messageQueue);                //prepare消息的offset                long halfOffset = transactionalMessageBridge.fetchConsumeOffset(messageQueue);                //prepare消息                MessageExt msgExt = getHalfMsg(messageQueue, i);                //中间会有一堆的逻辑判断用于是否需要回查事务状态。                //例如：是否超过了回查的次数（默认五次）、消息是否已经失效了、对应的op消息是否已经处理了等。                if (isNeedCheck) {                    //交给线程池异步处理回调查询事务的状态。                    listener.resolveHalfMsg(msgExt);                }            }    }}</code></pre><p>大概的处理思路是：<br>broker维护一个死循环，每一分钟执行一次，broker通过使用两个内部队列：<br>RMQ_SYS_TRANS_HALF_TOPIC、RMQ_SYS_TRANS_OP_HALF_TOPIC来存储事务消息推进状态，<br>服务端通过比对两个队列的差值来找到尚未提交的超时事务，调用Producer端，用来查询事务处理结果。</p><h4 id="Producer端接收broker回查的逻辑"><a href="#Producer端接收broker回查的逻辑" class="headerlink" title="Producer端接收broker回查的逻辑"></a>Producer端接收broker回查的逻辑</h4><pre><code class="angular2html">//接收broker的回调，回查本地事务情况，进行相应处理@Overridepublic void checkTransactionState(final String addr, final MessageExt msg,final CheckTransactionStateRequestHeader header) {    //处理broker检查本地事务处理情况的回调任务    Runnable request = new Runnable() {        @Override        public void run() {                //执行TransactionListener实现的checkLocalTransaction方法，检查本地事务处理情况。                LocalTransactionState localTransactionState = transactionCheckListener.checkLocalTransaction(message);                //将检查本地事务处理情况再次发送给broker。                this.processTransactionState(localTransactionState,group,exception);        }        //处理本地事务处理的结果反馈        private void processTransactionState(final LocalTransactionState localTransactionState,final String producerGroup,final Throwable exception) {            final EndTransactionRequestHeader thisHeader = new EndTransactionRequestHeader();            ...            根据检查到的本地事务执行的不同结果封装成不同的处理类型发送给broker            switch (localTransactionState) {                case COMMIT_MESSAGE:                    thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE);                    break;                case ROLLBACK_MESSAGE:                    thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE);                    break;                case UNKNOW:                    thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE);                    break;                default:                    break;            }            //结果反馈给broker            DefaultMQProducerImpl.this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr,thisHeader,remark,3000);        }    };    //提交任务到线程池    this.checkExecutor.submit(request);}</code></pre><p>大致的处理思路是：<br>Producer端一个线程池维护执行TransactionListener的executeLocalTransaction实现，也就是本地事务方法的任务。将查询到的本地事务结果反馈给broker端，broker来决定对事务消息如何处理。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;事务的必要性&quot;&gt;&lt;a href=&quot;#事务的必要性&quot; class=&quot;headerlink&quot; title=&quot;事务的必要性&quot;&gt;&lt;/a&gt;事务的必要性&lt;/h4&gt;&lt;p&gt;一般提到事务，首先想到的就是 MySQL 的 transaction，但是很多场景，仅仅依靠 MySQL, 
      
    
    </summary>
    
    
      <category term="http" scheme="http://8090lambert.cn/tags/http/"/>
    
  </entry>
  
  <entry>
    <title>从 Ethernet 到 tcp 包分析</title>
    <link href="http://8090lambert.cn/2019/01/27/%E4%BB%8EEthernet%E5%88%B0tcp/"/>
    <id>http://8090lambert.cn/2019/01/27/从Ethernet到tcp/</id>
    <published>2019-01-27T13:28:41.000Z</published>
    <updated>2021-05-09T14:50:16.597Z</updated>
    
    <content type="html"><![CDATA[<h2 id="以太网帧格式"><a href="#以太网帧格式" class="headerlink" title="以太网帧格式"></a>以太网帧格式</h2><blockquote><p>“ 以太网是一种计算机局域网技术。IEEE组织的IEEE 802.3标准制定了以太网的技术标准，它规定了包括物理层的连线、电子信号和介质访问层协议的内容。以太网是目前应用最普遍的局域网技术，取代了其他局域网技术如令牌环、FDDI和ARCNET。”  – Wiki百科</p></blockquote><p>从 Xerox 公布的 Ethernet I 发展到现在，有过6种以太帧格式：  </p><ul><li>Ethernet I</li><li>Ethernet II</li><li>Ethernet 802.3 raw</li><li>Ethernet 802.3 SAP</li><li>802.3/802.2 LLC</li><li>802.3/802.2 SNAP  </li></ul><p>其中主流应用的是 Ethernet II、802.3/802.2 LLC、802.3/802.2 SNAP 这三种，最常用的是 RFC894 定义，也就是 Ethernet II 的帧格式。</p><h3 id="Ethernet-II"><a href="#Ethernet-II" class="headerlink" title="Ethernet II"></a>Ethernet II</h3><p><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191031161211.png" alt=""></p><ul><li>目标 MAC 地址：6个字节（48位），发送时会先检查目标 MAC 的地址，与当前适配器的物理地址是否一致，不一致就丢弃；</li><li>源 MAC 地址：6个字段（48位），发送帧的网络适配器物理地址</li><li>类型：上层协议的类型，常见的有，0x0800 表示是 IPV4 协议，0x0806 表示是 ARP 协议，0x86DD 表示是 IPV6 协议，更多<a href="https://en.wikipedia.org/wiki/EtherType#Examples" target="_blank" rel="noopener">详见</a></li><li>数据报文：最小 46 字节，最大 1500 字节（MTU）</li></ul><h3 id="802-3-802-2-LLC"><a href="#802-3-802-2-LLC" class="headerlink" title="802.3/802.2 LLC"></a>802.3/802.2 LLC</h3><p><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191031163803.png" alt=""></p><ul><li>DASP：1个字节，目的服务访问点</li><li>SSAP：1个字节，源服务访问点<br>将 Ethernet II 帧头的<code>类型</code>字段替换为帧<code>长度</code>，并且因为新增加了 DASP, SSAP，Control这三个各占1字节的字段，报文的长度也调整为：43~1497，它们三个字段作为 LLC 的头</li></ul><h3 id="802-3-802-2-SNAP"><a href="#802-3-802-2-SNAP" class="headerlink" title="802.3/802.2 SNAP"></a>802.3/802.2 SNAP</h3><p><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191031165124.png" alt=""></p><ul><li>类型：2个字节，不同于 Ethernet II 的类型字段</li><li>OUI ID：3个字节，通常都为 0<br>数据报文变为：38~1492字节   </li></ul><p>Ethernet 帧，从最上层（应用层）发送的数据单元（PDU），每经过一层，都会把上层整个的 PDU 作为下层 PDU 的 data 域，然后加上<br>自己的协议头；接受端，同下而上的层层拆掉每层的头部。了解了这些，我们尝试抓包具体分析每个字段</p><h2 id="Tcp-报文"><a href="#Tcp-报文" class="headerlink" title="Tcp 报文"></a>Tcp 报文</h2><p><code>$ tcpdump -i eth1 port 9527 -s 0 -w ./target9527.cap</code><br>用 <code>wireshark</code> 打开抓到的二进制报文，如图所示：<br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191031172528.png" alt=""></p><h3 id="建立连接"><a href="#建立连接" class="headerlink" title="建立连接"></a>建立连接</h3><p>Frame 1，表示第1帧，源ip和目的ip分别是：172.24.31.67 和 10.96.77.128，都是内网ip。<br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191031180719.png" alt=""></p><ul><li>type：0x0800 表示 IPV4</li><li>源 MAC 地址：04:25:c5:83:f5:64</li><li>目标设备mac地址：5e:38:57:10:84:d9</li><li>Flags：0x4000，没有拆包，如果请求报文大于 MTU，会拆多次发送</li><li>Times to live：ttl，存活时间，数据包每经过一个三层路由器设备时，ttl域的值减1，当其存活次数为0时，便会取消数据包的转发。ttl，默认值是64，如下图，经过 14 次到达目标ip，所有64-13=51<br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191031182456.png" alt=""></li><li>SYN：1，表示 请求及建立连接，包括剩下的两次握手请求包<br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191031193822.png" alt=""><br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191031194009.png" alt=""></li></ul><h3 id="发送数据包"><a href="#发送数据包" class="headerlink" title="发送数据包"></a>发送数据包</h3><p><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191101175300.png" alt=""><br>从 Frame 4 至 Frame 7 是建立连接后，发送具体请求的数据包。首先，发送了 HTTP 协议的 GET 请求，收到请求后回复了ACK。具体看下：<br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191101180306.png" alt=""></p><ul><li>在 GET 请求时，设置了标志位 ACK 和 <code>PSH</code>，<code>PSH</code> 是告诉接收端，立即交由应用层处理而不必等到<code>Recv socket buffer</code>写满</li><li>接收端回复 ACK 和 Seq number，接收端和发送端同样会再回复一个<code>PSH</code>标记的包，要求立即处理</li><li>最后，应用层通过 HTTP 协议回复报文，在回复报文时，<strong>这里要注意还有个标志位</strong>，在报文中，FIN=1，表示在返回的同时请求关闭连接<br><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191101181658.png" alt=""></li></ul><h3 id="断开连接"><a href="#断开连接" class="headerlink" title="断开连接"></a>断开连接</h3><p><img src="https://raw.githubusercontent.com/8090Lambert/material/master/20191101192901.png" alt=""><br>tcp 连接是双工的，所以任何建立连接的双方都可以发起关闭连接的请求。自己之前面试也总喜欢问这些问题，看看候选人到底理解的是否透彻，<br>可是大多数都不怎么清楚。言归正传，剩下的 Frame 8 至 Frame 11 是回复详情的 ACK 和 端开连接的 tcp 包。</p><ul><li>Frame 8 和 Frame 9，分别回复的是，Frame 6 <code>PSH</code>标志位的请求和 Frame 7 的 HTTP 请求</li><li>Frame 10 是连接另一边发起了关闭连接的请求，标志位 FIN=1</li><li>Frame 11 是发起关闭请求方，回复上一个 FIN=1 的 ACK 请求包 </li></ul><p>四次挥手全部结束。有同学可以会比较疑惑，不是应该是4次请求吗，这里只有三次。<strong>解释下这个问题：因为服务端在响应HTTP请求时，因为知道自己已经发送完全部数据，所以在响应包里加上了四次挥手中的第一次 FIN=1 的请求</strong>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;以太网帧格式&quot;&gt;&lt;a href=&quot;#以太网帧格式&quot; class=&quot;headerlink&quot; title=&quot;以太网帧格式&quot;&gt;&lt;/a&gt;以太网帧格式&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;“ 以太网是一种计算机局域网技术。IEEE组织的IEEE 802.3标准制定了以太
      
    
    </summary>
    
    
      <category term="http" scheme="http://8090lambert.cn/tags/http/"/>
    
  </entry>
  
  <entry>
    <title>epoll究竟快在哪</title>
    <link href="http://8090lambert.cn/2018/12/06/epoll%E7%A9%B6%E7%AB%9F%E5%BF%AB%E5%9C%A8%E5%93%AA/"/>
    <id>http://8090lambert.cn/2018/12/06/epoll究竟快在哪/</id>
    <published>2018-12-06T07:51:15.000Z</published>
    <updated>2021-05-09T14:50:16.596Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么-epoll-这么快"><a href="#为什么-epoll-这么快" class="headerlink" title="为什么 epoll 这么快"></a>为什么 epoll 这么快</h3><p>epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,在开始讨论这个问题之前,先来解释一下为什么需要多路复用IO.  </p><p>以一个生活中的例子来解释.</p><p>假设你在大学中读书,要等待一个朋友来访,而这个朋友只知道你在A号楼,但是不知道你具体住在哪里,于是你们约好了在A号楼门口见面.<br>如果你使用的阻塞IO模型来处理这个问题,那么你就只能一直守候在A号楼门口等待朋友的到来,在这段时间里你不能做别的事情,不难知道,这种方式的效率是低下的.  </p><p>现在时代变化了,开始使用多路复用IO模型来处理这个问题.你告诉你的朋友来了A号楼找楼管大妈,让她告诉你该怎么走.这里的楼管大妈扮演的就是多路复用IO的角色.  </p><p>进一步解释select和epoll模型的差异.</p><p>select版大妈做的是如下的事情:比如同学甲的朋友来了,select版大妈比较笨,她带着朋友挨个房间进行查询谁是同学甲,你等的朋友来了,于是在实际的代码中,select版大妈做的是以下的事情:</p><pre><code class="angularjs">int n = select(&amp;readset,NULL,NULL,100);for (int i = 0; n &gt; 0; ++i){    if (FD_ISSET(fdarray[i], &amp;readset))    {        do_something(fdarray[i]);        --n;    }}</code></pre><p>epoll版大妈就比较先进了,她记下了同学甲的信息,比如说他的房间号,那么等同学甲的朋友到来时,只需要告诉该朋友同学甲在哪个房间即可,不用自己亲自带着人满大楼的找人了.于是epoll版大妈做的事情可以用如下的代码表示:</p><pre><code class="angularjs">n = epoll_wait(epfd,events,20,500); for(i=0;i&lt;n;++i){    do_something(events[n]);}</code></pre><p>在epoll中,关键的数据结构epoll_event定义如下:</p><pre><code class="angularjs">typedef union epoll_data {    void *ptr;    int fd;    __uint32_t u32;    __uint64_t u64;} epoll_data_t;struct epoll_event {    __uint32_t events;      /* Epoll events */    epoll_data_t data;      /* User data variable */}</code></pre><p>可以看到,epoll_data是一个union结构体,它就是epoll版大妈用于保存同学信息的结构体,它可以保存很多类型的信息:fd,指针,等等.有了这个结构体,epoll大妈可以不用吹灰之力就可以定位到同学甲.</p><p>别小看了这些效率的提高,在一个大规模并发的服务器中,轮询IO是最耗时间的操作之一.再回到那个例子中,如果每到来一个朋友楼管大妈都要全楼的查询同学,那么处理的效率必然就低下了,过不久楼底就有不少的人了.</p><p>对比最早给出的阻塞IO的处理模型, 可以看到采用了多路复用IO之后, 程序可以自由的进行自己除了IO操作之外的工作, 只有到IO状态发生变化的时候由多路复用IO进行通知, 然后再采取相应的操作, 而不用一直阻塞等待IO状态发生变化了.</p><p>从上面的分析也可以看出,epoll比select的提高实际上是一个用空间换时间思想的具体应用.</p><h3 id="深入理解epoll的实现原理"><a href="#深入理解epoll的实现原理" class="headerlink" title="深入理解epoll的实现原理"></a>深入理解epoll的实现原理</h3><p>开发高性能网络程序时，windows开发者们言必称iocp，linux开发者们则言必称epoll。大家都明白epoll是一种IO多路复用技术，可以非常高效的处理数以百万计的socket句柄，比起以前的select和poll效率高大发了。我们用起epoll来都感觉挺爽，确实快，那么，它到底为什么可以高速处理这么多并发连接呢？</p><p>先简单回顾下如何使用C库封装的3个epoll系统调用吧。</p><pre><code class="angularjs">int epoll_create(int size)int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout)</code></pre><p>使用起来很清晰，首先要调用epoll_create建立一个epoll对象。参数size是内核保证能够正确处理的最大句柄数，多于这个最大数时内核可不保证效果。<br>epoll_ctl可以操作上面建立的epoll，例如，将刚建立的socket加入到epoll中让其监控，或者把 epoll正在监控的某个socket句柄移出epoll，不再监控它等等。<br>epoll_wait在调用时，在给定的timeout时间内，当在监控的所有句柄中有事件发生时，就返回用户态的进程。</p><p>从上面的调用方式就可以看到epoll比select/poll的优越之处：因为后者每次调用时都要传递你所要监控的所有socket给select/poll系统调用，这意味着需要将用户态的socket列表copy到内核态，如果以万计的句柄会导致每次都要copy几十几百KB的内存到内核态，非常低效。而我们调用epoll_wait时就相当于以往调用select/poll，但是这时却不用传递socket句柄给内核，因为内核已经在epoll_ctl中拿到了要监控的句柄列表。</p><p>所以，实际上在你调用epoll_create后，内核就已经在内核态开始准备帮你存储要监控的句柄了，每次调用epoll_ctl只是在往内核的数据结构里塞入新的socket句柄。</p><p>对于linux操作系统而言，一切皆文件。所以，epoll向内核注册了一个文件系统，用于存储上述的被监控socket。当你调用epoll_create时，就会在这个虚拟的epoll文件系统里创建一个file结点。当然这个file不是普通文件，它只服务于epoll。</p><p>epoll在被内核初始化时（操作系统启动），同时<strong>会开辟出epoll自己的内核高速cache区</strong>，用于安置每一个我们想监控的socket，这些socket会<strong>以红黑树的形式</strong>保存在内核cache里，以支持快速的查找、插入、删除。这个内核高速cache区，就是建立连续的物理内存页，然后在之上建立slab层，简单的说，就是物理上分配好你想要的size的内存对象，每次使用时都是使用空闲的已分配好的对象。</p><pre><code class="angularjs">static int __init eventpoll_init(void)  {      ... ...      /* Allocates slab cache used to allocate &quot;struct epitem&quot; items */      epi_cache = kmem_cache_create(&quot;eventpoll_epi&quot;, sizeof(struct epitem),              0, SLAB_HWCACHE_ALIGN|EPI_SLAB_DEBUG|SLAB_PANIC,              NULL, NULL);      /* Allocates slab cache used to allocate &quot;struct eppoll_entry&quot; */      pwq_cache = kmem_cache_create(&quot;eventpoll_pwq&quot;,              sizeof(struct eppoll_entry), 0,              EPI_SLAB_DEBUG|SLAB_PANIC, NULL, NULL);  ... ...</code></pre><p>epoll的高效就在于，当我们调用epoll_ctl往里塞入百万个句柄时，epoll_wait仍然可以飞快的返回，并有效的将发生事件的句柄给我们用户。这是由于我们在调用epoll_create时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。</p><p>而且，通常情况下<strong>即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait仅需要从内核态copy少量的句柄到用户态而已，如何能不高效？！</strong></p><p>那么，这个准备就绪list链表是怎么维护的呢？当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。</p><p>如此，一颗红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。执行epoll_create时，创建了红黑树和就绪链表，执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据。执行epoll_wait时立刻返回准备就绪链表里的数据即可。</p><p>最后看看epoll独有的两种模式LT和ET。无论是LT和ET模式，都适用于以上所说的流程。区别是，LT模式下，只要一个句柄上的事件一次没有处理完，会在以后调用epoll_wait时次次返回这个句柄，而ET模式仅在第一次返回。</p><p>这件事怎么做到的呢？当一个socket句柄上有事件时，内核会把该句柄插入上面所说的准备就绪list链表，这时我们调用epoll_wait，会把准备就绪的socket拷贝到用户态内存，然后清空准备就绪list链表，最后，epoll_wait干了件事，就是检查这些socket，如果不是ET模式（就是LT模式的句柄了），并且这些socket上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表了。所以，非ET的句柄，只要它上面还有事件，epoll_wait每次都会返回。而ET模式的句柄，除非有新中断到，即使socket上的事件没有处理完，也是不会次次从epoll_wait返回的。</p><h3 id="扩展阅读（epoll与之前其他相关技术的比较）"><a href="#扩展阅读（epoll与之前其他相关技术的比较）" class="headerlink" title="扩展阅读（epoll与之前其他相关技术的比较）"></a>扩展阅读（epoll与之前其他相关技术的比较）</h3><p>Linux提供了select、poll、epoll接口来实现IO复用，三者的原型如下所示，本文从参数、实现、性能等方面对三者进行对比。</p><pre><code class="angularjs">int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); int poll(struct pollfd *fds, nfds_t nfds, int timeout); int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); </code></pre><p>select、poll、epoll_wait参数及实现对比 ：  </p><ul><li>select的第一个参数nfds为fdset集合中最大描述符值加1，fdset是一个位数组，其大小限制为__FD_SETSIZE（1024），位数组的每一位代表其对应的描述符是否需要被检查；  </li></ul><p>select的第二三四个参数表示需要关注读、写、错误事件的文件描述符位数组，这些参数既是输入参数也是输出参数，可能会被内核修改用于标示哪些描述符上发生了关注的事件。所以每次调用select前都需要重新初始化fdset。   </p><p>select对应于内核中的sys_select调用，sys_select首先将第二三四个参数指向的fd_set拷贝到内核，然后对每个被SET的描述符调用进行poll，并记录在临时结果中（fdset），如果有事件发生，select会将临时结果写到用户空间并返回；当轮询一遍后没有任何事件发生时，如果指定了超时时间，则select会睡眠到超时，睡眠结束后再进行一次轮询，并将临时结果写到用户空间，然后返回。 </p><p>select返回后，需要逐一检查关注的描述符是否被SET（事件是否发生）。 </p><ul><li>poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。 </li></ul><p>poll的实现机制与select类似，其对应内核中的sys_poll，只不过poll向内核传递pollfd数组，然后对pollfd中的每个描述符进行poll，相比处理fdset来说，poll效率更高。 </p><p>poll返回后，需要对pollfd中的每个元素检查其revents值，来得指事件是否发生。 </p><ul><li>epoll通过epoll_create创建一个用于epoll轮询的描述符，通过epoll_ctl添加/修改/删除事件，通过epoll_wait检查事件，epoll_wait的第二个参数用于存放结果。 </li></ul><p>epoll与select、poll不同，首先，其不用每次调用都向内核拷贝事件描述信息，在第一次调用后，事件信息就会与对应的epoll描述符关联起来。另外epoll不是通过轮询，而是通过在等待的描述符上注册回调函数，当事件发生时，回调函数负责把发生的事件存储在就绪事件链表中，最后写到用户空间。 </p><p>epoll返回后，该参数指向的缓冲区中即为发生的事件，对缓冲区中每个元素进行处理即可，而不需要像poll、select那样进行轮询检查。 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;为什么-epoll-这么快&quot;&gt;&lt;a href=&quot;#为什么-epoll-这么快&quot; class=&quot;headerlink&quot; title=&quot;为什么 epoll 这么快&quot;&gt;&lt;/a&gt;为什么 epoll 这么快&lt;/h3&gt;&lt;p&gt;epoll是多路复用IO(I/O Multiplex
      
    
    </summary>
    
    
      <category term="http" scheme="http://8090lambert.cn/tags/http/"/>
    
  </entry>
  
  <entry>
    <title>对比IO和IO多路复用模型</title>
    <link href="http://8090lambert.cn/2018/12/04/%E5%AF%B9%E6%AF%94IO%E5%92%8CIO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B/"/>
    <id>http://8090lambert.cn/2018/12/04/对比IO和IO多路复用模型/</id>
    <published>2018-12-04T06:51:15.000Z</published>
    <updated>2021-05-09T14:50:16.599Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IO-模式-和-IO-多路复用"><a href="#IO-模式-和-IO-多路复用" class="headerlink" title="IO 模式 和 IO 多路复用"></a>IO 模式 和 IO 多路复用</h2><h4 id="用户空间和内核空间"><a href="#用户空间和内核空间" class="headerlink" title="用户空间和内核空间"></a>用户空间和内核空间</h4><p>&emsp;&emsp;现在操作系统都采用虚拟寻址，<strong>处理器先产生一个虚拟地址，通过地址翻译成物理地址（内存的地址）</strong>，再通过总线的传递，最后处理器拿到某个物理地址返回的字节。</p><p>&emsp;&emsp;对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。</p><p>&emsp;&emsp;<strong>补充：地址空间就是一个非负整数地址的有序集合。如{0,1,2…}。</strong></p><h4 id="进程上下文切换"><a href="#进程上下文切换" class="headerlink" title="进程上下文切换"></a>进程上下文切换</h4><p>&emsp;&emsp;为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换（也叫调度）。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。</p><p>&emsp;&emsp;从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：</p><ul><li>保存当前进程A的上下文<blockquote><p>上下文就是内核再次唤醒当前进程时所需要的状态，由一些对象（程序计数器、状态寄存器、用户栈等各种内核数据结构）的值组成。这些值包括描绘地址空间的页表、包含进程相关信息的进程表、文件表等。</p></blockquote></li><li>切换页全局目录以安装一个新的地址空间</li><li>恢复进程B的上下文</li><li>处理B进程逻辑</li><li>恢复进程A的上下文</li><li>…  <blockquote><p>可以理解成一个比较耗资源的过程</p></blockquote></li></ul><h4 id="进程的阻塞"><a href="#进程的阻塞" class="headerlink" title="进程的阻塞"></a>进程的阻塞</h4><p>&emsp;&emsp;正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。</p><h4 id="文件描述符（FD）"><a href="#文件描述符（FD）" class="headerlink" title="文件描述符（FD）"></a>文件描述符（FD）</h4><p>&emsp;&emsp;文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。<br>&emsp;&emsp;文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。对于UNIX、Linux这样的操作系统的设计初衷就是：一切皆文件。</p><h4 id="直接I-O和缓存I-O"><a href="#直接I-O和缓存I-O" class="headerlink" title="直接I/O和缓存I/O"></a>直接I/O和缓存I/O</h4><p>&emsp;&emsp;缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，以write为例，数据会先被拷贝进程缓冲区，在拷贝到操作系统内核的缓冲区中，然后才会写到存储设备中。</p><p><strong>缓存I/O的write</strong><br><img src="https://8090lambert.cn/images/blog/io/01.png" alt="缓存I/O的write"></p><p><strong>直接I/O的write：（省去了拷贝到进程缓冲区这一步）</strong><br><img src="https://8090lambert.cn/images/blog/io/02.png" alt="直接I/O的write"></p><p><strong>write过程中会有很多次拷贝，知道数据全部写到磁盘。好了，准备知识概略复习了一下，开始探讨IO模式。</strong></p><h4 id="I-O模式"><a href="#I-O模式" class="headerlink" title="I/O模式"></a>I/O模式</h4><p>&emsp;&emsp;对于一次IO访问（这回以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的缓冲区，最后交给进程。所以说，当一个read操作发生时，它会<strong>经历两个阶段</strong>：</p><ul><li>等待数据准备 (Waiting for the data to be ready)</li><li>将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)</li></ul><p>因为这两个阶段，linux系统产生了下面五种网络I/O的模式：</p><ul><li>阻塞 I/O（blocking IO）</li><li>非阻塞 I/O（nonblocking IO）</li><li>I/O 多路复用（ IO multiplexing）</li><li>信号驱动 I/O（ signal driven IO）</li><li>异步 I/O（asynchronous IO）<br>信号驱动在实际中并不常用，所以只讨论其他四种</li></ul><h4 id="Block-I-O-模型（阻塞I-O）"><a href="#Block-I-O-模型（阻塞I-O）" class="headerlink" title="Block I/O 模型（阻塞I/O）"></a>Block I/O 模型（阻塞I/O）</h4><p><img src="https://8090lambert.cn/images/blog/io/03.png" alt="阻塞I/O模型"><br>&emsp;&emsp;还是以read为例子</p><ul><li>进程发起 read，进行 recvfrom 系统调用；</li><li>内核开始第一阶段，准备数据（从磁盘拷贝到缓冲区），进程请求的数据并不是一下就能准备好；准备数据是要消耗时间的；</li><li>与此同时，进程阻塞（进程是自己选择阻塞与否），等待数据ing；</li><li>直到数据从内核拷贝到了用户空间，内核返回结果，进程解除阻塞。</li></ul><p>也就是说，<strong>内核准备数据和数据从内核拷贝到进程内存地址</strong>这两个过程都是阻塞的。</p><h4 id="None-Block-I-O-模型（非阻塞I-O）"><a href="#None-Block-I-O-模型（非阻塞I-O）" class="headerlink" title="None-Block I/O 模型（非阻塞I/O）"></a>None-Block I/O 模型（非阻塞I/O）</h4><p>&emsp;&emsp;可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：<br><img src="https://8090lambert.cn/images/blog/io/04.png" alt="非阻塞I/O"></p><ul><li>当用户进程发出 <code>read</code> 操作时，如果 <code>Kernel</code> 中的数据还没有准备好；</li><li>那么它并不会 block 用户进程，而是立刻返回一个 error，从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果；</li><li>用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 <code>system call</code>；</li><li>那么它马上就将数据拷贝到了用户内存，然后返回。</li></ul><p>Non-Block IO的特点是用户进程在内核准备数据的阶段<strong>需要不断的主动询问</strong>数据好了没有。</p><h4 id="Multiplexing-I-O-多路复用I-O"><a href="#Multiplexing-I-O-多路复用I-O" class="headerlink" title="Multiplexing I/O (多路复用I/O)"></a>Multiplexing I/O (多路复用I/O)</h4><p>&emsp;&emsp;I/O多路复用实际上就是用select, poll, epoll监听多个io对象，当io对象有变化（有数据）的时候就通知用户进程。好处就是单个进程可以处理多个socket。当然具体区别我们后面再讨论，现在先来看下I/O多路复用的流程：<br><img src="https://8090lambert.cn/images/blog/io/05.png" alt="I/O多路复用模型"></p><ul><li>当用户进程调用了 select，那么整个进程会被 block；</li><li>而同时，kernel 会“监视”所有 select 负责的 socket；</li><li>当任何一个 socket 中的数据准备好了，select就会返回;</li><li>这个时候用户进程再调用 read 操作，将数据从 kernel 拷贝到用户进程;<br>&emsp;&emsp;I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select() 函数就可以返回。<br>&emsp;&emsp;这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。<br>&emsp;&emsp;所以，<strong>如果处理的连接数不是很高的话，使用 select/epoll 的 web server 不一定比使用多线程 + 阻塞 IO的 web server 性能更好，可能延迟还更大</strong>。select/epoll 的优势<strong>并不是对于单个连接能处理得更快，而是在于能处理更多的连接。</strong><br>在IO multiplexing Model中，实际中，对于每一个 socket，一般都设置成为 none-block，但是，如上图所示，整个用户的 process 其实是一直被 block 的。只不过 process 是被 select 这个函数 block，而不是被 socket IO 给 block (<strong>对应 epoll 的就是 epoll_wait() 会 block 住 process</strong>)。</li></ul><h4 id="Asynchronous-I-O（异步-I-O）"><a href="#Asynchronous-I-O（异步-I-O）" class="headerlink" title="Asynchronous I/O（异步 I/O）"></a>Asynchronous I/O（异步 I/O）</h4><p>异步 I/O 是真正做到了非阻塞，流程大概如下：<br><img src="https://8090lambert.cn/images/blog/io/06.png" alt=""></p><ul><li>用户进程发起read操作之后，立刻就可以开始去做其它的事。</li><li>而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。</li><li>然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。<br><br><br><br></li></ul><blockquote><p>Reference： <a href="https://www.cnblogs.com/wangyao2317072926/p/7918643.html" target="_blank" rel="noopener">https://www.cnblogs.com/wangyao2317072926/p/7918643.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;IO-模式-和-IO-多路复用&quot;&gt;&lt;a href=&quot;#IO-模式-和-IO-多路复用&quot; class=&quot;headerlink&quot; title=&quot;IO 模式 和 IO 多路复用&quot;&gt;&lt;/a&gt;IO 模式 和 IO 多路复用&lt;/h2&gt;&lt;h4 id=&quot;用户空间和内核空间&quot;&gt;&lt;a
      
    
    </summary>
    
    
      <category term="http" scheme="http://8090lambert.cn/tags/http/"/>
    
  </entry>
  
  <entry>
    <title>Redis-字典</title>
    <link href="http://8090lambert.cn/2018/11/29/Redis-%E5%AD%97%E5%85%B8/"/>
    <id>http://8090lambert.cn/2018/11/29/Redis-字典/</id>
    <published>2018-11-29T14:51:47.000Z</published>
    <updated>2021-05-09T14:50:16.595Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 还有一种比较常用的数据类型，字典。C 语言没有这种数据结构，但是 在JAVA 语言中的 <code>map</code>，和 PHP 语言里的 关联数组，就是这种类型，它用来保存 <code>key</code> =&gt; <code>value</code> 的键值对，要求键必须是唯一，在字段中，已知一个 <code>key</code>，对这个的 <code>key</code> 对应 <code>value</code> 做 CRUD操作，都非常方便。</p><p>Redis 自己实现了这个结构，并且用它来作 哈希键的底层实现之一，如果 <strong>一个哈希类型包含的键值对较多</strong> 或者 <strong>键值对中的元素都是较长的字符串</strong>，就会用 字典 来作为它的实现。数据库的 CRUD 操作也是作用在 字典上。具体的源码在文件 <code>src/dict.h</code>，它的底层使用哈希表，哈希表内部可以拥有多个节点，每个节点上就存储这一个键值对。</p><pre><code class="angular2html">// 哈希表typedef struct dictht {    dictEntry **table;  // 哈希表数组    unsigned long size; // 哈希表大小，一般是2的指数    unsigned long sizemask; // 哈希表掩码，等于 size - 1    unsigned long used; // 哈希表已有节点数量，used / size 这个是装载因子，比值越大，hash冲突月 } dictht;// 哈希表节点typedef struct dictEntry {    void *key;    union {        void *val;        uint64_t u64;        int64_t s64;        double d;    } v;    struct dictEntry *next;} dictEntry;</code></pre><p>在 <code>dictht</code> 结构体中 <code>table</code> 数组中的每个元素，都是一个指向哈希表节点 <code>dictEntry</code> 的指针，<code>size</code> 标识dictEntry指针数组，就是 <code>table</code> 数组的长度，它总是2的指数；<code>sizemask</code> 的值为 <code>size - 1</code>， 这个属性和哈希值决定了一个键要被放在 <code>table</code> 数组的哪个索引位置上（通过hash &amp; sizemask计算出），<code>used</code> 的属性则记录了哈希表目前已有节点的数量，size / used 是装在因子，这个值越大，哈希冲突的概率就越高。</p><p>这个就是 <code>dict</code> 和 <code>dictEntry</code> 的结构示意：</p><p><img src="http://8090lambert.cn/images/blog/dict/dict_01.png" alt=""></p><p><code>dictEntry</code> 结构是哈希表的节点，其中 <code>key</code> 是键值对的键，而 <code>v</code> 是键值对的值，<code>v</code> 中可以是一个指针、uint64 的整数、uint64的整数或者是一个 double 的浮点数，<code>next</code> 属性是指向下一个哈希表节点 <code>dictEntry</code> 结构体的指针，所谓下一个哈希表节点，就是当哈希键 <code>key</code> 相同的哈希表节点，它们会挨个排列，前一个的 <code>next</code> 指针指向后一个。</p><h2 id="Hash键冲突"><a href="#Hash键冲突" class="headerlink" title="Hash键冲突"></a>Hash键冲突</h2><p>Redis 使用 MurmurHash 算法来计算键的hash值，虽然在效率上和随机性上很好，但是还是会产生 hash冲突。<br>针对这个问题，采用了 拉链法 解决冲突。<code>next</code> 指针，表示两个相同的hash组成的一个链表。<br>包含多个键hash值相同的情况：</p><p><img src="http://8090lambert.cn/images/blog/dict/dict_02.png" alt=""></p><p>每次冲突时，都会从头部插入新的键，时间复杂度保证都是O(1)。</p><p>在 <code>dict</code> 结构体里，管理这两个的 <code>dictht</code></p><pre><code class="angular2html">typedef struct dict {    dictType *type;    void *privdata;    dictht ht[2];    long rehashidx; /* rehashing not in progress if rehashidx == -1 */    unsigned long iterators; /* number of iterators currently running */} dict;</code></pre><p><code>type</code> 和 <code>privdata</code> 属性是为实现多态字典而设置的，主要是用于不同类型的键值对。其实，<code>type</code> 是指向 <code>dictType</code> 结构的指针，在 <code>dictType</code> 结构体中，保存着一系列的方法：</p><pre><code>typedef struct dictType {    uint64_t (*hashFunction)(const void *key);  // 计算哈希值    void *(*keyDup)(void *privdata, const void *key);   // 复制键    void *(*valDup)(void *privdata, const void *obj);   // 复制值    int (*keyCompare)(void *privdata, const void *key1, const void *key2);  // 对比键    void (*keyDestructor)(void *privdata, void *key);   // 销毁键    void (*valDestructor)(void *privdata, void *obj);   // 销毁值} dictType;</code></pre><p><code>ht</code> 是拥有两个元素的数组，每个都是一个 <code>dictht</code>。一般情况，使用第1个索引位置的哈希表来存储，第二个索引位置的哈希表一般是做 <code>rehash</code> 时使用的。<code>rehashidx</code> 就是表示是否正在做 <code>rehash</code>，如果目前不是正在进行，它的值为 -1。<code>iterators</code> 是当前正在运行的迭代器数目。</p><pre><code class="angular2html">typedef struct dictIterator {    dict *d;    long index;    int table, safe;    dictEntry *entry, *nextEntry;    /* unsafe iterator fingerprint for misuse detection. */    long long fingerprint;} dictIterator; </code></pre><p>这是字典的迭代器。<code>d</code> 是指向字典的指针，<code>index</code> 是迭代器当前索引的位置。</p><h2 id="Rehash"><a href="#Rehash" class="headerlink" title="Rehash"></a>Rehash</h2><p>如果哈希表的数据变的越来越多，在装载因子（dictht 中 size / used 的比值）超过预定时，<br>这时，Redis 会对哈希表做 Rehash 操作，它采用的是一种增量式重哈希，就是将rehash的过程，<br>分散到所有对 dict 的增删改查操作中。<br>开始 rehash 后，所有的写入操作，都直接写入 ht[1] 里，同时，会将 ht[0] 哈希表在 rehashidx 上的所有键 rehash 至 ht[1]，<br>直到 ht[0] 中键的个数为 0时，rehash 结束。释放 ht[0], 再将 ht[1] 设为 ht[0], 重新申请一个空白哈希表作为新的 ht[1]。</p><p>##<br>Redis对于字典的操作就是这些，还有一些 API，没有做更深入的研究。 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Redis 还有一种比较常用的数据类型，字典。C 语言没有这种数据结构，但是 在JAVA 语言中的 &lt;code&gt;map&lt;/code&gt;，和 PHP 语言里的 关联数组，就是这种类型，它用来保存 &lt;code&gt;key&lt;/code&gt; =&amp;gt; &lt;code&gt;value&lt;/code&gt;
      
    
    </summary>
    
    
      <category term="redis" scheme="http://8090lambert.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>聊聊504、502和499的故事</title>
    <link href="http://8090lambert.cn/2018/11/27/%E8%81%8A%E8%81%8A504%E3%80%81502%E5%92%8C499%E7%9A%84%E6%95%85%E4%BA%8B/"/>
    <id>http://8090lambert.cn/2018/11/27/聊聊504、502和499的故事/</id>
    <published>2018-11-27T14:21:37.000Z</published>
    <updated>2021-05-09T14:50:16.599Z</updated>
    
    <content type="html"><![CDATA[<p>每次工作中碰到 5xx 的 http 状态码，都会比较头疼，又要排查了，每次都是从 nginx 的 <code>error_log</code> 追溯，<br>一直到 <code>php_error_log</code>，确定大概位置，翻代码…</p><p>恰巧碰到最近组内在学习 <code>nginx</code> 源码，打算深入研究一下，如果有可能让偶发事件成可控事件，那一定能明白<br>其中的原因，更快定位问题，对日后工作排查，应该会有帮助。</p><h3 id="Gateway-Time-out"><a href="#Gateway-Time-out" class="headerlink" title="Gateway Time-out"></a>Gateway Time-out</h3><blockquote><p>504错误是（网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。<br>服务器（不一定是 Web 服务器）正在作为一个网关或代理来完成客户（如您的浏览器或我们的 CheckUpDown 机器人）<br>访问所需网址的请求。 为了完成您的 HTTP 请求， 该服务器访问一个上游服务器， 但没得到及时的响应。</p></blockquote><p>这是维基百科上直译过来的一段话，网关超时，可以推测下，对于我们常见的服务模型来说，就是 <code>client</code> 请求到 <code>nginx</code>，<br><code>php-fpm</code> 未在 <code>nginx</code> 的最大执行时间内返回。试着构造一下：</p><ul><li>首先准备环境： </li><li><code>Ubuntu 18.04 LTS</code>；<code>nginx version: nginx/1.14.0 (Ubuntu)</code>; <code>PHP 7.2.14-1+ubuntu18.04.1+deb.sury.org+1 (cli)</code></li><li>修改 Nginx 中 <code>fastcgi_read_timeout</code> = 3，这个参数是说从 fastcgi 读取数据的最大时间，单位为秒<br><img src="http://8090lambert.cn/images/blog/http/http_01.png" alt="nginx.conf"></li><li>php 代码<br><img src="http://8090lambert.cn/images/blog/http/http_02.png" alt="index.php"><br>重启 nginx，直接在浏览器请求;<br><img src="http://8090lambert.cn/images/blog/http/http_03.png" alt=""></li></ul><p>和推测的完全吻合，通俗点说，<strong>就是 php 在 <code>nginx</code> 超时时间(设置的3s)内未返回，<code>nginx</code> 等不及，就会返回给客户端 504</strong>,<br>error_log 如下,<br><code>2018/11/28s 00:13:05 [error] 3540#3540: *3 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 192.168.10.1, server: mine.test, request: &quot;GET / HTTP/1.1&quot;, upstream: &quot;fastcgi://unix:/var/run/php/php7.2-fpm.sock&quot;, host: &quot;mine.test&quot;</code></p><h3 id="Bad-Gateway"><a href="#Bad-Gateway" class="headerlink" title="Bad Gateway"></a>Bad Gateway</h3><blockquote><p>502状态码是服务器（不一定是Web服务器）作为网关或代理，以满足客户的要求来访问所请求的URL 。此服务器收到无效响应从上游服务器访问履行它的要求。</p></blockquote><p><code>无效响应</code> 可以理解是下游服务（php-fpm）不可用</p><p>还是刚才的环境，这次，停掉 <code>php-fpm</code> 进程 (因为我是多版本共存的，nginx配置的是php7.2的php-fpm，剩下的都是7.1php-fpm的worker进程)<br><img src="http://8090lambert.cn/images/blog/http/http_04.png" alt="关闭php-fpm服务"><br>现在，访问刚才的url<br><img src="http://8090lambert.cn/images/blog/http/http_05.png" alt=""></p><p> 我们再模拟一种情况：在 <code>php-fpm.conf</code> 中有个参数设置</p><pre><code class="angularjs">; The timeout for serving a single request after which the worker process will; be killed. This option should be used when the &#39;max_execution_time&#39; ini option; does not stop script execution for some reason. A value of &#39;0&#39; means &#39;off&#39;.; Available units: s(econds)(default), m(inutes), h(ours), or d(ays); Default Value: 0request_terminate_timeout = 15</code></pre><p>每个 php-fpm 的 worker 进程如果执行时间超过，会被 kill 掉。就是 php-fpm 等待程序的最大时长，<br>修改为 <code>request_terminate_timeout = 3</code>，然后重启 php-fpm，刷新浏览器。<br>发现和刚才的情况一样，也是 nginx 返回给 clint 一个 502 的错误页面。</p><p>在 nginx 的 error_log 里会出现这样一条日志：<br><code>2018/11/28 00:20:43 [error] 3793#3793: *20 connect() to unix:/var/run/php/php7.2-fpm.sock failed (111: Connection refused) while connecting to upstream, client: 192.168.10.1, server: mine.test, request: &quot;GET / HTTP/1.1&quot;, upstream: &quot;fastcgi://unix:/var/run/php/php7.2-fpm.sock:&quot;, host: &quot;mine.test&quot;</code></p><p>同时，access_log 里也会增加一条日志：<br><code>192.168.10.1 - - [28/Nov/2018:00:20:43 +0800] &quot;GET / HTTP/1.1&quot; 504 594 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36&quot;</code></p><p>这两种情况，有个共同点：<strong>就是没有正常的返回给 nginx （不论是php-fpm服务不可用还是php-fpm等待超时，主动断开）。</strong></p><h3 id="Client-has-closed-connection"><a href="#Client-has-closed-connection" class="headerlink" title="Client has closed connection"></a>Client has closed connection</h3><p><code>499：客户端关闭连接</code> 这个乍一看，是客户端的锅，是它先“动手”，关闭连接的。从标准的 RFC2616 协议中，是没有 499 状态码，<br>是 nginx 自己定义的。</p><p>根据字面的意思，这种情况是客户端主动断开连接，或许是服务端在客户端最大等待时间内，没有返回结果，导致客户端等不及。<br>这次我们在终端试试（在写的时候，已用浏览器测试，奈何浏览器作为客户端，等待时间太长了，复现不了）。</p><p>服务端还是这行代码：</p><pre><code class="angularjs">&lt;?phpsleep(10);echo &quot;hello world&quot;;</code></pre><p>在终端执行，紧接着 <code>command + c</code> 强制终止进程</p><blockquote><p>$ curl <a href="http://mine.test" target="_blank" rel="noopener">http://mine.test</a></p></blockquote><p>从 nginx 的 access_log 中查看日志发现：<br><code>192.168.10.1 - - [28/Nov/2018:14:42:26 +0800] &quot;GET / HTTP/1.1&quot; 499 0 &quot;-&quot; &quot;curl/7.54.0&quot;</code></p><p>因为客户端主动断开，在下游的 nginx 就会有一条 499 的日志。在普通的 web 应用中很少见，但是<br>在微服务下，跨部门跨组之间的调用，都是 http 请求，如果下游的服务不够稳定，这种状态码一般很多。<br><strong>上游要保证，在连接等待的时候，必须有合理的超时时间，不能因为下游服务挂掉了，而拖垮自己，导致<br>整个服务雪崩。</strong></p><p>说到底，这三种状态码（不考虑php-fpm服务不可用时的502），都是 <code>nginx</code> 、<code>php-fpm</code> 和 <code>client</code> 中的<br>两者之间发生超时，只要能够分清是谁timeout，就能准确的判断会发生的情况。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;每次工作中碰到 5xx 的 http 状态码，都会比较头疼，又要排查了，每次都是从 nginx 的 &lt;code&gt;error_log&lt;/code&gt; 追溯，&lt;br&gt;一直到 &lt;code&gt;php_error_log&lt;/code&gt;，确定大概位置，翻代码…&lt;/p&gt;
&lt;p&gt;恰巧碰到最近组
      
    
    </summary>
    
    
      <category term="http" scheme="http://8090lambert.cn/tags/http/"/>
    
  </entry>
  
  <entry>
    <title>Redis-整数集合</title>
    <link href="http://8090lambert.cn/2018/11/11/Redis-%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/"/>
    <id>http://8090lambert.cn/2018/11/11/Redis-整数集合/</id>
    <published>2018-11-11T15:25:02.000Z</published>
    <updated>2021-05-09T14:50:16.595Z</updated>
    
    <content type="html"><![CDATA[<p>在 Redis 中，如果有用过它的 <code>set</code> 集合，底层的实现整数集合。<br>整数集合，就是只能包括整数值的元素，我们试着创建一个整数集合<br><img src="http://8090lambert.cn/images/blog/intset/inset_00.png" alt="创建一个整数集合"></p><p>它的结构很简单，具体的源码在 <code>src/intset.h</code> 文件中</p><pre><code>typedef struct intset {    uint32_t encoding;  // 编码类型    uint32_t length;    // 元素数量    int8_t contents[];  // 保存元素数组} intset;</code></pre><p>在 <code>contents</code> 数组中，集合的每个元素，都对应着数组的一个元素，<br>他们按照从小到大的顺序，有序的排列着，并且每个元素在数组中都是唯一的。<br><code>length</code> 记录了集合中现有元素的数量，可以 O（1）的方式，每次快速<br>返回 <code>contents</code> 数组的数量。<code>encoding</code> 属性是值，<code>contents</code> 数组<br>中的每个元素，都是以什么类型存的，共有三种类型：</p><pre><code>/* Note that these encodings are ordered, so: * INTSET_ENC_INT16 &lt; INTSET_ENC_INT32 &lt; INTSET_ENC_INT64. */#define INTSET_ENC_INT16 (sizeof(int16_t))  // int16, -2^15 ~ 2^15 - 1 #define INTSET_ENC_INT32 (sizeof(int32_t))  // int32, -2^31 ~ 2^31 - 1  #define INTSET_ENC_INT64 (sizeof(int64_t))  // int64, -2^63 ~ 2^63 - 1</code></pre><p>一个拥有5个int16类型的整数集合<br><img src="http://8090lambert.cn/images/blog/intset/inset_01.png" alt=""></p><h3 id="集合的类型转换"><a href="#集合的类型转换" class="headerlink" title="集合的类型转换"></a>集合的类型转换</h3><p>当我们需要往现有集合中增加插入一个整数的时候，如果要添加的整数的大小不满足<br>现有集合的编码类型，则需要对现有集合的每个元素转换类型。具体步骤：</p><ol><li>根据新元素的类型，扩展整数集合的空间大小；</li><li>将现有元素类型，转换为集合中最大数所属类型，保持原有顺序，再添加新元素至合适位置；</li><li>修改 <code>contents</code> 数组长度 <code>length</code> 和 编码类型 <code>encoding</code></li></ol><p>例如，有一个集合，包含3个元素，分别是 <code>1，2，3</code>，集合的 <code>encoding</code> 属性<br>为 <code>INTSET_ENC_INT16</code>，所占空间为 <code>3 * 16 = 48</code> 位，6个字节。现在要将<br>65535 添加到集合中，按照上面说的步骤：</p><ul><li>首先，因为 65535 超过 <code>INTSET_ENC_INT16</code>，属于 <code>INTSET_ENC_INT32</code> 范围内，<br>所以，需要对空间进行重新分配，新的空间需要 <code>4 * 32 = 128</code> 位，16个字节；</li><li>接着，从 96 ~ 127 位，留给最后一个 <code>65535</code> 元素，剩下的三个元素，从 95 位开始，<br>至 <code>96 - 32 = 64</code> 位，保存3，从 63 位开始至 <code>64 - 32 = 32</code> 位，保存2，剩下的<br>0 至 31 位，保存 1，最后将要插入的 65535 放入最先预留的 96 - 127 位；</li><li>将 <code>length</code> 改为4， <code>encoding</code> 改为 <code>INTSET_ENC_INT32</code></li></ul><p>至此，类型转换就完成了。整数集合，不会将高位的 <code>encoding</code>，改为低位，如果说，<br>因为增加元素 <code>encoding</code> 的类型改为高位，即使后来再删除元素，<code>encoding</code> 始终<br>就是增加时修改的值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在 Redis 中，如果有用过它的 &lt;code&gt;set&lt;/code&gt; 集合，底层的实现整数集合。&lt;br&gt;整数集合，就是只能包括整数值的元素，我们试着创建一个整数集合&lt;br&gt;&lt;img src=&quot;http://8090lambert.cn/images/blog/intset/
      
    
    </summary>
    
    
      <category term="redis" scheme="http://8090lambert.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis-跳跃表</title>
    <link href="http://8090lambert.cn/2018/11/02/Redis-%E8%B7%B3%E8%B7%83%E8%A1%A8/"/>
    <id>http://8090lambert.cn/2018/11/02/Redis-跳跃表/</id>
    <published>2018-11-02T14:04:20.000Z</published>
    <updated>2021-05-09T14:50:16.595Z</updated>
    
    <content type="html"><![CDATA[<p>有一种查询效率特别高的有序的数据结构，跳跃表（SkipList），这种结构，在Redis和levelDB中，都有用到。<br>其实是在有序链表的基础上进行扩展，丰富了在链表中查找制定值，需要 O（N）的时间复杂度的问题，它在查<br>询时，能做到最快 O（1），平均 O（logN），最坏 O（N）的复杂度。</p><p>一般，要求查询效率高的结构，都会想到平衡树，但是树比跳跃表更复杂，但是效率，未必有跳跃表高。许多<br>时候可以用跳表来取代平衡树。</p><p>在 Redis 中，跳跃表作为 有序集合（ZSET）的底层实现之一和集群节点内部结构。源码在 <code>src/server.h</code> 中</p><pre><code class="angular2html">typedef struct zskiplist {    struct zskiplistNode *header, *tail;    // 头节点指针和尾节点指针    unsigned long length;   // 节点数量（不包括头节点）    int level;  // 所有节点，层数最高的节点的层数} zskiplist;</code></pre><pre><code class="angular2html">/* ZSETs use a specialized version of Skiplists */typedef struct zskiplistNode {    sds ele;    // 数据值    double score;   // 分值    struct zskiplistNode *backward; // 后退指针    struct zskiplistLevel { // 每个节点的层        struct zskiplistNode *forward;  // 每层前进指针        unsigned int span;  // 距离下个相同层的节点的跨度    } level[];} zskiplistNode;</code></pre><p>作者 <code>antirez</code> 指出 Redis 跳跃表与一般跳跃表的不同</p><blockquote><p>a) this implementation allows for repeated scores.  // 允许分值重复<br>b) the comparison is not just by key (our ‘score’) but by satellite data. // 对比的时候不仅比较分值还比较对象的值<br>c) there is a back pointer, so it’s a doubly linked list with the back pointers being only at “level 1”. // 有一个后退指针，即在第一层实现了一个双向链表，允许后退遍历</p></blockquote><p><img src="http://8090lambert.cn/images/blog/skiplist/skiplist_01.png" alt="跳跃表结构"><br>表头节点是一个拥有32个level的 <code>zskiplistNode</code> 结构，正向遍历跳表，就是从表头<br>的某层开始，一般层的数量越多，查询的效率就会越高，每次插入一个新跳表节点时，会随机<br>生成一个 1 ~ 32 的层数（对应表头节点，最高32层），从索引位置 0 ~ 31。</p><h3 id="跳跃表的查找"><a href="#跳跃表的查找" class="headerlink" title="跳跃表的查找"></a>跳跃表的查找</h3><p><img src="http://8090lambert.cn/images/blog/skiplist/skiplist_02.png" alt="跳跃表查找"><br>当我们要查找一个分值为46的节点时，普通的链表只能从头至尾循环查找，对于跳跃表，它每次<br>从 <code>level</code> 最高的层开始查找。</p><ol><li>首先，从 <code>zskiplist</code> 的头结点找到最高 <code>level</code> 的节点，55 <code>大于</code> 要找的46，根据层的 <code>backward</code> 指针后退至 L3 节点；</li><li>L3 节点的分值为 21 <code>小于</code> 46 ，则从 55 的下一层开始后退到 L2 节点；</li><li>L2 节点的分值 37 <code>小于</code> 46， 则从 L2 节点的下一层前进至 L1 节点；</li><li>L1 节点的分值为 46，查找成功</li></ol><p>少量的数据，在做这种对比的时候，优势并不明显，如果数据量特别多，跳过的元素数量<br>将会非常可观，效率的提升也会非常明显。</p><p>当跳跃表的多个元素分值（score）相同时，会按照成员对象的字典顺序进行排序，成员<br>对象小的节点排在靠近表头的位置，成员对象大的节点排在靠近表尾的位置。</p><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>跳跃表是特别高效的节点查找方式，在工作中，在自己的程序设计时，如果有对已排序<br>的数据做查找时，它是比树更简单的一种思路。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;有一种查询效率特别高的有序的数据结构，跳跃表（SkipList），这种结构，在Redis和levelDB中，都有用到。&lt;br&gt;其实是在有序链表的基础上进行扩展，丰富了在链表中查找制定值，需要 O（N）的时间复杂度的问题，它在查&lt;br&gt;询时，能做到最快 O（1），平均 O（l
      
    
    </summary>
    
    
      <category term="redis" scheme="http://8090lambert.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>详解Laravel中的依赖注入和IoC</title>
    <link href="http://8090lambert.cn/2017/10/14/%E8%AF%A6%E8%A7%A3Laravel%E4%B8%AD%E7%9A%84%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E5%92%8CIoC/"/>
    <id>http://8090lambert.cn/2017/10/14/详解Laravel中的依赖注入和IoC/</id>
    <published>2017-10-14T13:44:30.000Z</published>
    <updated>2021-05-09T14:50:16.600Z</updated>
    
    <content type="html"><![CDATA[<p>作为开发者，我们一直在尝试通过使用设计模式和尝试新的健壮型框架来寻找新的方式来编写设计良好且健壮的代码。在本篇文章中，我们将通过 Laravel 的 IoC 组件探索依赖注入设计模式，并了解它如何改进我们的设计。</p><h4 id="依赖注入"><a href="#依赖注入" class="headerlink" title="依赖注入"></a>依赖注入</h4><p>依赖注入一词是由 <a href="http://en.wikipedia.org/wiki/Martin_Fowler" target="_blank" rel="noopener">Martin Fowler</a> 提出的术语，它是将组件注入到应用程序中的一种行为。就像 <a href="http://en.wikipedia.org/wiki/Ward_Cunningham" target="_blank" rel="noopener">Ward Cunningham</a> 说的:</p><blockquote><p>依赖注入是敏捷架构中关键元素。</p></blockquote><p>让我们来看一个例子：</p><pre><code class="angular2html">class UserProvider{    protected $connection;    public function __construct(){        $this-&gt;connection = new Connection;    }    public function retrieveByCredentials( array $credentials ){        $user = $this-&gt;connection                        -&gt;where( &#39;email&#39;, $credentials[&#39;email&#39;])                        -&gt;where( &#39;password&#39;, $credentials[&#39;password&#39;])                        -&gt;first();        return $user;    }}</code></pre><p>如果你要测试或者维护这个类，你必须访问数据库的实例来进行一些查询。为了避免必须这样做，你可以将此类与其他类进行 解耦 ，你有三个选项之一，可以将 Connection 类注入而不需要直接使用它。</p><p>将组件注入类时，可以使用以下三个选项之一：</p><h4 id="构造方法注入"><a href="#构造方法注入" class="headerlink" title="构造方法注入"></a>构造方法注入</h4><pre><code class="angular2html">class UserProvider{    protected $connection;    public function __construct( Connection $con ){        $this-&gt;connection = $con;    }    ...</code></pre><h4 id="Setter-方法注入"><a href="#Setter-方法注入" class="headerlink" title="Setter 方法注入"></a>Setter 方法注入</h4><p>同样，我们也可以使用 Setter 方法注入依赖关系：</p><pre><code class="angular2html">class UserProvider{    protected $connection;    public function __construct(){        ...    }    public function setConnection( Connection $con ){        $this-&gt;connection = $con;    }    ...</code></pre><h4 id="接口注入"><a href="#接口注入" class="headerlink" title="接口注入"></a>接口注入</h4><pre><code class="angular2html">interface ConnectionInjector{    public function injectConnection( Connection $con );}class UserProvider implements ConnectionInjector{    protected $connection;    public function __construct(){        ...    }    public function injectConnection( Connection $con ){        $this-&gt;connection = $con;    }}</code></pre><p>当一个类实现了我们的接口时，我们定义了 <code>injectConnection</code> 方法来解决依赖关系。</p><h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><p>现在，当测试我们的类时，我们可以模拟依赖类并将其作为参数传递。每个类必须专注于一个特定的任务，而不应该关心解决它们的依赖性。这样，你将拥有一个更专注和可维护的应用程序。</p><p>如果你想了解更多关于 DI 的信息，<a href="http://www.sitepoint.com/managing-class-dependencies-1/" target="_blank" rel="noopener">Alejandro Gervassio</a> 在 本系列 文章中对其进行了广泛而专业的介绍，所以一定要去读这些文章。那么，什么又是 IoC 呢？IoC （控制反转）不需要使用依赖注入，但它可以帮助你有效的管理依赖关系。</p><h3 id="控制反转"><a href="#控制反转" class="headerlink" title="控制反转"></a>控制反转</h3><p>Ioc 是一个简单的组件，可以更加方便地解析依赖项。你可以将对象形容为容器，并且每次解析类时，都会自动注入依赖项。</p><h4 id="Laravel-Ioc"><a href="#Laravel-Ioc" class="headerlink" title="Laravel Ioc"></a>Laravel Ioc</h4><p>当你请求一个对象时， Laravel Ioc 在解决依赖关系的方式上有些特殊：<br><img src="http://8090lambert.cn/images/blog/laravel/01.png" alt=""><br>我们使用一个简单的例子，将在本文中改进它。<br><code>SimpleAuth</code> 类依赖于 <code>FileSessionStorage</code> ，所以我们的代码可能是这样的：</p><pre><code class="angular2html">class FileSessionStorage{  public function __construct(){    session_start();  }  public function get( $key ){    return $_SESSION[$key];  }  public function set( $key, $value ){    $_SESSION[$key] = $value;  }}class SimpleAuth{  protected $session;  public function __construct(){    $this-&gt;session = new FileSessionStorage;  }}//创建一个 SimpleAuth$auth = new SimpleAuth();</code></pre><p>这是一种经典的方法，让我们从使用构造函数注入开始。</p><pre><code class="angular2html">class SimpleAuth{  protected $session;  public function __construct( FileSessionStorage $session ){    $this-&gt;session = $session;  }}</code></pre><p>现在我们创建一个对象：</p><pre><code class="angular2html">$auth = new SimpleAuth( new FileSessionStorage() );</code></pre><p>现在我想使用 <a href="https://github.com/laravel/framework/tree/master/src/Illuminate/Container" target="_blank" rel="noopener">Laravel Ioc</a> 来管理这一切。<br>因为 <code>Application</code> 类继承自 <code>Container</code> 类，所以你可以通过 App 门面来访问容器。</p><pre><code class="angular2html">App::bind( &#39;FileSessionStorage&#39;, function(){    return new FileSessionStorage;});</code></pre><p> <code>bind</code> 方法第一个参数是要绑定到容器的唯一 ID ，第二个参数是一个回调函数每当执行 FileSessionStorage 类时执行，我们还可以传递一个表示类名的字符串，如下所示。<br><em>Note:</em>如果你查看 Laravel 包时，你将看到绑定有时会分组，比如（ view, view.finder……）。<br>假设我们将会话存储转换为 Mysql 存储，我们的类应该类似于：</p><pre><code class="angular2html">class MysqlSessionStorage{  public function __construct(){    //...  }  public function get($key){    // do something  }  public function set( $key, $value ){    // do something  }}</code></pre><p>现在我们已经更改了依赖项，我们还需要更改 <code>SimpleAuth</code> 构造函数，并将新对象绑定到容器中！</p><blockquote><p>高级模块不应该依赖于低级模块，两者都应该依赖于抽象对象。<br>  抽象不应该依赖于细节，细节应该取决于抽象。<br>  <br><br>  Robert C. Martin </p></blockquote><p>我们的 <code>SimpleAuth</code> 类不应该关心我们的存储是如何完成的，相反它更应该关注于消费的服务。<br>因此，我们可以抽象实现我们的存储：</p><pre><code class="angular2html">interface SessionStorage{  public function get( $key );  public function set( $key, $value );}</code></pre><p>这样我们就可以实现并请求 <code>SessionStorage</code> 接口的实例：</p><pre><code class="angular2html">class FileSessionStorage implements SessionStorage{  public function __construct(){    //...  }  public function get( $key ){    //...  }  public function set( $key, $value ){    //...  }}class MysqlSessionStorage implements SessionStorage{  public function __construct(){    //...  }  public function get( $key ){    //...  }  public function set( $key, $value ){    //...  }}class SimpleAuth{  protected $session;  public function __construct( SessionStorage $session ){    $this-&gt;session = $session;  }}</code></pre><p>如果我们使用 <code>App::make(&#39;SimpleAuth&#39;)</code> 通过容器解析 <code>SimpleAuth</code><br>类，容器将会抛出 <code>BindingResolutionException</code> ，尝试从绑定解析类之后，返回到反射方法并解析所有依赖项</p><pre><code class="angular2html">Uncaught exception &#39;Illuminate\Container\BindingResolutionException&#39; with message &#39;Target [SessionStorage] is not instantiable.&#39;</code></pre><p>容器正试图将接口实例化。我们可以为该接口做一个具体的绑定。</p><pre><code class="angular2html">App:bind( &#39;SessionStorage&#39;, &#39;MysqlSessionStorage&#39; );</code></pre><p>现在每次我们尝试从容器解析该接口时，我们会得到一个 <code>MysqlSessionStorage</code> 实例。如果我们想要切换我们的存储服务，我们只要变更一下这个绑定。</p><p><em>Note:</em>如果你想要查看一个类是否已经在容器中被绑定，你可以使用 <code>App::bound(&#39;ClassName&#39;)</code> ，或者可以使用 <code>App::bindIf(&#39;ClassName&#39;)</code> 来注册一个还未被注册过的绑定。</p><p>Laravel Ioc 也提供 <code>App::singleton(&#39;ClassName&#39;, &#39;resolver&#39;)</code> 来处理单例的绑定。<br>你也可以使用 <code>App::instance(&#39;ClassName&#39;, &#39;instance&#39;)</code> 来创建单例的绑定。<br>如果容器不能解析依赖项就会抛出 <code>ReflectionException</code> ，但是我们可以使用 <code>App::resolvingAny(Closure)</code> 方法以回调函数的形式来解析任何指定的类型。</p><p><em>Note:</em>如果你为某个类型已经注册了一个解析方式 <code>resolvingAny</code> 方法仍然会被调用，但它会直接返回 <code>bind</code> 方法的返回值。</p><h4 id="小贴士"><a href="#小贴士" class="headerlink" title="小贴士"></a>小贴士</h4><ul><li>这些绑定写在哪儿：<br>如果只是一个小型应用你可以写在一个全局的起始文件 <code>global/start.php</code> 中，但如果项目变得越来越庞大就有必要使用 <a href="https://github.com/laravel/framework/blob/5.8/src/Illuminate/Support/ServiceProvider.php" target="_blank" rel="noopener">Service Provider</a> 。</li><li>测试:<br>当需要快速简易的测试可以考虑使用 <code>php artisan tinker</code> ，它十分强大，且能帮你提升你的 Laravel 测试流程。</li><li>Reflection API：<br>PHP 的 <a href="http://www.sitepoint.com/introspection-and-reflection-in-php/" target="_blank" rel="noopener">Reflection API</a> 是非常强大的，如果你想要深入 Laravel Ioc 你需要熟悉 Reflection API ，可以先看下这个 教程 来获得更多的信息。   </li></ul><blockquote><p>Reference： <a href="https://www.sitepoint.com/dependency-injection-laravels-ioc/" target="_blank" rel="noopener">https://www.sitepoint.com/dependency-injection-laravels-ioc/</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;作为开发者，我们一直在尝试通过使用设计模式和尝试新的健壮型框架来寻找新的方式来编写设计良好且健壮的代码。在本篇文章中，我们将通过 Laravel 的 IoC 组件探索依赖注入设计模式，并了解它如何改进我们的设计。&lt;/p&gt;
&lt;h4 id=&quot;依赖注入&quot;&gt;&lt;a href=&quot;#依赖
      
    
    </summary>
    
    
      <category term="php" scheme="http://8090lambert.cn/tags/php/"/>
    
  </entry>
  
  <entry>
    <title>Redis-链表</title>
    <link href="http://8090lambert.cn/2017/07/23/Redis-%E9%93%BE%E8%A1%A8/"/>
    <id>http://8090lambert.cn/2017/07/23/Redis-链表/</id>
    <published>2017-07-23T14:21:37.000Z</published>
    <updated>2021-05-09T14:50:16.596Z</updated>
    
    <content type="html"><![CDATA[<p>链表是一种基本的数据结构，它是由一系列的节点组成，每个节点上都包括有两部分数据：一个是存储数据元素的数据域，一个是存储下一个节点地址的指针域。新增节点时，可以做到O(1)的复杂度。链表一般分为：单向链表、双向链表、循环链表。Redis 的链表，属于双向链表。</p><p>链表中节点结构体在文件 <code>src/adlist.h</code> 如下：</p><pre><code class="angular2html">typedef struct listNode {    struct listNode *prev;    struct listNode *next;    void *value;} listNode;</code></pre><p>其中 <code>prev</code> 指向当前节点的上一个节点，<code>next</code> 指向当前节点的下一个节点；<code>value</code> 用来存储当前节点的数据，其中 <code>prev</code> 和 <code>next</code> 共同组成了链表的指针域，<code>value</code> 则是它的数据域，因为是 <code>void *</code>，所以可以在节点中存储任意的数据类型。</p><p>多个 <code>listNode</code> 通过 <code>prev</code> 和 <code>next</code> 就可以组成一个双向链表。但是 Redis 还是决定用一个结构体来管理链表。这是它的结构体：</p><pre><code class="angular2html">typedef struct list {    listNode *head;     // 表头节点    listNode *tail;     // 表尾节点    void *(*dup)(void *ptr);    // 节点复制函数    void (*free)(void *ptr);    // 节点释放函数    int (*match)(void *ptr, void *key);     // 节点对比函数    unsigned long len;  // 链表长度} list;</code></pre><p><code>head</code>、<code>tail</code> 和 <code>len</code> 就不多做介绍了，<code>dup</code>、<code>free</code> 和 <code>match</code> 主要是实现多态链表的函数，因为 <code>listNode</code> 的 <code>value</code> 可以存储任意类型的数据，在复制、释放或者比较时，对于不同的类型，需要有不同的操作，所以，在生成链表时，需要对应的set每种类型的操作（复制、释放和对比）API。<br>在 <code>src/adlist.h</code> 64行开始，有6个宏定义的方法，作为 <code>setter</code> 和 <code>getter</code>。</p><pre><code class="angular2html">#define listSetDupMethod(l,m) ((l)-&gt;dup = (m))#define listSetFreeMethod(l,m) ((l)-&gt;free = (m))#define listSetMatchMethod(l,m) ((l)-&gt;match = (m))#define listGetDupMethod(l) ((l)-&gt;dup)#define listGetFree(l) ((l)-&gt;free)#define listGetMatchMethod(l) ((l)-&gt;match)</code></pre><p>对于链表结构，获取前一个节点和后一个节点的复杂度都是O(1)，因为有 <code>len</code> 属性，所以获取链表长度复杂度也是O(1)。在网上找了些文章，在 <code>list</code> 的实现，主要就用到了链表，其实可以想到，因为 <code>list</code> 本身就是一个链表的结构。</p><p><code>aslist.h</code> 文件中还有一个结构体</p><pre><code class="angular2html">typedef struct listIter {    listNode *next;    int direction;} listIter;</code></pre><p>这个是 <code>list</code> 的迭代器，<code>next</code> 指针指向下个节点，<code>direction</code> 是定义迭代的方向，<code>AL_START_HEAD</code> 和 <code>AL_START_TAIL</code> 分别对应从头部 -&gt; 尾部的方向、尾部 -&gt; 头部的方向。相关的方法有：</p><pre><code class="angular2html">listIter *listGetIterator(list *list, int direction)    // 初始化一个 链表迭代器listNode *listNext(listIter *iter)  // 迭代器 next 方法void listReleaseIterator(listIter *iter);   // 迭代器释放void listRewind(list *list, listIter *li);  // 迭代器恢复指针至表头位置void listRewindTail(list *list, listIter *li);  // 迭代器恢复指针至表尾位置</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;链表是一种基本的数据结构，它是由一系列的节点组成，每个节点上都包括有两部分数据：一个是存储数据元素的数据域，一个是存储下一个节点地址的指针域。新增节点时，可以做到O(1)的复杂度。链表一般分为：单向链表、双向链表、循环链表。Redis 的链表，属于双向链表。&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
    
      <category term="redis" scheme="http://8090lambert.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis-SDS的实现</title>
    <link href="http://8090lambert.cn/2017/07/21/Redis-SDS%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>http://8090lambert.cn/2017/07/21/Redis-SDS的实现/</id>
    <published>2017-07-21T07:58:47.000Z</published>
    <updated>2021-05-09T14:50:16.594Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 的作者 <code>antirez</code> 在前些日子，通过博客文章《<a href="http://antirez.com/news/110" target="_blank" rel="noopener"> The first release candidate of Redis 4.0 is out </a>》发布了 redis 4.0 版本。在网上看到了一些文章，对于4.0新特性的介绍：</p><ul><li>Lazyfree，之前的版本，在对一个较大的key执行删除时，会造成 redis-server 阻塞，现在可以使用 <code>UNLINK</code> 异步删除， <code>FLUSHDB</code> 和 <code>FLUSHALL</code> 都新增了 <code>ASYNC</code> 选项，支持在后台线程进行；</li><li>LFU，新添加了 Last Frequently Used 缓存驱逐策略，具体见 <a href="http://antirez.com/news/109" target="_blank" rel="noopener">antirez的另一篇文章</a>；</li><li>内存命令，新添加了一个 MEMORY 命令， 可以用于内存使用情况；</li><li>混合 RDB-AOF 持久化格式，之前大部分的做法，都是同时开启 RDB 和 AOF 两种持久化，这种模式会在 AOF rewrite 文件里同时包含 RDB 格式的内容和 AOF 格式的内容，可以发生问题时迅速载入数据（RDB 优点），还能快速的生成重写文件</li><li>更多的可以查看 <a href="https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES" target="_blank" rel="noopener"> https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES </a></li></ul><p>有了这么几个优化点，带着好奇心，决定看看新版本的源码和之前相比有什么不同。</p><h3 id="新版本的-SDS"><a href="#新版本的-SDS" class="headerlink" title="新版本的 SDS"></a>新版本的 SDS</h3><p>我们都知道，sds 是 Redis 用来表示字符串键值对，在3.0版本中，sds的结构体是这样子的:</p><pre><code class="angular2html">struct sdshdr {    int len; // 记录 buf 数组中已使用字节的数量，等于SDS所保存字符串的长度     int free; // 记录 buf 数组中未使用字节的数量      char buf[]; // 字节数组，用于保存字符串  }</code></pre><p>新版本的sds根据保存字符串长度的不同，分别对应5种结构体：</p><pre><code class="angular2html">/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 {    unsigned char flags; /* 3 lsb of type, and 5 msb of string length */    char buf[];};struct __attribute__ ((__packed__)) sdshdr8 {    uint8_t len; /* used */    uint8_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];};struct __attribute__ ((__packed__)) sdshdr16 {    uint16_t len; /* used */    uint16_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];};struct __attribute__ ((__packed__)) sdshdr32 {    uint32_t len; /* used */    uint32_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];};struct __attribute__ ((__packed__)) sdshdr64 {    uint64_t len; /* used */    uint64_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];};</code></pre><p>新的结构体，其中 <code>len</code> 表示字符串的长度（不包含结尾’\0’的空字符）；<code>alloc</code> 表示为字符串分配的空间，<code>flags</code> 中最低三个bit，表示类型， <code>buf</code> 存储着具体的字符串</p><h3 id="常数复杂度获取字符串长度"><a href="#常数复杂度获取字符串长度" class="headerlink" title="常数复杂度获取字符串长度"></a>常数复杂度获取字符串长度</h3><p>sds 和 C 字符串都是以一个空字符 “\0” 结尾。C 字符串本身不记录长度，要想得到长度，必须遍历计算，时间复杂度 O(N)，而 sds 结构体中的 <code>len</code> 记录了本身的长度，所以获取一个 sds 字符串的长度的复杂度是 O(1)。</p><p>sds 在每次初始化或者长度有变化时，相应的 api 都会有这样的计算，可以直接使用而无需关心是怎么样做的，有兴趣的可以看源码的 src/sds.h 中的 <code>sdslen</code> 方法（86行）</p><h3 id="杜绝缓冲区的溢出"><a href="#杜绝缓冲区的溢出" class="headerlink" title="杜绝缓冲区的溢出"></a>杜绝缓冲区的溢出</h3><p>在做字符串拼接的时候，在 C 语言里，比如执行 <code>strcat(char *hello, const char *world )</code> 拼接两个字符串时，在内存中与 hello 紧邻的还有另一个字符串 “hello1”，假定未为 hello 分配足够多的内存，在 <code>strcat</code> 执行后，hello 的数据溢出到 “hello1”，<strong>导致其中 “hello” 被 “world” 在不知情的情况下被替换掉</strong>，这种情况是非常危险的…</p><p>sds 在字符串修改时，在拼接之前，会先检查 sds 的空间是否满足，如果不满足的话，会自动（通过调用 <code>sdsMakeRoomFor</code>）修改至所需的大小，然后才执行实际的修改，这样保证了新的字符串不会因为溢出而污染其他相邻内存上的数据。</p><h3 id="空间分配策略"><a href="#空间分配策略" class="headerlink" title="空间分配策略"></a>空间分配策略</h3><p>C 字符串在每次增加或者缩短字符串时，程序总是要对这个 C 字符串的数组进行一次内存重新分配：</p><blockquote><p>如果是增长字符串，那么在执行这个操作之前，需要通过内存重新分配来扩展底层数组的大小，否则就会造成 缓冲区溢出</p></blockquote><blockquote><p>如果是缩短字符串，那么在执行这个操作之后，需要通过内存重新分配来释放字符串不再使用的那部分空间，否则就会造成 内存泄露</p></blockquote><p>每一次内存分配，都是比较耗时的操作，涉及到复杂的算法和内存的IO，如果出于性能的考虑，就要更可能少的去做这样的事情。</p><p>作者的初衷，相信也是将 Redis 定位成更高效，性能更好的NoSQL。为了优化 这种缺陷，sds做了预分配和惰性释放来分别应对这两种内存重新分配的情况。</p><ol><li>空间预分配</li></ol><p>空间预分配主要作用于 sds 字符串增长操作，通过 API <code>sdsMakeRoomFor</code> 来重新计算分配空间，具体规则在 src/sds.c 210行：</p><pre><code class="angular2html">if (newlen &lt; SDS_MAX_PREALLOC)    newlen *= 2;else    newlen += SDS_MAX_PREALLOC;</code></pre><p>总结一下就是：如果新的字符串大小 <strong>小于</strong> 1MB，那么会分配 2倍的新的字符串的大小，即 <code>newlen *= 2</code>，buf 的大小则为 <code>newlen * 2 + 1</code>，一字节用来存结尾空字符 “\0”；如果新字符串的长度 <strong>大于</strong> 1MB，那么会分配 新字符串大小 + 1MB，即 <code>newlen += SDS_MAX_PREALLOC</code>。</p><p>这样做的话，会将原本增长N次，便会重新进行N次内存分配，变成了，最多会重新分配内存N次，就是说，如果一次预分配后的大小，满足 sds 修改后的大小，就不需要再对内存重新分配，直接增长即可。</p><ol start="2"><li>空间惰性释放</li></ol><p>空间惰性释放是指缩短 sds 时，不是立即使用内存重新分配来回收缩短后多出来的空间，而是继续保留，以便将来使用。<br>以 <code>sdstrim</code> 这个 api 为例，看下它的源码</p><pre><code class="angular2html">sds sdstrim(sds s, const char *cset) {    char *start, *end, *sp, *ep;    size_t len;    sp = start = s;    ep = end = s+sdslen(s)-1;    while(sp &lt;= end &amp;&amp; strchr(cset, *sp)) sp++;    while(ep &gt; sp &amp;&amp; strchr(cset, *ep)) ep--;    len = (sp &gt; ep) ? 0 : ((ep-sp)+1);    if (s != sp) memmove(s, sp, len);    s[len] = &#39;\0&#39;;    sdssetlen(s,len);    return s;}</code></pre><p>只做了 <code>memmove</code> 操作，并没有真正重新分配内存，倘若此时，需要执行 <code>sdscat</code>，拼接上一个较短字符串，就可以直接使用，避免了再次分配内存。</p><p>如果有需要，必须使用释放掉这部分内存，可以调用 <code>sdsRemoveFreeSpace</code> 来真正释放掉。</p><h3 id="二进制安全"><a href="#二进制安全" class="headerlink" title="二进制安全"></a>二进制安全</h3><p>我们都知道，C 字符串除了在末尾的空字符外，其他位置不允许有空字符，否则最先被读到的空字符，就会被误认为是字符串结尾。这样限制了只能存储纯文本内容，不能保存二进制数据。</p><p>sds 就不会有这样的要求，它可以满足你存储任何数据，即使字符串中间有空字符也不受影响，因为它有 len 来表示字符串是否结尾。sds 所有 API 都是二进制安全的，和 C 字符串一样，是以空字符结尾，因此可以复用 C 字符串的一些函数。</p><p>以上就是我对 sds 字符串的认识，觉得作者真的是非常用心的设计，既遵循了规范，并且还有很好的优化点在里面，越来越有兴趣继续研究下去了~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Redis 的作者 &lt;code&gt;antirez&lt;/code&gt; 在前些日子，通过博客文章《&lt;a href=&quot;http://antirez.com/news/110&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt; The first release candi
      
    
    </summary>
    
    
      <category term="redis" scheme="http://8090lambert.cn/tags/redis/"/>
    
  </entry>
  
</feed>
